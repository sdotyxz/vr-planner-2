# Godot_Docs - 2D

**Pages:** 43

---

## 2D and 3D physics interpolation — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/physics/interpolation/2d_and_3d_physics_interpolation.html

**Contents:**
- 2D and 3D physics interpolation
- Global versus local interpolation
- Resetting physics interpolation
- 2D Particles
- Other
- User-contributed notes

Generally 2D and 3D physics interpolation work in very similar ways. However, there are a few differences, which will be described here.

In 3D, physics interpolation is performed independently on the global transform of each 3D instance.

In 2D by contrast, physics interpolation is performed on the local transform of each 2D instance.

This has some implications:

In 3D, it is easy to turn interpolation on and off at the level of each Node, via the physics_interpolation_mode property in the Inspector, which can be set to On, Off, or Inherited.

However this means that in 3D, pivots that occur in the SceneTree (due to parent child relationships) can only be interpolated approximately over the physics tick. In most cases this will not matter, but in some situations the interpolation can look slightly wrong.

In 2D, interpolated local transforms are passed down to children during rendering. This means that if a parent has physics_interpolation_mode set to On, but the child is set to Off, the child will still be interpolated if the parent is moving. Only the child's local transform is uninterpolated. Controlling the on / off behavior of 2D nodes therefore requires a little more thought and planning.

On the positive side, pivot behavior in the scene tree is perfectly preserved during interpolation in 2D, which gives super smooth behavior.

Whenever objects are moved to a completely new position, and interpolation is not desired (so as to prevent a "streaking" artefact), it is the responsibility of the user to call reset_physics_interpolation().

The good news is that in 2D, this is automatically done for you when nodes first enter the tree. This reduces boiler plate, and reduces the effort required to get an existing project working.

If you move objects after adding to the scene tree, you will still need to call reset_physics_interpolation() as with 3D.

Currently only CPUParticles2D are supported for physics interpolation in 2D. It is recommended to use a physics tick rate of at least 20-30 ticks per second to keep particles looking fluid.

Particles2D (GPU particles) are not yet interpolated, so for now it is recommended to convert to CPUParticles2D (but keep a backup of your Particles2D in case we get these working).

get_global_transform_interpolated() is currently only available for 3D.

MultiMeshes are supported in both 2D and 3D.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D antialiasing — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/2d_antialiasing.html

**Contents:**
- 2D antialiasing
- Introduction
- Antialiasing property in Line2D and custom drawing
- Multisample antialiasing (MSAA)
- User-contributed notes

Godot also supports antialiasing in 3D rendering. This is covered on the 3D antialiasing page.

Due to their limited resolution, scenes rendered in 2D can exhibit aliasing artifacts. These artifacts usually manifest in the form of a "staircase" effect on geometry edges, and are most noticeable when using nodes such as Line2D, Polygon2D or TextureProgressBar. Custom drawing in 2D can also have aliasing artifacts for methods that don't support antialiasing.

In the example below, you can notice how edges have a blocky appearance:

Image is scaled by 2× with nearest-neighbor filtering to make aliasing more noticeable.

To combat this, Godot supports several methods of enabling antialiasing on 2D rendering.

This is the recommended method, as it has a lower performance impact in most cases.

Line2D has an Antialiased property which you can enable in the inspector. Also, several methods for Custom drawing in 2D support an optional antialiased parameter, which can be set to true when calling the function.

These methods do not require MSAA to be enabled, which makes their baseline performance cost low. In other words, there is no permanent added cost if you're not drawing any antialiased geometry at some point.

The downside of these antialiasing methods is that they work by generating additional geometry. If you're generating complex 2D geometry that's updated every frame, this may be a bottleneck. Also, Polygon2D, TextureProgressBar, and several custom drawing methods don't feature an antialiased property. For these nodes, you can use 2D multisample antialiasing instead.

This is only available in the Forward+ and Mobile renderers, not the Compatibility renderer.

Before enabling MSAA in 2D, it's important to understand what MSAA will operate on. MSAA in 2D follows similar restrictions as in 3D. While it does not introduce any blurriness, its scope of application is limited. The main applications of 2D MSAA are:

Geometry edges, such as line and polygon drawing.

Sprite edges only for pixels touching one of the texture's edges. This works for both linear and nearest-neighbor filtering. Sprite edges created using transparency on the image are not affected by MSAA.

The downside of MSAA is that it only operates on edges. This is because MSAA increases the number of coverage samples, but not the number of color samples. However, since the number of color samples did not increase, fragment shaders are still run for each pixel only once. As a result, MSAA will not affect the following kinds of aliasing in any way:

Aliasing within nearest-neighbor filtered textures (pixel art).

Aliasing caused by custom 2D shaders.

Specular aliasing when using Light2D.

Aliasing in font rendering.

MSAA can be enabled in the Project Settings by changing the value of the Rendering > Anti Aliasing > Quality > MSAA 2D setting. It's important to change the value of the MSAA 2D setting and not MSAA 3D, as these are entirely separate settings.

Comparison between no antialiasing (left) and various MSAA levels (right). The top-left corner contains a Line2D node, the top-right corner contains 2 TextureProgressBar nodes. The bottom contains 8 pixel art sprites, with 4 of them touching the edges (green background) and 4 of them not touching the edges (Godot logo):

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D coordinate systems and 2D transforms — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/engine_details/architecture/2d_coordinate_systems.html

**Contents:**
- 2D coordinate systems and 2D transforms
- Introduction
- Godot 2D coordinate systems
- Node transforms
- User-contributed notes

This is a detailed overview of the available 2D coordinate systems and 2D transforms that are built in. The basic concepts are covered in Viewport and canvas transforms.

Transform2D are matrices that convert coordinates from one coordinate system to another. In order to use them, it is beneficial to know which coordinate systems are available in Godot. For a deeper understanding, the Matrices and transforms tutorial offers insights to the underlying functionality.

The following graphic gives an overview of Godot 2D coordinate systems and the available node-transforms, transform-functions and coordinate-system related functions. At the left is the OS Window Manager screen, at the right are the CanvasItems. For simplicity reasons this graphic doesn't include SubViewport, SubViewportContainer, ParallaxLayer and ParallaxBackground all of which also influence transforms.

The graphic is based on a node tree of the following form: Root Window (embed Windows) ⇒ Window (don't embed Windows) ⇒ CanvasLayer ⇒ CanvasItem ⇒ CanvasItem ⇒ CanvasItem. There are more complex combinations possible, like deeply nested Window and SubViewports, however this example intends to provide an overview of the methodology in general.

Click graphic to enlarge.

This is the local coordinate system of a CanvasItem.

This is the local coordinate system of the parent's CanvasItem. When positioning CanvasItems in the Canvas, they usually inherit the transformations of their parent CanvasItems. An exceptions is CanvasItems.top_level.

As mentioned in the previous tutorial Canvas layers, there are two types of canvases (Viewport canvas and CanvasLayer canvas) and both have a canvas coordinate system. These are also called world coordinates. A Viewport can contain multiple Canvases with different coordinate systems.

This is the coordinate system of the Viewport.

This is only used internally for functionality like 3D-camera ray projections.

Every Viewport (Window or SubViewport) in the scene tree is embedded either in a different node or in the OS Window Manager. This coordinate system's origin is identical to the top-left corner of the Window or SubViewport and its scale is the one of the embedder or the OS Window Manager.

If the embedder is the OS Window Manager, then they are also called Screen Coordinates.

The origin of this coordinate system is the top-left corner of the embedding node or the OS Window Manager screen. Its scale is the one of the embedder or the OS Window Manager.

If the embedder is the OS Window Manager, then they are also called Absolute Screen Coordinates.

Each of the mentioned nodes have one or more transforms associated with them and the combination of these nodes infer the transforms between the different coordinate systems. With a few exceptions, the transforms are Transform2D and the following list shows details and effects of each of them.

CanvasItems are either Control-nodes or Node2D-nodes.

For Control nodes this transform consists of a position relative to the parent's origin and a scale and rotation around a pivot point.

For Node2D nodes transform consists of position, rotation, scale and skew.

The transform affects the item itself and usually also child-CanvasItems and in the case of a SubViewportContainer it affects the contained SubViewport.

The CanvasLayer's transform affects all CanvasItems within the CanvasLayer. It doesn't affect other CanvasLayers or Windows in its Viewport.

The follow viewport transform is an automatically calculated transform, that is based on the Viewport's canvas transform and the CanvasLayer's follow viewport scale and can be used, if enabled, to achieve a pseudo-3D effect. It affects the same child nodes as the CanvasLayer transform.

The canvas transform affects all CanvasItems in the Viewport's default canvas. It also affects CanvasLayers, that have follow viewport transform enabled. The Viewport's active Camera2D works by changing this transform. It doesn't affect this Viewport's embedded Windows.

Viewports also have a global canvas transform. This is the master transform and affects all individual Canvas Layer and embedded Window transforms. This is primarily used in Godot's CanvasItem Editor.

Finally, Viewports have a stretch transform, which is used when resizing or stretching the viewport. This transform is used for Windows as described in Multiple resolutions, but can also be manually set on SubViewports by means of size and size_2d_override. Its translation, rotation and skew are the default values and it can only have non-default scale.

In order to scale and position the Window's content as described in Multiple resolutions, each Window contains a window transform. It is for example responsible for the black bars at the Window's sides so that the Viewport is displayed with a fixed aspect ratio.

Every Window also has a position to describe its position within its embedder. The embedder can be another Viewport or the OS Window Manager.

stretch together with stretch_shrink declare for a SubViewportContainer if and by what integer factor the contained SubViewport should be scaled in comparison to the container's size.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/index.html

**Contents:**
- 2D
- Rendering
- Physics and movement
- Tools

Godot includes a dedicated 2D renderer and 2D physics engine, as well as 2D-specific features like tilemaps, particles, and animation systems. This section covers most 2D-specific topics in Godot.

For 2D topics not covered in this section, see also 2D skeletons and 2D navigation overview. For using physics in 2D, see Physics. There is also a step-by-step tutorial on creating a 2D game in Your first 2D game.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D lights and shadows — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/2d_lights_and_shadows.html

**Contents:**
- 2D lights and shadows
- Introduction
- Nodes
- Point lights
- Directional light
- Common light properties
- Setting up shadows
  - Automatically generating a light occluder
  - Manually drawing a light occluder
- Normal and specular maps

By default, 2D scenes in Godot are unshaded, with no lights and shadows visible. While this is fast to render, unshaded scenes can look bland. Godot provides the ability to use real-time 2D lighting and shadows, which can greatly enhance the sense of depth in your project.

No 2D lights or shadows, scene is unshaded

2D lights enabled (without shadows)

2D lights and shadows enabled

There are several nodes involved in a complete 2D lighting setup:

CanvasModulate (to darken the rest of the scene)

PointLight2D (for omnidirectional or spot lights)

DirectionalLight2D (for sunlight or moonlight)

LightOccluder2D (for light shadow casters)

Other 2D nodes that receive lighting, such as Sprite2D or TileMapLayer.

CanvasModulate is used to darken the scene by specifying a color that will act as the base "ambient" color. This is the final lighting color in areas that are not reached by any 2D light. Without a CanvasModulate node, the final scene would look too bright as 2D lights would only brighten the existing unshaded appearance (which appears fully lit).

Sprite2Ds are used to display the textures for the light blobs, the background, and for the shadow casters.

PointLight2Ds are used to light the scene. The way a light typically works is by adding a selected texture over the rest of the scene to simulate lighting.

LightOccluder2Ds are used to tell the shader which parts of the scene cast shadows. These occluders can be placed as independent nodes or can be part of a TileMapLayer node.

The shadows appear only on areas covered by the PointLight2D and their direction is based on the center of the Light.

The background color does not receive any lighting. If you want light to be cast on the background, you need to add a visual representation for the background, such as a Sprite2D.

The Sprite2D's Region properties can be helpful to quickly create a repeating background texture, but remember to also set Texture > Repeat to Enabled in the Sprite2D's properties.

Point lights (also called positional lights) are the most common element in 2D lighting. Point lights can be used to represent light from torches, fire, projectiles, etc.

PointLight2D offers the following properties to tweak in the inspector:

Texture: The texture to use as a light source. The texture's size determines the size of the light. The texture may have an alpha channel, which is useful when using Light2D's Mix blend mode, but it is not required if using the Add (default) or Subtract blend modes.

Offset: The offset for the light texture. Unlike when you move the light node, changing the offset does not cause shadows to move.

Texture Scale: The multiplier for the light's size. Higher values will make the light extend out further. Larger lights have a higher performance cost as they affect more pixels on screen, so consider this before increasing a light's size.

Height: The light's virtual height with regards to normal mapping. By default, the light is very close to surfaces receiving lights. This will make lighting hardly visible if normal mapping is used, so consider increasing this value. Adjusting the light's height only makes a visible difference on surfaces that use normal mapping.

If you don't have a pre-made texture to use in a light, you can use this "neutral" point light texture (right-click > Save Image As…):

Neutral point light texture

If you need different falloff, you can procedurally create a texture by assigning a New GradientTexture2D on the light's Texture property. After creating the resource, expand its Fill section and set the fill mode to Radial. You will then have to adjust the gradient itself to start from opaque white to transparent white, and move its starting location to be in the center.

New in Godot 4.0 is the ability to have directional lighting in 2D. Directional lighting is used to represent sunlight or moonlight. Light rays are casted parallel to each other, as if the sun or moon was infinitely far away from the surface that is receiving the light.

DirectionalLight2D offers the following properties:

Height: The light's virtual height with regards to normal mapping (0.0 = parallel to surfaces, 1.0 = perpendicular to surfaces). By default, the light is fully parallel with the surfaces receiving lights. This will make lighting hardly visible if normal mapping is used, so consider increasing this value. Adjusting the light's height only makes a visual difference on surfaces that use normal mapping. Height does not affect shadows' appearance.

Max Distance: The maximum distance from the camera center objects can be before their shadows are culled (in pixels). Decreasing this value can prevent objects located outside the camera from casting shadows (while also improving performance). Camera2D zoom is not taken into account by Max Distance, which means that at higher zoom values, shadows will appear to fade out sooner when zooming onto a given point.

Directional shadows will always appear to be infinitely long, regardless of the value of the Height property. This is a limitation of the shadow rendering method used for 2D lights in Godot.

To have directional shadows that are not infinitely long, you should disable shadows in the DirectionalLight2D and use a custom shader that reads from the 2D signed distance field instead. This distance field is automatically generated from LightOccluder2D nodes present in the scene.

Both PointLight2D and DirectionalLight2D offer common properties, which are part of the Light2D base class:

Enabled: Allows toggling the light's visibility. Unlike hiding the light node, disabling this property will not hide the light's children.

Editor Only: If enabled, the light is only visible within the editor. It will be automatically disabled in the running project.

Color: The light's color.

Energy: The light's intensity multiplier. Higher values result in a brighter light.

Blend Mode: The blending formula used for light computations. The default Add is suited for most use cases. Subtract can be used for negative lights, which are not physically accurate but can be used for special effects. The Mix blend mode mixes the value of pixels corresponding to the light's texture with the values of pixels under it by linear interpolation.

Range > Z Min: The lowest Z index affected by the light.

Range > Z Max: The highest Z index affected by the light.

Range > Layer Min: The lowest visual layer affected by the light.

Range > Layer Max: The highest visual layer affected by the light.

Range > Item Cull Mask: Controls which nodes receive light from this node, depending on the other nodes' enabled visual layers Occluder Light Mask. This can be used to prevent certain objects from receiving light.

After enabling the Shadow > Enabled property on a PointLight2D or DirectionalLight2D node, you will not see any visual difference initially. This is because no nodes in your scene have any occluders yet, which are used as a basis for shadow casting.

For shadows to appear in the scene, LightOccluder2D nodes must be added to the scene. These nodes must also have occluder polygons that are designed to match the sprite's outline.

Along with their polygon resource (which must be set to have any visual effect), LightOccluder2D nodes have 2 properties:

SDF Collision: If enabled, the occluder will be part of a real-time generated signed distance field that can be used in custom shaders. When not using custom shaders that read from this SDF, enabling this makes no visual difference and has no performance cost, so this is enabled by default for convenience.

Occluder Light Mask: This is used in tandem with PointLight2D and DirectionalLight2D's Shadow > Item Cull Mask property to control which objects cast shadows for each light. This can be used to prevent specific objects from casting shadows.

There are two ways to create light occluders:

Occluders can be created automatically from Sprite2D nodes by selecting the node, clicking the Sprite2D menu at the top of the 2D editor then choosing Create LightOccluder2D Sibling.

In the dialog that appears, an outline will surround your sprite's edges. If the outline matches the sprite's edges closely, you can click OK. If the outline is too far away from the sprite's edges (or is "eating" into the sprite's edges), adjust Grow (pixels) and Shrink (pixels), then click Update Preview. Repeat this operation until you get satisfactory results.

Create a LightOccluder2D node, then select the node and click the "+" button at the top of the 2D editor. When asked to create a polygon resource, answer Yes. You can then start drawing an occluder polygon by clicking to create new points. You can remove existing points by right-clicking them, and you can create new points from the existing line by clicking on the line then dragging.

The following properties can be adjusted on 2D lights that have shadows enabled:

Color: The color of shaded areas. By default, shaded areas are fully black, but this can be changed for artistic purposes. The color's alpha channel controls how much the shadow is tinted by the specified color.

Filter: The filter mode to use for shadows. The default None is the fastest to render, and is well suited for games with a pixel art aesthetic (due to its "blocky" visuals). If you want a soft shadow, use PCF5 instead. PCF13 is even softer, but is the most demanding to render. PCF13 should only be used for a few lights at once due to its high rendering cost.

Filter Smooth: Controls how much softening is applied to shadows when Filter is set to PCF5 or PCF13. Higher values result in a softer shadow, but may cause banding artifacts to be visible (especially with PCF5).

Item Cull Mask: Controls which LightOccluder2D nodes cast shadows, depending on their respective Occluder Light Mask properties.

Soft shadows (PCF13, Filter Smooth 1.5)

Soft shadows with streaking artifacts due to Filter Smooth being too high (PCF5, Filter Smooth 4)

Normal maps and specular maps can greatly enhance the sense of depth of your 2D lighting. Similar to how these work in 3D rendering, normal maps can help make lighting look less flat by varying its intensity depending on the direction of the surface receiving light (on a per-pixel basis). Specular maps further help improve visuals by making some of the light reflect back to the viewer.

Both PointLight2D and DirectionalLight2D support normal mapping and specular mapping. Since Godot 4.0, normal and specular maps can be assigned to any 2D element, including nodes that inherit from Node2D or Control.

A normal map represents the direction in which each pixel is "pointing" towards. This information is then used by the engine to correctly apply lighting to 2D surfaces in a physically plausible way. Normal maps are typically created from hand-painted height maps, but they can also be automatically generated from other textures.

A specular map defines how much each pixel should reflect light (and in which color, if the specular map contains color). Brighter values will result in a brighter reflection at that given spot on the texture. Specular maps are typically created with manual editing, using the diffuse texture as a base.

If you don't have normal or specular maps for your sprites, you can generate them using the free and open source Laigter tool.

To set up normal maps and/or specular maps on a 2D node, create a new CanvasTexture resource for the property that draws the node's texture. For example, on a Sprite2D:

Creating a CanvasTexture resource for a Sprite2D node

Expand the newly created resource. You can find several properties you will need to adjust:

Diffuse > Texture: The base color texture. In this property, load the texture you're using for the sprite itself.

Normal Map > Texture: The normal map texture. In this property, load a normal map texture you've generated from a height map (see the tip above).

Specular > Texture: The specular map texture, which controls the specular intensity of each pixel on the diffuse texture. The specular map is usually grayscale, but it can also contain color to multiply the color of reflections accordingly. In this property, load a specular map texture you've created (see the tip above).

Specular > Color: The color multiplier for specular reflections.

Specular > Shininess: The specular exponent to use for reflections. Lower values will increase the brightness of reflections and make them more diffuse, while higher values will make reflections more localized. High values are more suited for wet-looking surfaces.

Texture > Filter: Can be set to override the texture filtering mode, regardless of what the node's property is set to (or the Rendering > Textures > Canvas Textures > Default Texture Filter project setting).

Texture > Repeat: Can be set to override the texture filtering mode, regardless of what the node's property is set to (or the Rendering > Textures > Canvas Textures > Default Texture Repeat project setting).

After enabling normal mapping, you may notice that your lights appear to be weaker. To resolve this, increase the Height property on your PointLight2D and DirectionalLight2D nodes. You may also want to increase the lights's Energy property slightly to get closer to how your lighting's intensity looked prior to enabling normal mapping.

If you run into performance issues when using 2D lights, it may be worth replacing some of them with Sprite2D nodes that use additive blending. This is particularly suited for short-lived dynamic effects, such as bullets or explosions.

Additive sprites are much faster to render, since they don't need to go through a separate rendering pipeline. Additionally, it is possible to use this approach with AnimatedSprite2D (or Sprite2D + AnimationPlayer), which allows for animated 2D "lights" to be created.

However, additive sprites have a few downsides compared to 2D lights:

The blending formula is inaccurate compared to "actual" 2D lighting. This is usually not a problem in sufficiently lit areas, but this prevents additive sprites from correctly lighting up areas that are fully dark.

Additive sprites cannot cast shadows, since they are not lights.

Additive sprites ignore normal and specular maps used on other sprites.

To display a sprite with additive blending, create a Sprite2D node and assign a texture to it. In the inspector, scroll down to the CanvasItem > Material section, unfold it and click the dropdown next to the Material property. Choose New CanvasItemMaterial, click the newly created material to edit it, then set Blend Mode to Add.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D meshes — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/2d_meshes.html

**Contents:**
- 2D meshes
- Introduction
- Optimizing pixels drawn
- Converting Sprite2Ds to 2D meshes
- User-contributed notes

The content of this page was not yet updated for Godot 4.5 and may be outdated. If you know how to improve this page or you can confirm that it's up to date, feel free to open a pull request.

In 3D, meshes are used to display the world. In 2D, they are rare as images are used more often. Godot's 2D engine is a pure two-dimensional engine, so it can't really display 3D meshes directly (although it can be done via Viewport and ViewportTexture).

If you are interested in displaying 3D meshes on a 2D viewport, see the Using a SubViewport as a texture tutorial.

2D meshes are meshes that contain two-dimensional geometry (Z can be omitted or ignored) instead of 3D. You can experiment creating them yourself using SurfaceTool from code and displaying them in a MeshInstance2D node.

Currently, the only way to generate a 2D mesh within the editor is by either importing an OBJ file as a mesh, or converting it from a Sprite2D.

This workflow is useful for optimizing 2D drawing in some situations. When drawing large images with transparency, Godot will draw the whole quad to the screen. The large transparent areas will still be drawn.

This can affect performance, especially on mobile devices, when drawing very large images (generally screen sized), or layering multiple images on top of each other with large transparent areas (for example, when using ParallaxBackground).

Converting to a mesh will ensure that only the opaque parts will be drawn and the rest will be ignored.

You can take advantage of this optimization by converting a Sprite2D to a MeshInstance2D. Start with an image that contains large amounts of transparency on the edges, like this tree:

Put it in a Sprite2D and select "Convert to 2D Mesh" from the menu:

A dialog will appear, showing a preview of how the 2D mesh will be created:

The default values are good enough for many cases, but you can change growth and simplification according to your needs:

Finally, push the Convert 2D Mesh button and your Sprite2D will be replaced:

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D movement overview — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/2d_movement.html

**Contents:**
- 2D movement overview
- Introduction
- Setup
- 8-way movement
- Rotation + movement
- Rotation + movement (mouse)
- Click-and-move
- Summary
- User-contributed notes

Every beginner has been there: "How do I move my character?" Depending on the style of game you're making, you may have special requirements, but in general the movement in most 2D games is based on a small number of designs.

We'll use CharacterBody2D for these examples, but the principles will apply to other node types (Area2D, RigidBody2D) as well.

Each example below uses the same scene setup. Start with a CharacterBody2D with two children: Sprite2D and CollisionShape2D. You can use the Godot icon ("icon.png") for the Sprite2D's texture or use any other 2D image you have.

Open Project -> Project Settings and select the "Input Map" tab. Add the following input actions (see InputEvent for details):

In this scenario, you want the user to press the four directional keys (up/left/down/right or W/A/S/D) and move in the selected direction. The name "8-way movement" comes from the fact that the player can move diagonally by pressing two keys at the same time.

Add a script to the character body and add the following code:

In the get_input() function, we use Input get_vector() to check for the four key events and sum return a direction vector.

We can then set our velocity by multiplying this direction vector, which has a length of 1, by our desired speed.

If you've never used vector math before, or need a refresher, you can see an explanation of vector usage in Godot at Vector math.

If the code above does nothing when you press the keys, double-check that you've set up input actions correctly as described in the Setup part of this tutorial.

This type of movement is sometimes called "Asteroids-style" because it resembles how that classic arcade game worked. Pressing left/right rotates the character, while up/down moves it forward or backward in whatever direction it's facing.

Here we've added two variables to track our rotation direction and speed. The rotation is applied directly to the body's rotation property.

To set the velocity, we use the body's transform.x which is a vector pointing in the body's "forward" direction, and multiply that by the speed.

This style of movement is a variation of the previous one. This time, the direction is set by the mouse position instead of the keyboard. The character will always "look at" the mouse pointer. The forward/back inputs remain the same, however.

Here we're using the Node2D look_at() method to point the player towards the mouse's position. Without this function, you could get the same effect by setting the angle like this:

This last example uses only the mouse to control the character. Clicking on the screen will cause the player to move to the target location.

Note the distance_to() check we make prior to movement. Without this test, the body would "jitter" upon reaching the target position, as it moves slightly past the position and tries to move back, only to move too far and repeat.

Uncommenting the look_at() line will also turn the body to point in its direction of motion if you prefer.

This technique can also be used as the basis of a "following" character. The target position can be that of any object you want to move to.

You may find these code samples useful as starting points for your own projects. Feel free to use them and experiment with them to see what you can make.

You can download this sample project here: 2d_movement_starter.zip

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (gdscript):
```gdscript
extends CharacterBody2D

@export var speed = 400

func get_input():
    var input_direction = Input.get_vector("left", "right", "up", "down")
    velocity = input_direction * speed

func _physics_process(delta):
    get_input()
    move_and_slide()
```

Example 2 (csharp):
```csharp
using Godot;

public partial class Movement : CharacterBody2D
{
    [Export]
    public int Speed { get; set; } = 400;

    public void GetInput()
    {

        Vector2 inputDirection = Input.GetVector("left", "right", "up", "down");
        Velocity = inputDirection * Speed;
    }

    public override void _PhysicsProcess(double delta)
    {
        GetInput();
        MoveAndSlide();
    }
}
```

Example 3 (gdscript):
```gdscript
extends CharacterBody2D

@export var speed = 400
@export var rotation_speed = 1.5

var rotation_direction = 0

func get_input():
    rotation_direction = Input.get_axis("left", "right")
    velocity = transform.x * Input.get_axis("down", "up") * speed

func _physics_process(delta):
    get_input()
    rotation += rotation_direction * rotation_speed * delta
    move_and_slide()
```

Example 4 (csharp):
```csharp
using Godot;

public partial class Movement : CharacterBody2D
{
    [Export]
    public int Speed { get; set; } = 400;

    [Export]
    public float RotationSpeed { get; set; } = 1.5f;

    private float _rotationDirection;

    public void GetInput()
    {
        _rotationDirection = Input.GetAxis("left", "right");
        Velocity = Transform.X * Input.GetAxis("down", "up") * Speed;
    }

    public override void _PhysicsProcess(double delta)
    {
        GetInput();
        Rotation += _rotationDirection * RotationSpeed * (float)delta;
        MoveAndSlide();
    }
}
```

---

## 2D Parallax — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/2d_parallax.html

**Contents:**
- 2D Parallax
- Introduction
- Getting started
- Scroll scale
- Infinite repeat
  - Poor sizing
    - Make the viewport smaller
    - Scale the Parallax2D
    - Scale the child nodes
    - Repeat the textures

Parallax is an effect used to simulate depth by having textures move at different speeds relative to the camera. Godot provides the Parallax2D node to achieve this effect. It can still be easy to get tripped up though, so this page provides in-depth descriptions of some properties and how to fix some common mistakes.

This page covers how to use Parallax2D, which is recommended to use over the ParallaxLayer and ParallaxBackground nodes.

The parallax node supports adding nodes that render things as children, so you can use one or many nodes to make up each layer. To begin, place each node or nodes you want to have scroll independently as a child of their own parallax node. Make sure that the top left of the textures used are at the (0, 0) crossing, like in the image below. See the section on positioning for why this is important.

The scene above uses one prepared texture for the higher clouds in a Sprite2D, but you could just as easily use multiple nodes spaced out to compose the layer.

The backbone of the parallax effect is the scroll_scale property. It works as a scroll-speed multiplier, allowing layers to move at a different speed than the camera for each axis set. A value of 1 makes the parallax node scroll at the same speed as the camera. If you want your image to look further away when scrolling, use a value lower than 1, with 0 bringing it to a complete stop. If you want something to appear closer to the camera, use a value higher than 1, making it scroll faster.

The scene above is comprised of five layers. Some good scroll_scale values might be:

(0.3, 1) - Lower Clouds

(0.2, 1) - Higher Clouds

The video below displays how these values affect scrolling while in-game:

Parallax2D provides a bonus effect that gives textures the illusion of repeating infinitely. repeat_size tells the node to snap its position forward or back when the camera scrolls by the set value. This effect is achieved by adding a single repeat to all the child canvas items offset by the value. While the camera scrolls between the image and its repeat, it invisibly snaps back giving the appearance of a looping image.

Being a delicate effect, it's easy for unfamiliar users to make mistakes with their setup. Let's go over the "how" and "why" of a few common problems users encounter.

The infinite repeat effect is easiest to work with when you have an image designed to repeat seamlessly and is the same size or larger than your viewport before setting the repeat_size. If you aren't able to obtain assets that are designed for this task, there are some other things you can do to better prepare your image in regards to size.

Here is an example of a texture that is too small for its viewport:

We can see that the viewport size is 500x300 but the texture is 288x208. If we set the repeat_size to the size of our image, the infinite repeat effect doesn't scroll properly because the original texture doesn't cover the viewport. If we set the repeat_size to the size of the viewport, we have a large gap. What can we do?

The simplest answer is to make the viewport the same size or smaller than your textures. In Project Settings > Display > Window, change the Viewport Width and Viewport Height settings to match your background.

If you're not aiming for a pixel-perfect style, or don't mind a little blurriness, you may opt to scale the textures larger to fit your screen. Set the scale of the Parallax2D, and all child textures scale with it.

Similar to scaling the Parallax2D, you can scale your Sprite2D nodes to be large enough to cover the screen. Keep in mind that some settings like Parallax2D.repeat_size and Sprite2D.region_rect do not take scaling into account, so it's necessary to adjust these values based on the scale.

You can also start off on the right foot by preparing child nodes earlier in the process. If you have a Sprite2D you'd like to repeat, but is too small, you can do the following to repeat it:

set texture_repeat to CanvasItem.TEXTURE_REPEAT_ENABLED

set region_enabled to true

set the region_rect to a multiple of the size of your texture large enough to cover the viewport.

Below, you can see that repeating the image twice makes it large enough to cover the screen.

It's common to see users mistakenly set all of their textures to be centered at (0,0):

This creates problems with the infinite repeat effect and should be avoided. The "infinite repeat canvas" starts at (0,0) and expands down and to the right to the size of the repeat_size value.

If the textures are centered on the (0,0) crossing, the infinite repeat canvas is only partly covered, so it only partly repeats.

Increasing repeat_times technically would work in some scenarios, but is a brute force solution and not the problem it is designed to solve (we'll go over this in a bit). A better fix is to understand how the repeat effect works and set up the parallax textures appropriately to begin with.

First, check to see if any textures are spilling over onto the negative parts of the canvas. Make sure the textures used in the parallax nodes fit inside the "infinite repeat canvas" starting at (0,0). That way, if Parallax2D.repeat_size is set correctly, it should look something like this, with one single loop of the image the same size or larger than the viewport:

If you think of how the image scrolls across the screen, it starts by displaying what's inside the red rectangle (determined by repeat_size), and when it reaches what's inside the yellow rectangle it zips the image forward to give the illusion of scrolling forever.

If you have the image positioned away from the "infinite repeat canvas", when the camera reaches the yellow rectangle, half of the image is cut off before it jumps forward like in the image below:

If your parallax textures are already working correctly, but you prefer it to start at a different point, Parallax2D comes with a scroll_offset property used to offset where the infinite repeat canvas starts. As an example, if your image is 288x208, setting the scroll_offset to (-144,0) or (144,0) allows it to begin halfway across the image.

Ideally, following this guide, your parallax textures are large enough to cover the screen even when zoomed out. Until now, we have had a perfectly fitting 288x208 texture inside of a 288x208 viewport. However, problems occur when we zoom out by setting the Camera2D.zoom to (0.5, 0.5):

Even though everything is correctly set for the viewport at the default zoom level, zooming out makes it smaller than the viewport, breaking the infinite repeat effect. This is where repeat_times can help out. Setting a value of 3 (one extra repeat behind and in front), it is now large enough to accommodate the infinite repeat effect.

If these textures were meant to be repeated vertically, we would have specified a y value for the repeat_size. The repeat_times would automatically add a repeat above and below as well. This is only a horizontal parallax, so it leaves an empty block above and below the image. How do we solve this? We need to get creative! In this example, we stretch the sky higher, and grass sprite lower. The textures now support the normal zoom level and zooming out to half size.

Most tutorials for making a split screen game in Godot begin by writing a small script to assign the Viewport.world_2d of the first SubViewport to the second, so they have a shared display. Questions often pop up about how to share a parallax effect between both screens.

The parallax effect fakes a perspective by moving the positions of different textures in relation to the camera. This is understandably problematic if you have multiple cameras, because your textures can't be in two places at once!

This is still achievable by cloning the parallax nodes into the second (or third or fourth) SubViewport. Here's how a setup looks for a two player game:

Of course, now both backgrounds show in both SubViewports. What we want is for each parallax to only show in their corresponding viewport. We can achieve this by doing the following:

Leave all parallax nodes at their default visibility_layer of 1.

Set the first SubViewport's canvas_cull_mask to only layers 1 and 2.

Do the same for the second SubViewport but use layers 1 and 3.

Give your parallax nodes in the first SubViewport a common parent and set its visibility_layer to 2.

Do the same for the second SubViewport's parallax nodes, but use a layer of 3.

How does this work? If a canvas item has a visibility_layer that doesn't match the SubViewport's canvas_cull_mask, it will hide all children, even if they do. We use this to our advantage, letting the SubViewports cut off rendering of parallax nodes whose parent doesn't have a supported visibility_layer.

Prior to 4.3, the recommendation was to place every layer in their own ParallaxBackground, enable the follow_viewport_enabled property, and scale the individual layer. This method has always been tricky to get right, but is still achievable by using a CanvasLayer instead of a ParallaxBackground.

Another recommendation is KoBeWi's "Parallax2D Preview" addon. It provides a few different preview modes and is very handy!

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D particle systems — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/particle_systems_2d.html

**Contents:**
- 2D particle systems
- Intro
  - Particle nodes
  - ParticleProcessMaterial
  - Texture
    - Using an animation flipbook
- Time parameters
  - Lifetime
  - One Shot
  - Preprocess

The content of this page was not yet updated for Godot 4.5 and may be outdated. If you know how to improve this page or you can confirm that it's up to date, feel free to open a pull request.

Particle systems are used to simulate complex physical effects, such as sparks, fire, magic particles, smoke, mist, etc.

The idea is that a "particle" is emitted at a fixed interval and with a fixed lifetime. During its lifetime, every particle will have the same base behavior. What makes each particle different from the rest and provides a more organic look is the "randomness" associated with each parameter. In essence, creating a particle system means setting base physics parameters and then adding randomness to them.

Godot provides two different nodes for 2D particles, GPUParticles2D and CPUParticles2D. GPUParticles2D is more advanced and uses the GPU to process particle effects. CPUParticles2D is a CPU-driven option with near-feature parity with GPUParticles2D, but lower performance when using large amounts of particles. On the other hand, CPUParticles2D may perform better on low-end systems or in GPU-bottlenecked situations.

While GPUParticles2D is configured via a ParticleProcessMaterial (and optionally with a custom shader), the matching options are provided via node properties in CPUParticles2D (with the exception of the trail settings).

Going forward there are no plans to add new features to CPUParticles2D, though pull requests to add features already in GPUParticles2D will be accepted. For that reason we recommend using GPUParticles2D unless you have an explicit reason not to.

You can convert a CPUParticles2D node into a GPUParticles2D node by clicking on the node in the scene tree, selecting the 2D workspace, and selecting CPUParticles2D > Convert to GPUParticles2D in the toolbar.

It is also possible to convert a GPUParticles2D node to a CPUParticles2D node, however there may be issues if you use GPU-only features.

The rest of this tutorial is going to use the GPUParticles2D node. First, add a GPUParticles2D node to your scene. After creating that node you will notice that only a white dot was created, and that there is a warning icon next to your GPUParticles2D node in the scene dock. This is because the node needs a ParticleProcessMaterial to function.

To add a process material to your particles node, go to Process Material in your inspector panel. Click on the box next to Material, and from the dropdown menu select New ParticleProcessMaterial.

Your GPUParticles2D node should now be emitting white points downward.

A particle system can use a single texture or an animation flipbook. A flipbook is a texture that contains several frames of animation that can be played back, or chosen at random during emission. This is equivalent to a spritesheet for particles.

The texture is set via the Texture property:

Particle flipbooks are suited to reproduce complex effects such as smoke, fire, explosions. They can also be used to introduce random texture variation, by making every particle use a different texture. You can find existing particle flipbook images online, or pre-render them using external tools such as Blender or EmberGen.

Example of a particle system that uses a flipbook texture

Using an animation flipbook requires additional configuration compared to a single texture. For demonstration purposes, we'll use this texture with 5 columns and 7 rows (right-click and choose Save as…):

Credit: JoesAlotofthings (CC BY 4.0)

To use an animation flipbook, you must create a new CanvasItemMaterial in the Material section of the GPUParticles2D (or CPUParticles2D) node:

Creating a CanvasItemMaterial at the bottom of the particles node inspector

In this CanvasItemMaterial, enable Particle Animation and set H Frames and V Frames to the number of columns and rows present in your flipbook texture:

Configuring the CanvasItemMaterial for the example flipbook texture

Once this is done, the Animation section in ParticleProcessMaterial (for GPUParticles2D) or in the CPUParticles2D inspector will be effective.

If your flipbook texture has a black background instead of a transparent background, you will also need to set the blend mode to Add instead of Mix for correct display. Alternatively, you can modify the texture to have a transparent background in an image editor. In GIMP, this can be done using the Color > Color to Alpha menu.

The time in seconds that every particle will stay alive. When lifetime ends, a new particle is created to replace it.

When enabled, a GPUParticles2D node will emit all of its particles once and then never again.

Particle systems begin with zero particles emitted, then start emitting. This can be an inconvenience when loading a scene and systems like a torch, mist, etc. begin emitting the moment you enter. Preprocess is used to let the system process a given number of seconds before it is actually drawn the first time.

The speed scale has a default value of 1 and is used to adjust the speed of a particle system. Lowering the value will make the particles slower while increasing the value will make the particles much faster.

If lifetime is 1 and there are 10 particles, it means a particle will be emitted every 0.1 seconds. The explosiveness parameter changes this, and forces particles to be emitted all together. Ranges are:

0: Emit particles at regular intervals (default value).

1: Emit all particles simultaneously.

Values in the middle are also allowed. This feature is useful for creating explosions or sudden bursts of particles:

All physics parameters can be randomized. Random values range from 0 to 1. The formula to randomize a parameter is:

This setting can be used to set the particle system to render at a fixed FPS. For instance, changing the value to 2 will make the particles render at 2 frames per second. Note this does not slow down the particle system itself.

Godot 4.3 does not currently support physics interpolation for 2D particles. As a workaround, disable physics interpolation for the particles node by setting Node > Physics Interpolation > Mode at the bottom of the inspector.

Setting Fract Delta to true results in fractional delta calculation, which has a smoother particles display effect. This increased smoothness stems from higher accuracy. The difference is more noticeable in systems with high randomness or fast-moving particles. It helps maintain the visual consistency of the particle system, making sure that each particle's motion aligns with its actual lifespan. Without it, particles might appear to jump or move more than they should in a single frame if they are emitted at a point within the frame. The greater accuracy has a performance tradeoff, particularly in systems with a higher amount of particles.

The visibility rectangle controls the visibility of the particles on screen. If this rectangle is outside of the viewport, the engine will not render the particles on screen.

The rectangle's W and H properties respectively control its Width and its Height. The X and Y properties control the position of the upper-left corner of the rectangle, relative to the particle emitter.

You can have Godot generate a Visibility Rect automatically using the toolbar above the 2d view. To do so, select the GPUParticles2D node and Click Particles > Generate Visibility Rect. Godot will simulate the Particles2D node emitting particles for a few seconds and set the rectangle to fit the surface the particles take.

You can control the emit duration with the Generation Time (sec) option. The maximum value is 25 seconds. If you need more time for your particles to move around, you can temporarily change the preprocess duration on the Particles2D node.

By default this option is on, and it means that the space that particles are emitted to is relative to the node. If the node is moved, all particles are moved with it:

If disabled, particles will emit to global space, meaning that if the node is moved, already emitted particles are not affected:

This controls the order in which individual particles are drawn. Index means particles are drawn according to their emission order (default). Lifetime means they are drawn in order of remaining lifetime.

For information on the settings in the ParticleProcessMaterial see this page.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
initial_value = param_value + param_value * randomness
```

---

## 2D skeletons — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/animation/2d_skeletons.html

**Contents:**
- 2D skeletons
- Introduction
- Setup
- Creating the polygons
- Creating the skeleton
- Deforming the polygons
- Internal vertices
- User-contributed notes

The content of this page was not yet updated for Godot 4.5 and may be outdated. If you know how to improve this page or you can confirm that it's up to date, feel free to open a pull request.

When working with 3D, skeletal deforms are common for characters and creatures and most 3D modeling applications support it. For 2D, as this function is not used as often, it's difficult to find mainstream software aimed for this.

One option is to create animations in third-party software such as Spine or Dragonbones. This functionality is also supported built-in.

Why would you want to do skeletal animations directly in Godot? The answer is that there are many advantages to it:

Better integration with the engine, so less hassle importing and editing from an external tool.

Ability to control particle systems, shaders, sounds, call scripts, colors, transparency, etc. in animations.

The built-in skeletal system in Godot is very efficient and designed for performance.

The following tutorial will, then, explain 2D skeletal deformations.

Before starting, we recommend you to go through the Cutout animation tutorial to gain a general understanding of animating within Godot.

For this tutorial, we will be using a single image to construct our character. Download it from gBot_pieces.png or save the image below.

It is also advised to download the final character image gBot_complete.png to have a good reference for putting the different pieces together.

Create a new scene for your model (if it's going to be an animated character, you may want to use a CharacterBody2D). For ease of use, an empty 2D node is created as a root for the polygons.

Begin with a Polygon2D node. There is no need to place it anywhere in the scene for now, so simply create it like this:

Select it and assign the texture with the character pieces you have downloaded before:

Drawing a polygon directly is not advised. Instead, open the "UV" dialog for the polygon:

Head over to the Points mode, select the pencil and draw a polygon around the desired piece:

Duplicate the polygon node and give it a proper name. Then, enter the "UV" dialog again and replace the old polygon with another one in the new desired piece.

When you duplicate nodes and the next piece has a similar shape, you can edit the previous polygon instead of drawing a new one.

After moving the polygon, remember to update the UV by selecting Edit > Copy Polygon to UV in the Polygon 2D UV Editor.

Keep doing this until you mapped all pieces.

You will notice that pieces for nodes appear in the same layout as they do in the original texture. This is because by default, when you draw a polygon, the UV and points are the same.

Rearrange the pieces and build the character. This should be pretty quick. There is no need to change pivots, so don't bother making sure rotation pivots for each piece are right; you can leave them be for now.

Ah, the visual order of the pieces is not correct yet, as some are covering wrong pieces. Rearrange the order of the nodes to fix this:

And there you go! It was definitely much easier than in the cutout tutorial.

Create a Skeleton2D node as a child of the root node. This will be the base of our skeleton:

Create a Bone2D node as a child of the skeleton. Put it on the hip (usually skeletons start here). The bone will be pointing to the right, but you can ignore this for now.

Keep creating bones in hierarchy and naming them accordingly.

At the end of this chain, there will be a jaw node. It is, again, very short and pointing to the right. This is normal for bones without children. The length of tip bones can be changed with a property in the inspector:

In this case, we don't need to rotate the bone (coincidentally the jaw points right in the sprite), but in case you need to, feel free to do it. Again, this is only really needed for tip bones as nodes with children don't usually need a length or a specific rotation.

Keep going and build the whole skeleton:

You will notice that all bones raise a warning about a missing rest pose. A rest pose is the default pose for a skeleton, you can come back to it anytime you want (which is very handy for animating). To set one click on the skeleton node in the scene tree, then click on the Skeleton2D button in the toolbar, and select Overwrite Rest Pose from the dropdown menu.

The warnings will go away. If you modify the skeleton (add/remove bones) you will need to set the rest pose again.

Select the previously created polygons and assign the skeleton node to their Skeleton property. This will ensure that they can eventually be deformed by it.

Click the property highlighted above and select the skeleton node:

Again, open the UV editor for the polygon and go to the Bones section.

You will not be able to paint weights yet. For this you need to synchronize the list of bones from the skeleton with the polygon. This step is done only once and manually (unless you modify the skeleton by adding/removing/renaming bones). It ensures that your rigging information is kept in the polygon, even if a skeleton node is accidentally lost or the skeleton modified. Push the "Sync Bones to Polygon" button to sync the list.

The list of bones will automatically appear. By default, your polygon has no weight assigned to any of them. Select the bones you want to assign weight to and paint them:

Points in white have a full weight assigned, while points in black are not influenced by the bone. If the same point is painted white for multiple bones, the influence will be distributed amongst them (so usually there is not that much need to use shades in-between unless you want to polish the bending effect).

After painting the weights, animating the bones (NOT the polygons!) will have the desired effect of modifying and bending the polygons accordingly. As you only need to animate bones in this approach, work becomes much easier!

But it's not all roses. Trying to animate bones that bend the polygon will often yield unexpected results:

This happens because Godot generates internal triangles that connect the points when drawing the polygon. They don't always bend the way you would expect. To solve this, you need to set hints in the geometry to clarify how you expect it to deform.

Open the UV menu for each bone again and go to the Points section. Add some internal vertices in the regions where you expect the geometry to bend:

Now, go to the Polygon section and redraw your own polygons with more detail. Imagine that, as your polygons bend, you need to make sure they deform the least possible, so experiment a bit to find the right setup.

Once you start drawing, the original polygon will disappear and you will be free to create your own:

This amount of detail is usually fine, though you may want to have more fine-grained control over where triangles go. Experiment by yourself until you get the results you like.

Note: Don't forget that your newly added internal vertices also need weight painting! Go to the Bones section again to assign them to the right bones.

Once you are all set, you will get much better results:

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## 2D sprite animation — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/2d_sprite_animation.html

**Contents:**
- 2D sprite animation
- Introduction
- Individual images with AnimatedSprite2D
  - Controlling the animation
- Sprite sheet with AnimatedSprite2D
- Sprite sheet with AnimationPlayer
  - Controlling an AnimationPlayer animation
- Summary
- User-contributed notes

In this tutorial, you'll learn how to create 2D animated characters with the AnimatedSprite2D class and the AnimationPlayer. Typically, when you create or download an animated character, it will come in one of two ways: as individual images or as a single sprite sheet containing all the animation's frames. Both can be animated in Godot with the AnimatedSprite2D class.

First, we'll use AnimatedSprite2D to animate a collection of individual images. Then we will animate a sprite sheet using this class. Finally, we will learn another way to animate a sprite sheet with AnimationPlayer and the Animation property of Sprite2D.

Art for the following examples by https://opengameart.org/users/ansimuz and tgfcoder.

In this scenario, you have a collection of images, each containing one of your character's animation frames. For this example, we'll use the following animation:

You can download the images here: 2d_sprite_animation_assets.zip

Unzip the images and place them in your project folder. Set up your scene tree with the following nodes:

The root node could also be Area2D or RigidBody2D. The animation will still be made in the same way. Once the animation is completed, you can assign a shape to the CollisionShape2D. See Physics Introduction for more information.

Now select the AnimatedSprite2D and in its SpriteFrames property, select "New SpriteFrames".

Click on the new SpriteFrames resource and you'll see a new panel appear at the bottom of the editor window:

From the FileSystem dock on the left side, drag the 8 individual images into the center part of the SpriteFrames panel. On the left side, change the name of the animation from "default" to "run".

Use the "Play" buttons on the top-right of the Filter Animations input to preview the animation. You should now see the animation playing in the viewport. However, it is a bit slow. To fix this, change the Speed (FPS) setting in the SpriteFrames panel to 10.

You can add additional animations by clicking the "Add Animation" button and adding additional images.

Once the animation is complete, you can control the animation via code using the play() and stop() methods. Here is a brief example to play the animation while the right arrow key is held, and stop it when the key is released.

You can also easily animate from a sprite sheet with the class AnimatedSprite2D. We will use this public domain sprite sheet:

Right-click the image and choose "Save Image As" to download it, and then copy the image into your project folder.

Set up your scene tree the same way you did previously when using individual images. Select the AnimatedSprite2D and in its SpriteFrames property, select "New SpriteFrames".

Click on the new SpriteFrames resource. This time, when the bottom panel appears, select "Add frames from a Sprite Sheet".

You will be prompted to open a file. Select your sprite sheet.

A new window will open, showing your sprite sheet. The first thing you will need to do is to change the number of vertical and horizontal images in your sprite sheet. In this sprite sheet, we have four images horizontally and two images vertically.

Next, select the frames from the sprite sheet that you want to include in your animation. We will select the top four, then click "Add 4 frames" to create the animation.

You will now see your animation under the list of animations in the bottom panel. Double click on default to change the name of the animation to jump.

Finally, check the play button on the SpriteFrames editor to see your frog jump!

Another way that you can animate when using a sprite sheet is to use a standard Sprite2D node to display the texture, and then animating the change from texture to texture with AnimationPlayer.

Consider this sprite sheet, which contains 6 frames of animation:

Right-click the image and choose "Save Image As" to download, then copy the image into your project folder.

Our goal is to display these images one after another in a loop. Start by setting up your scene tree:

The root node could also be Area2D or RigidBody2D. The animation will still be made in the same way. Once the animation is completed, you can assign a shape to the CollisionShape2D. See Physics Introduction for more information.

Drag the spritesheet into the Sprite's Texture property, and you'll see the whole sheet displayed on the screen. To slice it up into individual frames, expand the Animation section in the Inspector and set the Hframes to 6. Hframes and Vframes are the number of horizontal and vertical frames in your sprite sheet.

Now try changing the value of the Frame property. You'll see that it ranges from 0 to 5 and the image displayed by the Sprite2D changes accordingly. This is the property we'll be animating.

Select the AnimationPlayer and click the "Animation" button followed by "New". Name the new animation "walk". Set the animation length to 0.6 and click the "Loop" button so that our animation will repeat.

Now select the Sprite2D node and click the key icon to add a new track.

Continue adding frames at each point in the timeline (0.1 seconds by default), until you have all the frames from 0 to 5. You'll see the frames actually appearing in the animation track:

Press "Play" on the animation to see how it looks.

Like with AnimatedSprite2D, you can control the animation via code using the play() and stop() methods. Again, here is an example to play the animation while the right arrow key is held, and stop it when the key is released.

If updating both an animation and a separate property at once (for example, a platformer may update the sprite's h_flip/v_flip properties when a character turns while starting a 'turning' animation), it's important to keep in mind that play() isn't applied instantly. Instead, it's applied the next time the AnimationPlayer is processed. This may end up being on the next frame, causing a 'glitch' frame, where the property change was applied, but the animation was not. If this turns out to be a problem, after calling play(), you can call advance(0) to update the animation immediately.

These examples illustrate the two classes you can use in Godot for 2D animation. AnimationPlayer is a bit more complex than AnimatedSprite2D, but it provides additional functionality, since you can also animate other properties like position or scale. The class AnimationPlayer can also be used with an AnimatedSprite2D. Experiment to see what works best for your needs.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (gdscript):
```gdscript
extends CharacterBody2D

@onready var _animated_sprite = $AnimatedSprite2D

func _process(_delta):
    if Input.is_action_pressed("ui_right"):
        _animated_sprite.play("run")
    else:
        _animated_sprite.stop()
```

Example 2 (unknown):
```unknown
using Godot;

public partial class Character : CharacterBody2D
{
    private AnimatedSprite2D _animatedSprite;

    public override void _Ready()
    {
        _animatedSprite = GetNode<AnimatedSprite2D>("AnimatedSprite2D");
    }

    public override void _Process(double delta)
    {
        if (Input.IsActionPressed("ui_right"))
        {
            _animatedSprite.Play("run");
        }
        else
        {
            _animatedSprite.Stop();
        }
    }
}
```

Example 3 (gdscript):
```gdscript
extends CharacterBody2D

@onready var _animation_player = $AnimationPlayer

func _process(_delta):
    if Input.is_action_pressed("ui_right"):
        _animation_player.play("walk")
    else:
        _animation_player.stop()
```

Example 4 (unknown):
```unknown
using Godot;

public partial class Character : CharacterBody2D
{
    private AnimationPlayer _animationPlayer;

    public override void _Ready()
    {
        _animationPlayer = GetNode<AnimationPlayer>("AnimationPlayer");
    }

    public override void _Process(double delta)
    {
        if (Input.IsActionPressed("ui_right"))
        {
            _animationPlayer.Play("walk");
        }
        else
        {
            _animationPlayer.Stop();
        }
    }
}
```

---

## AnimatableBody2D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_animatablebody2d.html

**Contents:**
- AnimatableBody2D
- Description
- Tutorials
- Properties
- Property Descriptions
- User-contributed notes

Inherits: StaticBody2D < PhysicsBody2D < CollisionObject2D < Node2D < CanvasItem < Node < Object

A 2D physics body that can't be moved by external forces. When moved manually, it affects other bodies in its path.

An animatable 2D physics body. It can't be moved by external forces or contacts, but can be moved manually by other means such as code, AnimationMixers (with AnimationMixer.callback_mode_process set to AnimationMixer.ANIMATION_CALLBACK_MODE_PROCESS_PHYSICS), and RemoteTransform2D.

When AnimatableBody2D is moved, its linear and angular velocity are estimated and used to affect other physics bodies in its path. This makes it useful for moving platforms, doors, and other moving objects.

Troubleshooting physics issues

bool sync_to_physics = true 🔗

void set_sync_to_physics(value: bool)

bool is_sync_to_physics_enabled()

If true, the body's movement will be synchronized to the physics frame. This is useful when animating movement via AnimationPlayer, for example on moving platforms. Do not use together with PhysicsBody2D.move_and_collide().

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## AnimatedSprite2D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_animatedsprite2d.html

**Contents:**
- AnimatedSprite2D
- Description
- Tutorials
- Properties
- Methods
- Signals
- Property Descriptions
- Method Descriptions
- User-contributed notes

Inherits: Node2D < CanvasItem < Node < Object

Sprite node that contains multiple textures as frames to play for animation.

AnimatedSprite2D is similar to the Sprite2D node, except it carries multiple textures as animation frames. Animations are created using a SpriteFrames resource, which allows you to import image files (or a folder containing said files) to provide the animation frames for the sprite. The SpriteFrames resource can be configured in the editor via the SpriteFrames bottom panel.

2D Dodge The Creeps Demo

get_playing_speed() const

play(name: StringName = &"", custom_speed: float = 1.0, from_end: bool = false)

play_backwards(name: StringName = &"")

set_frame_and_progress(frame: int, progress: float)

animation_changed() 🔗

Emitted when animation changes.

animation_finished() 🔗

Emitted when the animation reaches the end, or the start if it is played in reverse. When the animation finishes, it pauses the playback.

Note: This signal is not emitted if an animation is looping.

Emitted when the animation loops.

Emitted when frame changes.

sprite_frames_changed() 🔗

Emitted when sprite_frames changes.

StringName animation = &"default" 🔗

void set_animation(value: StringName)

StringName get_animation()

The current animation from the sprite_frames resource. If this value is changed, the frame counter and the frame_progress are reset.

String autoplay = "" 🔗

void set_autoplay(value: String)

String get_autoplay()

The key of the animation to play when the scene loads.

bool centered = true 🔗

void set_centered(value: bool)

If true, texture will be centered.

Note: For games with a pixel art aesthetic, textures may appear deformed when centered. This is caused by their position being between pixels. To prevent this, set this property to false, or consider enabling ProjectSettings.rendering/2d/snap/snap_2d_vertices_to_pixel and ProjectSettings.rendering/2d/snap/snap_2d_transforms_to_pixel.

bool flip_h = false 🔗

void set_flip_h(value: bool)

If true, texture is flipped horizontally.

bool flip_v = false 🔗

void set_flip_v(value: bool)

If true, texture is flipped vertically.

void set_frame(value: int)

The displayed animation frame's index. Setting this property also resets frame_progress. If this is not desired, use set_frame_and_progress().

float frame_progress = 0.0 🔗

void set_frame_progress(value: float)

float get_frame_progress()

The progress value between 0.0 and 1.0 until the current frame transitions to the next frame. If the animation is playing backwards, the value transitions from 1.0 to 0.0.

Vector2 offset = Vector2(0, 0) 🔗

void set_offset(value: Vector2)

The texture's drawing offset.

float speed_scale = 1.0 🔗

void set_speed_scale(value: float)

float get_speed_scale()

The speed scaling ratio. For example, if this value is 1, then the animation plays at normal speed. If it's 0.5, then it plays at half speed. If it's 2, then it plays at double speed.

If set to a negative value, the animation is played in reverse. If set to 0, the animation will not advance.

SpriteFrames sprite_frames 🔗

void set_sprite_frames(value: SpriteFrames)

SpriteFrames get_sprite_frames()

The SpriteFrames resource containing the animation(s). Allows you the option to load, edit, clear, make unique and save the states of the SpriteFrames resource.

float get_playing_speed() const 🔗

Returns the actual playing speed of current animation or 0 if not playing. This speed is the speed_scale property multiplied by custom_speed argument specified when calling the play() method.

Returns a negative value if the current animation is playing backwards.

bool is_playing() const 🔗

Returns true if an animation is currently playing (even if speed_scale and/or custom_speed are 0).

Pauses the currently playing animation. The frame and frame_progress will be kept and calling play() or play_backwards() without arguments will resume the animation from the current playback position.

void play(name: StringName = &"", custom_speed: float = 1.0, from_end: bool = false) 🔗

Plays the animation with key name. If custom_speed is negative and from_end is true, the animation will play backwards (which is equivalent to calling play_backwards()).

If this method is called with that same animation name, or with no name parameter, the assigned animation will resume playing if it was paused.

void play_backwards(name: StringName = &"") 🔗

Plays the animation with key name in reverse.

This method is a shorthand for play() with custom_speed = -1.0 and from_end = true, so see its description for more information.

void set_frame_and_progress(frame: int, progress: float) 🔗

Sets frame and frame_progress to the given values. Unlike setting frame, this method does not reset the frame_progress to 0.0 implicitly.

Example: Change the animation while keeping the same frame and frame_progress:

Stops the currently playing animation. The animation position is reset to 0 and the custom_speed is reset to 1.0. See also pause().

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
var current_frame = animated_sprite.get_frame()
var current_progress = animated_sprite.get_frame_progress()
animated_sprite.play("walk_another_skin")
animated_sprite.set_frame_and_progress(current_frame, current_progress)
```

---

## AnimatedSprite3D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_animatedsprite3d.html

**Contents:**
- AnimatedSprite3D
- Description
- Tutorials
- Properties
- Methods
- Signals
- Property Descriptions
- Method Descriptions
- User-contributed notes

Inherits: SpriteBase3D < GeometryInstance3D < VisualInstance3D < Node3D < Node < Object

2D sprite node in 3D world, that can use multiple 2D textures for animation.

AnimatedSprite3D is similar to the Sprite3D node, except it carries multiple textures as animation sprite_frames. Animations are created using a SpriteFrames resource, which allows you to import image files (or a folder containing said files) to provide the animation frames for the sprite. The SpriteFrames resource can be configured in the editor via the SpriteFrames bottom panel.

2D Sprite animation (also applies to 3D)

get_playing_speed() const

play(name: StringName = &"", custom_speed: float = 1.0, from_end: bool = false)

play_backwards(name: StringName = &"")

set_frame_and_progress(frame: int, progress: float)

animation_changed() 🔗

Emitted when animation changes.

animation_finished() 🔗

Emitted when the animation reaches the end, or the start if it is played in reverse. When the animation finishes, it pauses the playback.

Note: This signal is not emitted if an animation is looping.

Emitted when the animation loops.

Emitted when frame changes.

sprite_frames_changed() 🔗

Emitted when sprite_frames changes.

StringName animation = &"default" 🔗

void set_animation(value: StringName)

StringName get_animation()

The current animation from the sprite_frames resource. If this value is changed, the frame counter and the frame_progress are reset.

String autoplay = "" 🔗

void set_autoplay(value: String)

String get_autoplay()

The key of the animation to play when the scene loads.

void set_frame(value: int)

The displayed animation frame's index. Setting this property also resets frame_progress. If this is not desired, use set_frame_and_progress().

float frame_progress = 0.0 🔗

void set_frame_progress(value: float)

float get_frame_progress()

The progress value between 0.0 and 1.0 until the current frame transitions to the next frame. If the animation is playing backwards, the value transitions from 1.0 to 0.0.

float speed_scale = 1.0 🔗

void set_speed_scale(value: float)

float get_speed_scale()

The speed scaling ratio. For example, if this value is 1, then the animation plays at normal speed. If it's 0.5, then it plays at half speed. If it's 2, then it plays at double speed.

If set to a negative value, the animation is played in reverse. If set to 0, the animation will not advance.

SpriteFrames sprite_frames 🔗

void set_sprite_frames(value: SpriteFrames)

SpriteFrames get_sprite_frames()

The SpriteFrames resource containing the animation(s). Allows you the option to load, edit, clear, make unique and save the states of the SpriteFrames resource.

float get_playing_speed() const 🔗

Returns the actual playing speed of current animation or 0 if not playing. This speed is the speed_scale property multiplied by custom_speed argument specified when calling the play() method.

Returns a negative value if the current animation is playing backwards.

bool is_playing() const 🔗

Returns true if an animation is currently playing (even if speed_scale and/or custom_speed are 0).

Pauses the currently playing animation. The frame and frame_progress will be kept and calling play() or play_backwards() without arguments will resume the animation from the current playback position.

void play(name: StringName = &"", custom_speed: float = 1.0, from_end: bool = false) 🔗

Plays the animation with key name. If custom_speed is negative and from_end is true, the animation will play backwards (which is equivalent to calling play_backwards()).

If this method is called with that same animation name, or with no name parameter, the assigned animation will resume playing if it was paused.

void play_backwards(name: StringName = &"") 🔗

Plays the animation with key name in reverse.

This method is a shorthand for play() with custom_speed = -1.0 and from_end = true, so see its description for more information.

void set_frame_and_progress(frame: int, progress: float) 🔗

Sets frame and frame_progress to the given values. Unlike setting frame, this method does not reset the frame_progress to 0.0 implicitly.

Example: Change the animation while keeping the same frame and frame_progress:

Stops the currently playing animation. The animation position is reset to 0 and the custom_speed is reset to 1.0. See also pause().

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
var current_frame = animated_sprite.get_frame()
var current_progress = animated_sprite.get_frame_progress()
animated_sprite.play("walk_another_skin")
animated_sprite.set_frame_and_progress(current_frame, current_progress)
```

---

## Animating thousands of fish with MultiMeshInstance3D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/performance/vertex_animation/animating_thousands_of_fish.html

**Contents:**
- Animating thousands of fish with MultiMeshInstance3D
- Animating one Fish
- Making a school of fish
- Animating a school of fish
- User-contributed notes

The content of this page was not yet updated for Godot 4.5 and may be outdated. If you know how to improve this page or you can confirm that it's up to date, feel free to open a pull request.

This tutorial explores a technique used in the game ABZU for rendering and animating thousands of fish using vertex animation and static mesh instancing.

In Godot, this can be accomplished with a custom Shader and a MultiMeshInstance3D. Using the following technique you can render thousands of animated objects, even on low-end hardware.

We will start by animating one fish. Then, we will see how to extend that animation to thousands of fish.

We will start with a single fish. Load your fish model into a MeshInstance3D and add a new ShaderMaterial.

Here is the fish we will be using for the example images, you can use any fish model you like.

The fish model in this tutorial is made by QuaterniusDev and is shared with a creative commons license. CC0 1.0 Universal (CC0 1.0) Public Domain Dedication https://creativecommons.org/publicdomain/zero/1.0/

Typically, you would use bones and a Skeleton3D to animate objects. However, bones are animated on the CPU and so you end having to calculate thousands of operations every frame and it becomes impossible to have thousands of objects. Using vertex animation in a vertex shader, you avoid using bones and can instead calculate the full animation in a few lines of code and completely on the GPU.

The animation will be made of four key motions:

A side to side motion

A pivot motion around the center of the fish

A panning wave motion

A panning twist motion

All the code for the animation will be in the vertex shader with uniforms controlling the amount of motion. We use uniforms to control the strength of the motion so that you can tweak the animation in editor and see the results in real time, without the shader having to recompile.

All the motions will be made using cosine waves applied to VERTEX in model space. We want the vertices to be in model space so that the motion is always relative to the orientation of the fish. For example, side-to-side will always move the fish back and forth in its left to right direction, instead of on the x axis in the world orientation.

In order to control the speed of the animation, we will start by defining our own time variable using TIME.

The first motion we will implement is the side to side motion. It can be made by offsetting VERTEX.x by cos of TIME. Each time the mesh is rendered, all the vertices will move to the side by the amount of cos(time).

The resulting animation should look something like this:

Next, we add the pivot. Because the fish is centered at (0, 0), all we have to do is multiply VERTEX by a rotation matrix for it to rotate around the center of the fish.

We construct a rotation matrix like so:

And then we apply it in the x and z axes by multiplying it by VERTEX.xz.

With only the pivot applied you should see something like this:

The next two motions need to pan down the spine of the fish. For that, we need a new variable, body. body is a float that is 0 at the tail of the fish and 1 at its head.

The next motion is a cosine wave that moves down the length of the fish. To make it move along the spine of the fish, we offset the input to cos by the position along the spine, which is the variable we defined above, body.

This looks very similar to the side to side motion we defined above, but in this one, by using body to offset cos each vertex along the spine has a different position in the wave making it look like a wave is moving along the fish.

The last motion is the twist, which is a panning roll along the spine. Similarly to the pivot, we first construct a rotation matrix.

We apply the rotation in the xy axes so that the fish appears to roll around its spine. For this to work, the fish's spine needs to be centered on the z axis.

Here is the fish with twist applied:

If we apply all these motions one after another, we get a fluid jelly-like motion.

Normal fish swim mostly with the back half of their body. Accordingly, we need to limit the panning motions to the back half of the fish. To do this, we create a new variable, mask.

mask is a float that goes from 0 at the front of the fish to 1 at the end using smoothstep to control the point at which the transition from 0 to 1 happens.

Below is an image of the fish with mask used as COLOR:

For the wave, we multiply the motion by mask which will limit it to the back half.

In order to apply the mask to the twist, we use mix. mix allows us to mix the vertex position between a fully rotated vertex and one that is not rotated. We need to use mix instead of multiplying mask by the rotated VERTEX because we are not adding the motion to the VERTEX we are replacing the VERTEX with the rotated version. If we multiplied that by mask, we would shrink the fish.

Putting the four motions together gives us the final animation.

Go ahead and play with the uniforms in order to alter the swim cycle of the fish. You will find that you can create a wide variety of swim styles using these four motions.

Godot makes it easy to render thousands of the same object using a MultiMeshInstance3D node.

A MultiMeshInstance3D node is created and used the same way you would make a MeshInstance3D node. For this tutorial, we will name the MultiMeshInstance3D node School, because it will contain a school of fish.

Once you have a MultiMeshInstance3D add a MultiMesh, and to that MultiMesh add your Mesh with the shader from above.

MultiMeshes draw your Mesh with three additional per-instance properties: Transform (rotation, translation, scale), Color, and Custom. Custom is used to pass in 4 multi-use variables using a Color.

instance_count specifies how many instances of the mesh you want to draw. For now, leave instance_count at 0 because you cannot change any of the other parameters while instance_count is larger than 0. We will set instance count in GDScript later.

transform_format specifies whether the transforms used are 3D or 2D. For this tutorial, select 3D.

For both color_format and custom_data_format you can choose between None, Byte, and Float. None means you won't be passing in that data (either a per-instance COLOR variable, or INSTANCE_CUSTOM) to the shader. Byte means each number making up the color you pass in will be stored with 8 bits while Float means each number will be stored in a floating-point number (32 bits). Float is slower but more precise, Byte will take less memory and be faster, but you may see some visual artifacts.

Now, set instance_count to the number of fish you want to have.

Next we need to set the per-instance transforms.

There are two ways to set per-instance transforms for MultiMeshes. The first is entirely in editor and is described in the MultiMeshInstance3D tutorial.

The second is to loop over all the instances and set their transforms in code. Below, we use GDScript to loop over all the instances and set their transform to a random position.

Running this script will place the fish in random positions in a box around the position of the MultiMeshInstance3D.

If performance is an issue for you, try running the scene with fewer fish.

Notice how all the fish are all in the same position in their swim cycle? It makes them look very robotic. The next step is to give each fish a different position in the swim cycle so the entire school looks more organic.

One of the benefits of animating the fish using cos functions is that they are animated with one parameter, time. In order to give each fish a unique position in the swim cycle, we only need to offset time.

We do that by adding the per-instance custom value INSTANCE_CUSTOM to time.

Next, we need to pass a value into INSTANCE_CUSTOM. We do that by adding one line into the for loop from above. In the for loop we assign each instance a set of four random floats to use.

Now the fish all have unique positions in the swim cycle. You can give them a little more individuality by using INSTANCE_CUSTOM to make them swim faster or slower by multiplying by TIME.

You can even experiment with changing the per-instance color the same way you changed the per-instance custom value.

One problem that you will run into at this point is that the fish are animated, but they are not moving. You can move them by updating the per-instance transform for each fish every frame. Although doing so will be faster than moving thousands of MeshInstance3Ds per frame, it'll still likely be slow.

In the next tutorial we will cover how to use GPUParticles3D to take advantage of the GPU and move each fish around individually while still receiving the benefits of instancing.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
//time_scale is a uniform float
float time = TIME * time_scale;
```

Example 2 (unknown):
```unknown
//side_to_side is a uniform float
VERTEX.x += cos(time) * side_to_side;
```

Example 3 (unknown):
```unknown
//angle is scaled by 0.1 so that the fish only pivots and doesn't rotate all the way around
//pivot is a uniform float
float pivot_angle = cos(time) * 0.1 * pivot;
mat2 rotation_matrix = mat2(vec2(cos(pivot_angle), -sin(pivot_angle)), vec2(sin(pivot_angle), cos(pivot_angle)));
```

Example 4 (unknown):
```unknown
VERTEX.xz = rotation_matrix * VERTEX.xz;
```

---

## Animating thousands of objects — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/performance/vertex_animation/index.html

**Contents:**
- Animating thousands of objects

The content of this page was not yet updated for Godot 4.5 and may be outdated. If you know how to improve this page or you can confirm that it's up to date, feel free to open a pull request.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## AnimationMixer — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_animationmixer.html

**Contents:**
- AnimationMixer
- Description
- Tutorials
- Properties
- Methods
- Signals
- Enumerations
- Property Descriptions
- Method Descriptions
- User-contributed notes

Inherits: Node < Object

Inherited By: AnimationPlayer, AnimationTree

Base class for AnimationPlayer and AnimationTree.

Base class for AnimationPlayer and AnimationTree to manage animation lists. It also has general properties and methods for playback and blending.

After instantiating the playback information data within the extended class, the blending is processed by the AnimationMixer.

Migrating Animations from Godot 4.0 to 4.3

AnimationCallbackModeDiscrete

callback_mode_discrete

AnimationCallbackModeMethod

AnimationCallbackModeProcess

callback_mode_process

_post_process_key_value(animation: Animation, track: int, value: Variant, object_id: int, object_sub_idx: int) virtual const

add_animation_library(name: StringName, library: AnimationLibrary)

advance(delta: float)

capture(name: StringName, duration: float, trans_type: TransitionType = 0, ease_type: EaseType = 0)

find_animation(animation: Animation) const

find_animation_library(animation: Animation) const

get_animation(name: StringName) const

get_animation_library(name: StringName) const

get_animation_library_list() const

get_animation_list() const

get_root_motion_position() const

get_root_motion_position_accumulator() const

get_root_motion_rotation() const

get_root_motion_rotation_accumulator() const

get_root_motion_scale() const

get_root_motion_scale_accumulator() const

has_animation(name: StringName) const

has_animation_library(name: StringName) const

remove_animation_library(name: StringName)

rename_animation_library(name: StringName, newname: StringName)

animation_finished(anim_name: StringName) 🔗

Notifies when an animation finished playing.

Note: This signal is not emitted if an animation is looping.

animation_libraries_updated() 🔗

Notifies when the animation libraries have changed.

animation_list_changed() 🔗

Notifies when an animation list is changed.

animation_started(anim_name: StringName) 🔗

Notifies when an animation starts playing.

Note: This signal is not emitted if an animation is looping.

Notifies when the caches have been cleared, either automatically, or manually via clear_caches().

Notifies when the blending result related have been applied to the target objects.

Notifies when the property related process have been updated.

enum AnimationCallbackModeProcess: 🔗

AnimationCallbackModeProcess ANIMATION_CALLBACK_MODE_PROCESS_PHYSICS = 0

Process animation during physics frames (see Node.NOTIFICATION_INTERNAL_PHYSICS_PROCESS). This is especially useful when animating physics bodies.

AnimationCallbackModeProcess ANIMATION_CALLBACK_MODE_PROCESS_IDLE = 1

Process animation during process frames (see Node.NOTIFICATION_INTERNAL_PROCESS).

AnimationCallbackModeProcess ANIMATION_CALLBACK_MODE_PROCESS_MANUAL = 2

Do not process animation. Use advance() to process the animation manually.

enum AnimationCallbackModeMethod: 🔗

AnimationCallbackModeMethod ANIMATION_CALLBACK_MODE_METHOD_DEFERRED = 0

Batch method calls during the animation process, then do the calls after events are processed. This avoids bugs involving deleting nodes or modifying the AnimationPlayer while playing.

AnimationCallbackModeMethod ANIMATION_CALLBACK_MODE_METHOD_IMMEDIATE = 1

Make method calls immediately when reached in the animation.

enum AnimationCallbackModeDiscrete: 🔗

AnimationCallbackModeDiscrete ANIMATION_CALLBACK_MODE_DISCRETE_DOMINANT = 0

An Animation.UPDATE_DISCRETE track value takes precedence when blending Animation.UPDATE_CONTINUOUS or Animation.UPDATE_CAPTURE track values and Animation.UPDATE_DISCRETE track values.

AnimationCallbackModeDiscrete ANIMATION_CALLBACK_MODE_DISCRETE_RECESSIVE = 1

An Animation.UPDATE_CONTINUOUS or Animation.UPDATE_CAPTURE track value takes precedence when blending the Animation.UPDATE_CONTINUOUS or Animation.UPDATE_CAPTURE track values and the Animation.UPDATE_DISCRETE track values. This is the default behavior for AnimationPlayer.

AnimationCallbackModeDiscrete ANIMATION_CALLBACK_MODE_DISCRETE_FORCE_CONTINUOUS = 2

Always treat the Animation.UPDATE_DISCRETE track value as Animation.UPDATE_CONTINUOUS with Animation.INTERPOLATION_NEAREST. This is the default behavior for AnimationTree.

If a value track has un-interpolatable type key values, it is internally converted to use ANIMATION_CALLBACK_MODE_DISCRETE_RECESSIVE with Animation.UPDATE_DISCRETE.

Un-interpolatable type list:

@GlobalScope.TYPE_NIL

@GlobalScope.TYPE_NODE_PATH

@GlobalScope.TYPE_RID

@GlobalScope.TYPE_OBJECT

@GlobalScope.TYPE_CALLABLE

@GlobalScope.TYPE_SIGNAL

@GlobalScope.TYPE_DICTIONARY

@GlobalScope.TYPE_PACKED_BYTE_ARRAY

@GlobalScope.TYPE_BOOL and @GlobalScope.TYPE_INT are treated as @GlobalScope.TYPE_FLOAT during blending and rounded when the result is retrieved.

It is same for arrays and vectors with them such as @GlobalScope.TYPE_PACKED_INT32_ARRAY or @GlobalScope.TYPE_VECTOR2I, they are treated as @GlobalScope.TYPE_PACKED_FLOAT32_ARRAY or @GlobalScope.TYPE_VECTOR2. Also note that for arrays, the size is also interpolated.

@GlobalScope.TYPE_STRING and @GlobalScope.TYPE_STRING_NAME are interpolated between character codes and lengths, but note that there is a difference in algorithm between interpolation between keys and interpolation by blending.

void set_active(value: bool)

If true, the AnimationMixer will be processing.

int audio_max_polyphony = 32 🔗

void set_audio_max_polyphony(value: int)

int get_audio_max_polyphony()

The number of possible simultaneous sounds for each of the assigned AudioStreamPlayers.

For example, if this value is 32 and the animation has two audio tracks, the two AudioStreamPlayers assigned can play simultaneously up to 32 voices each.

AnimationCallbackModeDiscrete callback_mode_discrete = 1 🔗

void set_callback_mode_discrete(value: AnimationCallbackModeDiscrete)

AnimationCallbackModeDiscrete get_callback_mode_discrete()

Ordinarily, tracks can be set to Animation.UPDATE_DISCRETE to update infrequently, usually when using nearest interpolation.

However, when blending with Animation.UPDATE_CONTINUOUS several results are considered. The callback_mode_discrete specify it explicitly. See also AnimationCallbackModeDiscrete.

To make the blended results look good, it is recommended to set this to ANIMATION_CALLBACK_MODE_DISCRETE_FORCE_CONTINUOUS to update every frame during blending. Other values exist for compatibility and they are fine if there is no blending, but not so, may produce artifacts.

AnimationCallbackModeMethod callback_mode_method = 0 🔗

void set_callback_mode_method(value: AnimationCallbackModeMethod)

AnimationCallbackModeMethod get_callback_mode_method()

The call mode used for "Call Method" tracks.

AnimationCallbackModeProcess callback_mode_process = 1 🔗

void set_callback_mode_process(value: AnimationCallbackModeProcess)

AnimationCallbackModeProcess get_callback_mode_process()

The process notification in which to update animations.

bool deterministic = false 🔗

void set_deterministic(value: bool)

bool is_deterministic()

If true, the blending uses the deterministic algorithm. The total weight is not normalized and the result is accumulated with an initial value (0 or a "RESET" animation if present).

This means that if the total amount of blending is 0.0, the result is equal to the "RESET" animation.

If the number of tracks between the blended animations is different, the animation with the missing track is treated as if it had the initial value.

If false, The blend does not use the deterministic algorithm. The total weight is normalized and always 1.0. If the number of tracks between the blended animations is different, nothing is done about the animation that is missing a track.

Note: In AnimationTree, the blending with AnimationNodeAdd2, AnimationNodeAdd3, AnimationNodeSub2 or the weight greater than 1.0 may produce unexpected results.

For example, if AnimationNodeAdd2 blends two nodes with the amount 1.0, then total weight is 2.0 but it will be normalized to make the total amount 1.0 and the result will be equal to AnimationNodeBlend2 with the amount 0.5.

bool reset_on_save = true 🔗

void set_reset_on_save_enabled(value: bool)

bool is_reset_on_save_enabled()

This is used by the editor. If set to true, the scene will be saved with the effects of the reset animation (the animation with the key "RESET") applied as if it had been seeked to time 0, with the editor keeping the values that the scene had before saving.

This makes it more convenient to preview and edit animations in the editor, as changes to the scene will not be saved as long as they are set in the reset animation.

bool root_motion_local = false 🔗

void set_root_motion_local(value: bool)

bool is_root_motion_local()

If true, get_root_motion_position() value is extracted as a local translation value before blending. In other words, it is treated like the translation is done after the rotation.

NodePath root_motion_track = NodePath("") 🔗

void set_root_motion_track(value: NodePath)

NodePath get_root_motion_track()

The path to the Animation track used for root motion. Paths must be valid scene-tree paths to a node, and must be specified starting from the parent node of the node that will reproduce the animation. The root_motion_track uses the same format as Animation.track_set_path(), but note that a bone must be specified.

If the track has type Animation.TYPE_POSITION_3D, Animation.TYPE_ROTATION_3D, or Animation.TYPE_SCALE_3D the transformation will be canceled visually, and the animation will appear to stay in place. See also get_root_motion_position(), get_root_motion_rotation(), get_root_motion_scale(), and RootMotionView.

NodePath root_node = NodePath("..") 🔗

void set_root_node(value: NodePath)

NodePath get_root_node()

The node which node path references will travel from.

Variant _post_process_key_value(animation: Animation, track: int, value: Variant, object_id: int, object_sub_idx: int) virtual const 🔗

A virtual function for processing after getting a key during playback.

Error add_animation_library(name: StringName, library: AnimationLibrary) 🔗

Adds library to the animation player, under the key name.

AnimationMixer has a global library by default with an empty string as key. For adding an animation to the global library:

void advance(delta: float) 🔗

Manually advance the animations by the specified time (in seconds).

void capture(name: StringName, duration: float, trans_type: TransitionType = 0, ease_type: EaseType = 0) 🔗

If the animation track specified by name has an option Animation.UPDATE_CAPTURE, stores current values of the objects indicated by the track path as a cache. If there is already a captured cache, the old cache is discarded.

After this it will interpolate with current animation blending result during the playback process for the time specified by duration, working like a crossfade.

You can specify trans_type as the curve for the interpolation. For better results, it may be appropriate to specify Tween.TRANS_LINEAR for cases where the first key of the track begins with a non-zero value or where the key value does not change, and Tween.TRANS_QUAD for cases where the key value changes linearly.

void clear_caches() 🔗

AnimationMixer caches animated nodes. It may not notice if a node disappears; clear_caches() forces it to update the cache again.

StringName find_animation(animation: Animation) const 🔗

Returns the key of animation or an empty StringName if not found.

StringName find_animation_library(animation: Animation) const 🔗

Returns the key for the AnimationLibrary that contains animation or an empty StringName if not found.

Animation get_animation(name: StringName) const 🔗

Returns the Animation with the key name. If the animation does not exist, null is returned and an error is logged.

AnimationLibrary get_animation_library(name: StringName) const 🔗

Returns the first AnimationLibrary with key name or null if not found.

To get the AnimationMixer's global animation library, use get_animation_library("").

Array[StringName] get_animation_library_list() const 🔗

Returns the list of stored library keys.

PackedStringArray get_animation_list() const 🔗

Returns the list of stored animation keys.

Vector3 get_root_motion_position() const 🔗

Retrieve the motion delta of position with the root_motion_track as a Vector3 that can be used elsewhere.

If root_motion_track is not a path to a track of type Animation.TYPE_POSITION_3D, returns Vector3(0, 0, 0).

See also root_motion_track and RootMotionView.

The most basic example is applying position to CharacterBody3D:

By using this in combination with get_root_motion_rotation_accumulator(), you can apply the root motion position more correctly to account for the rotation of the node.

If root_motion_local is true, returns the pre-multiplied translation value with the inverted rotation.

In this case, the code can be written as follows:

Vector3 get_root_motion_position_accumulator() const 🔗

Retrieve the blended value of the position tracks with the root_motion_track as a Vector3 that can be used elsewhere.

This is useful in cases where you want to respect the initial key values of the animation.

For example, if an animation with only one key Vector3(0, 0, 0) is played in the previous frame and then an animation with only one key Vector3(1, 0, 1) is played in the next frame, the difference can be calculated as follows:

However, if the animation loops, an unintended discrete change may occur, so this is only useful for some simple use cases.

Quaternion get_root_motion_rotation() const 🔗

Retrieve the motion delta of rotation with the root_motion_track as a Quaternion that can be used elsewhere.

If root_motion_track is not a path to a track of type Animation.TYPE_ROTATION_3D, returns Quaternion(0, 0, 0, 1).

See also root_motion_track and RootMotionView.

The most basic example is applying rotation to CharacterBody3D:

Quaternion get_root_motion_rotation_accumulator() const 🔗

Retrieve the blended value of the rotation tracks with the root_motion_track as a Quaternion that can be used elsewhere.

This is necessary to apply the root motion position correctly, taking rotation into account. See also get_root_motion_position().

Also, this is useful in cases where you want to respect the initial key values of the animation.

For example, if an animation with only one key Quaternion(0, 0, 0, 1) is played in the previous frame and then an animation with only one key Quaternion(0, 0.707, 0, 0.707) is played in the next frame, the difference can be calculated as follows:

However, if the animation loops, an unintended discrete change may occur, so this is only useful for some simple use cases.

Vector3 get_root_motion_scale() const 🔗

Retrieve the motion delta of scale with the root_motion_track as a Vector3 that can be used elsewhere.

If root_motion_track is not a path to a track of type Animation.TYPE_SCALE_3D, returns Vector3(0, 0, 0).

See also root_motion_track and RootMotionView.

The most basic example is applying scale to CharacterBody3D:

Vector3 get_root_motion_scale_accumulator() const 🔗

Retrieve the blended value of the scale tracks with the root_motion_track as a Vector3 that can be used elsewhere.

For example, if an animation with only one key Vector3(1, 1, 1) is played in the previous frame and then an animation with only one key Vector3(2, 2, 2) is played in the next frame, the difference can be calculated as follows:

However, if the animation loops, an unintended discrete change may occur, so this is only useful for some simple use cases.

bool has_animation(name: StringName) const 🔗

Returns true if the AnimationMixer stores an Animation with key name.

bool has_animation_library(name: StringName) const 🔗

Returns true if the AnimationMixer stores an AnimationLibrary with key name.

void remove_animation_library(name: StringName) 🔗

Removes the AnimationLibrary associated with the key name.

void rename_animation_library(name: StringName, newname: StringName) 🔗

Moves the AnimationLibrary associated with the key name to the key newname.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
var global_library = mixer.get_animation_library("")
global_library.add_animation("animation_name", animation_resource)
```

Example 2 (gdscript):
```gdscript
var current_rotation

func _process(delta):
    if Input.is_action_just_pressed("animate"):
        current_rotation = get_quaternion()
        state_machine.travel("Animate")
    var velocity = current_rotation * animation_tree.get_root_motion_position() / delta
    set_velocity(velocity)
    move_and_slide()
```

Example 3 (gdscript):
```gdscript
func _process(delta):
    if Input.is_action_just_pressed("animate"):
        state_machine.travel("Animate")
    set_quaternion(get_quaternion() * animation_tree.get_root_motion_rotation())
    var velocity = (animation_tree.get_root_motion_rotation_accumulator().inverse() * get_quaternion()) * animation_tree.get_root_motion_position() / delta
    set_velocity(velocity)
    move_and_slide()
```

Example 4 (gdscript):
```gdscript
func _process(delta):
    if Input.is_action_just_pressed("animate"):
        state_machine.travel("Animate")
    set_quaternion(get_quaternion() * animation_tree.get_root_motion_rotation())
    var velocity = get_quaternion() * animation_tree.get_root_motion_position() / delta
    set_velocity(velocity)
    move_and_slide()
```

---

## AnimationPlayer — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_animationplayer.html

**Contents:**
- AnimationPlayer
- Description
- Tutorials
- Properties
- Methods
- Signals
- Enumerations
- Property Descriptions
- Method Descriptions
- User-contributed notes

Inherits: AnimationMixer < Node < Object

A node used for animation playback.

An animation player is used for general-purpose playback of animations. It contains a dictionary of AnimationLibrary resources and custom blend times between animation transitions.

Some methods and properties use a single key to reference an animation directly. These keys are formatted as the key for the library, followed by a forward slash, then the key for the animation within the library, for example "movement/run". If the library's key is an empty string (known as the default library), the forward slash is omitted, being the same key used by the library.

AnimationPlayer is better-suited than Tween for more complex animations, for example ones with non-trivial timings. It can also be used over Tween if the animation track editor is more convenient than doing it in code.

Updating the target properties of animations occurs at the process frame.

Animation documentation index

Third Person Shooter (TPS) Demo

current_animation_length

current_animation_position

playback_auto_capture

playback_auto_capture_duration

playback_auto_capture_ease_type

playback_auto_capture_transition_type

playback_default_blend_time

animation_get_next(animation_from: StringName) const

animation_set_next(animation_from: StringName, animation_to: StringName)

get_blend_time(animation_from: StringName, animation_to: StringName) const

AnimationMethodCallMode

get_method_call_mode() const

get_playing_speed() const

AnimationProcessCallback

get_process_callback() const

get_section_end_time() const

get_section_start_time() const

play(name: StringName = &"", custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false)

play_backwards(name: StringName = &"", custom_blend: float = -1)

play_section(name: StringName = &"", start_time: float = -1, end_time: float = -1, custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false)

play_section_backwards(name: StringName = &"", start_time: float = -1, end_time: float = -1, custom_blend: float = -1)

play_section_with_markers(name: StringName = &"", start_marker: StringName = &"", end_marker: StringName = &"", custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false)

play_section_with_markers_backwards(name: StringName = &"", start_marker: StringName = &"", end_marker: StringName = &"", custom_blend: float = -1)

play_with_capture(name: StringName = &"", duration: float = -1.0, custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false, trans_type: TransitionType = 0, ease_type: EaseType = 0)

queue(name: StringName)

seek(seconds: float, update: bool = false, update_only: bool = false)

set_blend_time(animation_from: StringName, animation_to: StringName, sec: float)

set_method_call_mode(mode: AnimationMethodCallMode)

set_process_callback(mode: AnimationProcessCallback)

set_root(path: NodePath)

set_section(start_time: float = -1, end_time: float = -1)

set_section_with_markers(start_marker: StringName = &"", end_marker: StringName = &"")

stop(keep_state: bool = false)

animation_changed(old_name: StringName, new_name: StringName) 🔗

Emitted when a queued animation plays after the previous animation finished. See also queue().

Note: The signal is not emitted when the animation is changed via play() or by an AnimationTree.

current_animation_changed(name: String) 🔗

Emitted when current_animation changes.

enum AnimationProcessCallback: 🔗

AnimationProcessCallback ANIMATION_PROCESS_PHYSICS = 0

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_PROCESS_PHYSICS.

AnimationProcessCallback ANIMATION_PROCESS_IDLE = 1

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_PROCESS_IDLE.

AnimationProcessCallback ANIMATION_PROCESS_MANUAL = 2

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_PROCESS_MANUAL.

enum AnimationMethodCallMode: 🔗

AnimationMethodCallMode ANIMATION_METHOD_CALL_DEFERRED = 0

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_METHOD_DEFERRED.

AnimationMethodCallMode ANIMATION_METHOD_CALL_IMMEDIATE = 1

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_METHOD_IMMEDIATE.

String assigned_animation 🔗

void set_assigned_animation(value: String)

String get_assigned_animation()

If playing, the current animation's key, otherwise, the animation last played. When set, this changes the animation, but will not play it unless already playing. See also current_animation.

String autoplay = "" 🔗

void set_autoplay(value: String)

String get_autoplay()

The key of the animation to play when the scene loads.

String current_animation = "" 🔗

void set_current_animation(value: String)

String get_current_animation()

The key of the currently playing animation. If no animation is playing, the property's value is an empty string. Changing this value does not restart the animation. See play() for more information on playing animations.

Note: While this property appears in the Inspector, it's not meant to be edited, and it's not saved in the scene. This property is mainly used to get the currently playing animation, and internally for animation playback tracks. For more information, see Animation.

float current_animation_length 🔗

float get_current_animation_length()

The length (in seconds) of the currently playing animation.

float current_animation_position 🔗

float get_current_animation_position()

The position (in seconds) of the currently playing animation.

bool movie_quit_on_finish = false 🔗

void set_movie_quit_on_finish_enabled(value: bool)

bool is_movie_quit_on_finish_enabled()

If true and the engine is running in Movie Maker mode (see MovieWriter), exits the engine with SceneTree.quit() as soon as an animation is done playing in this AnimationPlayer. A message is printed when the engine quits for this reason.

Note: This obeys the same logic as the AnimationMixer.animation_finished signal, so it will not quit the engine if the animation is set to be looping.

bool playback_auto_capture = true 🔗

void set_auto_capture(value: bool)

bool is_auto_capture()

If true, performs AnimationMixer.capture() before playback automatically. This means just play_with_capture() is executed with default arguments instead of play().

Note: Capture interpolation is only performed if the animation contains a capture track. See also Animation.UPDATE_CAPTURE.

float playback_auto_capture_duration = -1.0 🔗

void set_auto_capture_duration(value: float)

float get_auto_capture_duration()

See also play_with_capture() and AnimationMixer.capture().

If playback_auto_capture_duration is negative value, the duration is set to the interval between the current position and the first key.

EaseType playback_auto_capture_ease_type = 0 🔗

void set_auto_capture_ease_type(value: EaseType)

EaseType get_auto_capture_ease_type()

The ease type of the capture interpolation. See also EaseType.

TransitionType playback_auto_capture_transition_type = 0 🔗

void set_auto_capture_transition_type(value: TransitionType)

TransitionType get_auto_capture_transition_type()

The transition type of the capture interpolation. See also TransitionType.

float playback_default_blend_time = 0.0 🔗

void set_default_blend_time(value: float)

float get_default_blend_time()

The default time in which to blend animations. Ranges from 0 to 4096 with 0.01 precision.

float speed_scale = 1.0 🔗

void set_speed_scale(value: float)

float get_speed_scale()

The speed scaling ratio. For example, if this value is 1, then the animation plays at normal speed. If it's 0.5, then it plays at half speed. If it's 2, then it plays at double speed.

If set to a negative value, the animation is played in reverse. If set to 0, the animation will not advance.

StringName animation_get_next(animation_from: StringName) const 🔗

Returns the key of the animation which is queued to play after the animation_from animation.

void animation_set_next(animation_from: StringName, animation_to: StringName) 🔗

Triggers the animation_to animation when the animation_from animation completes.

Clears all queued, unplayed animations.

float get_blend_time(animation_from: StringName, animation_to: StringName) const 🔗

Returns the blend time (in seconds) between two animations, referenced by their keys.

AnimationMethodCallMode get_method_call_mode() const 🔗

Deprecated: Use AnimationMixer.callback_mode_method instead.

Returns the call mode used for "Call Method" tracks.

float get_playing_speed() const 🔗

Returns the actual playing speed of current animation or 0 if not playing. This speed is the speed_scale property multiplied by custom_speed argument specified when calling the play() method.

Returns a negative value if the current animation is playing backwards.

AnimationProcessCallback get_process_callback() const 🔗

Deprecated: Use AnimationMixer.callback_mode_process instead.

Returns the process notification in which to update animations.

PackedStringArray get_queue() 🔗

Returns a list of the animation keys that are currently queued to play.

NodePath get_root() const 🔗

Deprecated: Use AnimationMixer.root_node instead.

Returns the node which node path references will travel from.

float get_section_end_time() const 🔗

Returns the end time of the section currently being played.

float get_section_start_time() const 🔗

Returns the start time of the section currently being played.

bool has_section() const 🔗

Returns true if an animation is currently playing with a section.

bool is_playing() const 🔗

Returns true if an animation is currently playing (even if speed_scale and/or custom_speed are 0).

Pauses the currently playing animation. The current_animation_position will be kept and calling play() or play_backwards() without arguments or with the same animation name as assigned_animation will resume the animation.

void play(name: StringName = &"", custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false) 🔗

Plays the animation with key name. Custom blend times and speed can be set.

The from_end option only affects when switching to a new animation track, or if the same track but at the start or end. It does not affect resuming playback that was paused in the middle of an animation. If custom_speed is negative and from_end is true, the animation will play backwards (which is equivalent to calling play_backwards()).

The AnimationPlayer keeps track of its current or last played animation with assigned_animation. If this method is called with that same animation name, or with no name parameter, the assigned animation will resume playing if it was paused.

Note: The animation will be updated the next time the AnimationPlayer is processed. If other variables are updated at the same time this is called, they may be updated too early. To perform the update immediately, call advance(0).

void play_backwards(name: StringName = &"", custom_blend: float = -1) 🔗

Plays the animation with key name in reverse.

This method is a shorthand for play() with custom_speed = -1.0 and from_end = true, so see its description for more information.

void play_section(name: StringName = &"", start_time: float = -1, end_time: float = -1, custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false) 🔗

Plays the animation with key name and the section starting from start_time and ending on end_time. See also play().

Setting start_time to a value outside the range of the animation means the start of the animation will be used instead, and setting end_time to a value outside the range of the animation means the end of the animation will be used instead. start_time cannot be equal to end_time.

void play_section_backwards(name: StringName = &"", start_time: float = -1, end_time: float = -1, custom_blend: float = -1) 🔗

Plays the animation with key name and the section starting from start_time and ending on end_time in reverse.

This method is a shorthand for play_section() with custom_speed = -1.0 and from_end = true, see its description for more information.

void play_section_with_markers(name: StringName = &"", start_marker: StringName = &"", end_marker: StringName = &"", custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false) 🔗

Plays the animation with key name and the section starting from start_marker and ending on end_marker.

If the start marker is empty, the section starts from the beginning of the animation. If the end marker is empty, the section ends on the end of the animation. See also play().

void play_section_with_markers_backwards(name: StringName = &"", start_marker: StringName = &"", end_marker: StringName = &"", custom_blend: float = -1) 🔗

Plays the animation with key name and the section starting from start_marker and ending on end_marker in reverse.

This method is a shorthand for play_section_with_markers() with custom_speed = -1.0 and from_end = true, see its description for more information.

void play_with_capture(name: StringName = &"", duration: float = -1.0, custom_blend: float = -1, custom_speed: float = 1.0, from_end: bool = false, trans_type: TransitionType = 0, ease_type: EaseType = 0) 🔗

See also AnimationMixer.capture().

You can use this method to use more detailed options for capture than those performed by playback_auto_capture. When playback_auto_capture is false, this method is almost the same as the following:

If name is blank, it specifies assigned_animation.

If duration is a negative value, the duration is set to the interval between the current position and the first key, when from_end is true, uses the interval between the current position and the last key instead.

Note: The duration takes speed_scale into account, but custom_speed does not, because the capture cache is interpolated with the blend result and the result may contain multiple animations.

void queue(name: StringName) 🔗

Queues an animation for playback once the current animation and all previously queued animations are done.

Note: If a looped animation is currently playing, the queued animation will never play unless the looped animation is stopped somehow.

void reset_section() 🔗

Resets the current section. Does nothing if a section has not been set.

void seek(seconds: float, update: bool = false, update_only: bool = false) 🔗

Seeks the animation to the seconds point in time (in seconds). If update is true, the animation updates too, otherwise it updates at process time. Events between the current frame and seconds are skipped.

If update_only is true, the method / audio / animation playback tracks will not be processed.

Note: Seeking to the end of the animation doesn't emit AnimationMixer.animation_finished. If you want to skip animation and emit the signal, use AnimationMixer.advance().

void set_blend_time(animation_from: StringName, animation_to: StringName, sec: float) 🔗

Specifies a blend time (in seconds) between two animations, referenced by their keys.

void set_method_call_mode(mode: AnimationMethodCallMode) 🔗

Deprecated: Use AnimationMixer.callback_mode_method instead.

Sets the call mode used for "Call Method" tracks.

void set_process_callback(mode: AnimationProcessCallback) 🔗

Deprecated: Use AnimationMixer.callback_mode_process instead.

Sets the process notification in which to update animations.

void set_root(path: NodePath) 🔗

Deprecated: Use AnimationMixer.root_node instead.

Sets the node which node path references will travel from.

void set_section(start_time: float = -1, end_time: float = -1) 🔗

Changes the start and end times of the section being played. The current playback position will be clamped within the new section. See also play_section().

void set_section_with_markers(start_marker: StringName = &"", end_marker: StringName = &"") 🔗

Changes the start and end markers of the section being played. The current playback position will be clamped within the new section. See also play_section_with_markers().

If the argument is empty, the section uses the beginning or end of the animation. If both are empty, it means that the section is not set.

void stop(keep_state: bool = false) 🔗

Stops the currently playing animation. The animation position is reset to 0 and the custom_speed is reset to 1.0. See also pause().

If keep_state is true, the animation state is not updated visually.

Note: The method / audio / animation playback tracks will not be processed by this method.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
capture(name, duration, trans_type, ease_type)
play(name, custom_blend, custom_speed, from_end)
```

---

## AnimationTree — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_animationtree.html

**Contents:**
- AnimationTree
- Description
- Tutorials
- Properties
- Methods
- Signals
- Enumerations
- Property Descriptions
- Method Descriptions
- User-contributed notes

Inherits: AnimationMixer < Node < Object

A node used for advanced animation transitions in an AnimationPlayer.

A node used for advanced animation transitions in an AnimationPlayer.

Note: When linked with an AnimationPlayer, several properties and methods of the corresponding AnimationPlayer will not function as expected. Playback and transitions should be handled using only the AnimationTree and its constituent AnimationNode(s). The AnimationPlayer node should be used solely for adding, deleting, and editing animations.

Third Person Shooter (TPS) Demo

advance_expression_base_node

AnimationCallbackModeDiscrete

callback_mode_discrete

2 (overrides AnimationMixer)

true (overrides AnimationMixer)

AnimationProcessCallback

get_process_callback() const

set_process_callback(mode: AnimationProcessCallback)

animation_player_changed() 🔗

Emitted when the anim_player is changed.

enum AnimationProcessCallback: 🔗

AnimationProcessCallback ANIMATION_PROCESS_PHYSICS = 0

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_PROCESS_PHYSICS.

AnimationProcessCallback ANIMATION_PROCESS_IDLE = 1

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_PROCESS_IDLE.

AnimationProcessCallback ANIMATION_PROCESS_MANUAL = 2

Deprecated: See AnimationMixer.ANIMATION_CALLBACK_MODE_PROCESS_MANUAL.

NodePath advance_expression_base_node = NodePath(".") 🔗

void set_advance_expression_base_node(value: NodePath)

NodePath get_advance_expression_base_node()

The path to the Node used to evaluate the AnimationNode Expression if one is not explicitly specified internally.

NodePath anim_player = NodePath("") 🔗

void set_animation_player(value: NodePath)

NodePath get_animation_player()

The path to the AnimationPlayer used for animating.

AnimationRootNode tree_root 🔗

void set_tree_root(value: AnimationRootNode)

AnimationRootNode get_tree_root()

The root animation node of this AnimationTree. See AnimationRootNode.

AnimationProcessCallback get_process_callback() const 🔗

Deprecated: Use AnimationMixer.callback_mode_process instead.

Returns the process notification in which to update animations.

void set_process_callback(mode: AnimationProcessCallback) 🔗

Deprecated: Use AnimationMixer.callback_mode_process instead.

Sets the process notification in which to update animations.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Animation — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/animation/index.html

**Contents:**
- Animation

This section of the tutorial covers using the two animation nodes in Godot and the animation editor.

See Importing 3D scenes for information on importing animations from a 3D model.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Animation Track types — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/animation/animation_track_types.html

**Contents:**
- Animation Track types
- Property Track
- Position 3D / Rotation 3D / Scale 3D Track
- Blend Shape Track
- Call Method Track
- Bezier Curve Track
- Audio Playback Track
- Animation Playback Track
- User-contributed notes

This page gives an overview of the track types available for Godot's animation player node on top of the default property tracks.

We assume you already read Introduction to the animation features, which covers the basics, including property tracks.

The most basic track type. See Introduction to the animation features.

These 3D transform tracks control the location, rotation, and scale of a 3D object. They make it easier to animate a 3D object's transform compared to using regular property tracks.

It is designed for animations imported from external 3D models and can reduce resource capacity through compression.

A blend shape track is optimized for animating blend shape in MeshInstance3D.

It is designed for animations imported from external 3D models and can reduce resource capacity through compression.

A call method track allow you to call a function at a precise time from within an animation. For example, you can call queue_free() to delete a node at the end of a death animation.

The events placed on the call method track are not executed when the animation is previewed in the editor for safety.

To create such a track in the editor, click "Add Track -> Call Method Track." Then, a window opens and lets you select the node to associate with the track. To call one of the node's methods, right-click the timeline and select "Insert Key". A window opens with a list of available methods. Double-click one to finish creating the keyframe.

To change the method call or its arguments, click on the key and head to the inspector dock. There, you can change the method to call. If you expand the "Args" section, you will see a list of arguments you can edit.

To create such a track through code, pass a dictionary that contains the target method's name and parameters as the Variant for key in Animation.track_insert_key(). The keys and their expected values are as follows:

The name of the method as a String

The arguments to pass to the function as an Array

A bezier curve track is similar to a property track, except it allows you to animate a property's value using a bezier curve.

Bezier curve track and property track cannot be blended in AnimationPlayer and AnimationTree.

To create one, click "Add Track -> Bezier Curve Track". As with property tracks, you need to select a node and a property to animate. To open the bezier curve editor, click the curve icon to the right of the animation track.

In the editor, keys are represented by filled diamonds and the outlined diamonds connected to them by a line control curve's shape.

For better precision while manually working with curves, you might want to alter the zoom levels of the editor. The slider on the bottom right of the editor can be used to zoom in and out on the time axis, you can also do that with Ctrl + Shift + Mouse wheel. Using Ctrl + Alt + Mouse wheel will zoom in and out on the Y axis

While a keyframe is selected (not the handle), in the right click panel of the editor, you can select the handle mode:

Free: Allows you to orient a manipulator in any direction without affecting the other's position.

Linear: Does not allow rotation of the manipulator and draws a linear graph.

Balanced: Makes it so manipulators rotate together, but the distance between the key and a manipulator is not mirrored.

Mirrored: Makes the position of one manipulator perfectly mirror the other, including their distance to the key.

If you want to create an animation with audio, you need to create an audio playback track. To create one, your scene must have either an AudioStreamPlayer, AudioStreamPlayer2D, or AudioStreamPlayer3D node. When creating the track, you must select one of those nodes.

To play a sound in your animation, drag and drop an audio file from the file system dock onto the animation track. You should see the waveform of your audio file in the track.

To remove a sound from the animation, you can right-click it and select "Delete Key(s)" or click on it and press the Del key.

The blend mode allows you to choose whether or not to adjust the audio volume when blending in the AnimationTree.

Animation playback tracks allow you to sequence the animations of other animation player nodes in a scene. For example, you can use it to animate several characters in a cut-scene.

To create an animation playback track, select "New Track -> Animation Playback Track."

Then, select the animation player you want to associate with the track.

To add an animation to the track, right-click on it and insert a key. Select the key you just created to select an animation in the inspector dock.

If an animation is already playing and you want to stop it early, you can create a key and have it set to [STOP] in the inspector.

If you instanced a scene that contains an animation player into your scene, you need to enable "Editable Children" in the scene tree to access its animation player. Also, an animation player cannot reference itself.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (gdscript):
```gdscript
# Create a call method track.
func create_method_animation_track():
    # Get or create the animation the target method will be called from.
    var animation = $AnimationPlayer.get_animation("idle")
    # Get or create the target method's animation track.
    var track_index = animation.add_track(Animation.TYPE_METHOD)
    # Make the arguments for the target method jump().
    var jump_velocity = -400.0
    var multiplier = randf_range(.8, 1.2)
    # Get or create a dictionary with the target method's name and arguments.
    var method_dictionary = {
        "method": "jump",
        "args": [jump_velocity, multiplier],
    }

    # Set scene-tree path to node with target method.
    animation.track_set_path(track_index, ".")
    # Add the dictionary as the animation method track's key.
    animation.track_insert_key(track_index, 0.6, method_dictionary, 0)


# The target method that will be called from the animation.
func jump(jump_velocity, multiplier):
    velocity.y = jump_velocity * multiplier
```

Example 2 (unknown):
```unknown
// Create a call method track.
public void CreateAnimationTrack()
{
    // Get reference to the AnimationPlayer.
    var animationPlayer = GetNode<AnimationPlayer>("AnimationPlayer");
    // Get or create the animation the target method will be called from.
    var animation = animationPlayer.GetAnimation("idle");
    // Get or create the target method's animation track.
    var trackIndex = animation.AddTrack(Animation.TrackType.Method);
    // Make the arguments for the target method Jump().
    var jumpVelocity = -400.0;
    var multiplier = GD.RandRange(.8, 1.2);
    // Get or create a dictionary with the target method's name and arguments.
    var methodDictionary = new Godot.Collections.Dictionary
    {
        { "method", MethodName.Jump },
        { "args", new Godot.Collections.Array { jumpVelocity, multiplier } }
    };

    // Set scene-tree path to node with target method.
    animation.TrackSetPath(trackIndex, ".");
    // Add the dictionary as the animation method track's key.
    animation.TrackInsertKey(trackIndex, 0.6, methodDictionary, 0);
}


// The target method that will be called from the animation.
private void Jump(float jumpVelocity, float multiplier)
{
    Velocity = new Vector2(Velocity.X, jumpVelocity * multiplier);
}
```

---

## Area2D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_area2d.html

**Contents:**
- Area2D
- Description
- Tutorials
- Properties
- Methods
- Signals
- Enumerations
- Property Descriptions
- Method Descriptions
- User-contributed notes

Inherits: CollisionObject2D < Node2D < CanvasItem < Node < Object

A region of 2D space that detects other CollisionObject2Ds entering or exiting it.

Area2D is a region of 2D space defined by one or multiple CollisionShape2D or CollisionPolygon2D child nodes. It detects when other CollisionObject2Ds enter or exit it, and it also keeps track of which collision objects haven't exited it yet (i.e. which one are overlapping it).

This node can also locally alter or override physics parameters (gravity, damping) and route audio to custom audio buses.

Note: Areas and bodies created with PhysicsServer2D might not interact as expected with Area2Ds, and might not emit signals or track objects correctly.

2D Dodge The Creeps Demo

angular_damp_space_override

gravity_point_unit_distance

gravity_space_override

linear_damp_space_override

get_overlapping_areas() const

get_overlapping_bodies() const

has_overlapping_areas() const

has_overlapping_bodies() const

overlaps_area(area: Node) const

overlaps_body(body: Node) const

area_entered(area: Area2D) 🔗

Emitted when the received area enters this area. Requires monitoring to be set to true.

area_exited(area: Area2D) 🔗

Emitted when the received area exits this area. Requires monitoring to be set to true.

area_shape_entered(area_rid: RID, area: Area2D, area_shape_index: int, local_shape_index: int) 🔗

Emitted when a Shape2D of the received area enters a shape of this area. Requires monitoring to be set to true.

local_shape_index and area_shape_index contain indices of the interacting shapes from this area and the other area, respectively. area_rid contains the RID of the other area. These values can be used with the PhysicsServer2D.

Example: Get the CollisionShape2D node from the shape index:

area_shape_exited(area_rid: RID, area: Area2D, area_shape_index: int, local_shape_index: int) 🔗

Emitted when a Shape2D of the received area exits a shape of this area. Requires monitoring to be set to true.

See also area_shape_entered.

body_entered(body: Node2D) 🔗

Emitted when the received body enters this area. body can be a PhysicsBody2D or a TileMap. TileMaps are detected if their TileSet has collision shapes configured. Requires monitoring to be set to true.

body_exited(body: Node2D) 🔗

Emitted when the received body exits this area. body can be a PhysicsBody2D or a TileMap. TileMaps are detected if their TileSet has collision shapes configured. Requires monitoring to be set to true.

body_shape_entered(body_rid: RID, body: Node2D, body_shape_index: int, local_shape_index: int) 🔗

Emitted when a Shape2D of the received body enters a shape of this area. body can be a PhysicsBody2D or a TileMap. TileMaps are detected if their TileSet has collision shapes configured. Requires monitoring to be set to true.

local_shape_index and body_shape_index contain indices of the interacting shapes from this area and the interacting body, respectively. body_rid contains the RID of the body. These values can be used with the PhysicsServer2D.

Example: Get the CollisionShape2D node from the shape index:

body_shape_exited(body_rid: RID, body: Node2D, body_shape_index: int, local_shape_index: int) 🔗

Emitted when a Shape2D of the received body exits a shape of this area. body can be a PhysicsBody2D or a TileMap. TileMaps are detected if their TileSet has collision shapes configured. Requires monitoring to be set to true.

See also body_shape_entered.

enum SpaceOverride: 🔗

SpaceOverride SPACE_OVERRIDE_DISABLED = 0

This area does not affect gravity/damping.

SpaceOverride SPACE_OVERRIDE_COMBINE = 1

This area adds its gravity/damping values to whatever has been calculated so far (in priority order).

SpaceOverride SPACE_OVERRIDE_COMBINE_REPLACE = 2

This area adds its gravity/damping values to whatever has been calculated so far (in priority order), ignoring any lower priority areas.

SpaceOverride SPACE_OVERRIDE_REPLACE = 3

This area replaces any gravity/damping, even the defaults, ignoring any lower priority areas.

SpaceOverride SPACE_OVERRIDE_REPLACE_COMBINE = 4

This area replaces any gravity/damping calculated so far (in priority order), but keeps calculating the rest of the areas.

float angular_damp = 1.0 🔗

void set_angular_damp(value: float)

float get_angular_damp()

The rate at which objects stop spinning in this area. Represents the angular velocity lost per second.

See ProjectSettings.physics/2d/default_angular_damp for more details about damping.

SpaceOverride angular_damp_space_override = 0 🔗

void set_angular_damp_space_override_mode(value: SpaceOverride)

SpaceOverride get_angular_damp_space_override_mode()

Override mode for angular damping calculations within this area.

StringName audio_bus_name = &"Master" 🔗

void set_audio_bus_name(value: StringName)

StringName get_audio_bus_name()

The name of the area's audio bus.

bool audio_bus_override = false 🔗

void set_audio_bus_override(value: bool)

bool is_overriding_audio_bus()

If true, the area's audio bus overrides the default audio bus.

float gravity = 980.0 🔗

void set_gravity(value: float)

The area's gravity intensity (in pixels per second squared). This value multiplies the gravity direction. This is useful to alter the force of gravity without altering its direction.

Vector2 gravity_direction = Vector2(0, 1) 🔗

void set_gravity_direction(value: Vector2)

Vector2 get_gravity_direction()

The area's gravity vector (not normalized).

bool gravity_point = false 🔗

void set_gravity_is_point(value: bool)

bool is_gravity_a_point()

If true, gravity is calculated from a point (set via gravity_point_center). See also gravity_space_override.

Vector2 gravity_point_center = Vector2(0, 1) 🔗

void set_gravity_point_center(value: Vector2)

Vector2 get_gravity_point_center()

If gravity is a point (see gravity_point), this will be the point of attraction.

float gravity_point_unit_distance = 0.0 🔗

void set_gravity_point_unit_distance(value: float)

float get_gravity_point_unit_distance()

The distance at which the gravity strength is equal to gravity. For example, on a planet 100 pixels in radius with a surface gravity of 4.0 px/s², set the gravity to 4.0 and the unit distance to 100.0. The gravity will have falloff according to the inverse square law, so in the example, at 200 pixels from the center the gravity will be 1.0 px/s² (twice the distance, 1/4th the gravity), at 50 pixels it will be 16.0 px/s² (half the distance, 4x the gravity), and so on.

The above is true only when the unit distance is a positive number. When this is set to 0.0, the gravity will be constant regardless of distance.

SpaceOverride gravity_space_override = 0 🔗

void set_gravity_space_override_mode(value: SpaceOverride)

SpaceOverride get_gravity_space_override_mode()

Override mode for gravity calculations within this area.

float linear_damp = 0.1 🔗

void set_linear_damp(value: float)

float get_linear_damp()

The rate at which objects stop moving in this area. Represents the linear velocity lost per second.

See ProjectSettings.physics/2d/default_linear_damp for more details about damping.

SpaceOverride linear_damp_space_override = 0 🔗

void set_linear_damp_space_override_mode(value: SpaceOverride)

SpaceOverride get_linear_damp_space_override_mode()

Override mode for linear damping calculations within this area.

bool monitorable = true 🔗

void set_monitorable(value: bool)

bool is_monitorable()

If true, other monitoring areas can detect this area.

bool monitoring = true 🔗

void set_monitoring(value: bool)

If true, the area detects bodies or areas entering and exiting it.

void set_priority(value: int)

The area's priority. Higher priority areas are processed first. The World2D's physics is always processed last, after all areas.

Array[Area2D] get_overlapping_areas() const 🔗

Returns a list of intersecting Area2Ds. The overlapping area's CollisionObject2D.collision_layer must be part of this area's CollisionObject2D.collision_mask in order to be detected.

For performance reasons (collisions are all processed at the same time) this list is modified once during the physics step, not immediately after objects are moved. Consider using signals instead.

Array[Node2D] get_overlapping_bodies() const 🔗

Returns a list of intersecting PhysicsBody2Ds and TileMaps. The overlapping body's CollisionObject2D.collision_layer must be part of this area's CollisionObject2D.collision_mask in order to be detected.

For performance reasons (collisions are all processed at the same time) this list is modified once during the physics step, not immediately after objects are moved. Consider using signals instead.

bool has_overlapping_areas() const 🔗

Returns true if intersecting any Area2Ds, otherwise returns false. The overlapping area's CollisionObject2D.collision_layer must be part of this area's CollisionObject2D.collision_mask in order to be detected.

For performance reasons (collisions are all processed at the same time) the list of overlapping areas is modified once during the physics step, not immediately after objects are moved. Consider using signals instead.

bool has_overlapping_bodies() const 🔗

Returns true if intersecting any PhysicsBody2Ds or TileMaps, otherwise returns false. The overlapping body's CollisionObject2D.collision_layer must be part of this area's CollisionObject2D.collision_mask in order to be detected.

For performance reasons (collisions are all processed at the same time) the list of overlapping bodies is modified once during the physics step, not immediately after objects are moved. Consider using signals instead.

bool overlaps_area(area: Node) const 🔗

Returns true if the given Area2D intersects or overlaps this Area2D, false otherwise.

Note: The result of this test is not immediate after moving objects. For performance, the list of overlaps is updated once per frame and before the physics step. Consider using signals instead.

bool overlaps_body(body: Node) const 🔗

Returns true if the given physics body intersects or overlaps this Area2D, false otherwise.

Note: The result of this test is not immediate after moving objects. For performance, list of overlaps is updated once per frame and before the physics step. Consider using signals instead.

The body argument can either be a PhysicsBody2D or a TileMap instance. While TileMaps are not physics bodies themselves, they register their tiles with collision shapes as a virtual physics body.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
var other_shape_owner = area.shape_find_owner(area_shape_index)
var other_shape_node = area.shape_owner_get_owner(other_shape_owner)

var local_shape_owner = shape_find_owner(local_shape_index)
var local_shape_node = shape_owner_get_owner(local_shape_owner)
```

Example 2 (unknown):
```unknown
var body_shape_owner = body.shape_find_owner(body_shape_index)
var body_shape_node = body.shape_owner_get_owner(body_shape_owner)

var local_shape_owner = shape_find_owner(local_shape_index)
var local_shape_node = shape_owner_get_owner(local_shape_owner)
```

---

## AudioListener2D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_audiolistener2d.html

**Contents:**
- AudioListener2D
- Description
- Methods
- Method Descriptions
- User-contributed notes

Inherits: Node2D < CanvasItem < Node < Object

Overrides the location sounds are heard from.

Once added to the scene tree and enabled using make_current(), this node will override the location sounds are heard from. Only one AudioListener2D can be current. Using make_current() will disable the previous AudioListener2D.

If there is no active AudioListener2D in the current Viewport, center of the screen will be used as a hearing point for the audio. AudioListener2D needs to be inside SceneTree to function.

void clear_current() 🔗

Disables the AudioListener2D. If it's not set as current, this method will have no effect.

bool is_current() const 🔗

Returns true if this AudioListener2D is currently active.

void make_current() 🔗

Makes the AudioListener2D active, setting it as the hearing point for the sounds. If there is already another active AudioListener2D, it will be disabled.

This method will have no effect if the AudioListener2D is not added to SceneTree.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## CanvasItem shaders — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/shaders/shader_reference/canvas_item_shader.html

**Contents:**
- CanvasItem shaders
- Render modes
- Built-ins
- Global built-ins
- Vertex built-ins
- Fragment built-ins
  - COLOR and TEXTURE
  - NORMAL
- Light built-ins
- SDF functions

CanvasItem shaders are used to draw all 2D elements in Godot. These include all nodes that inherit from CanvasItems, and all GUI elements.

CanvasItem shaders contain fewer built-in variables and functionality than Spatial shaders, but they maintain the same basic structure with vertex, fragment, and light processor functions.

Mix blend mode (alpha is transparency), default.

Subtractive blend mode.

Multiplicative blend mode.

Pre-multiplied alpha blend mode.

Disable blending, values (including alpha) are written as-is.

Result is just albedo. No lighting/shading happens in material.

Only draw on light pass.

skip_vertex_transform

VERTEX needs to be transformed manually in the vertex() function.

VERTEX is modified in world coordinates instead of local.

Values marked as in are read-only. Values marked as out can optionally be written to and will not necessarily contain sensible values. Values marked as inout provide a sensible default value, and can optionally be written to. Samplers cannot be written to so they are not marked.

Not all built-ins are available in all processing functions. To access a vertex built-in from the fragment() function, you can use a varying. The same applies for accessing fragment built-ins from the light() function.

Global built-ins are available everywhere, including custom functions.

Global time since the engine has started, in seconds. It repeats after every 3,600 seconds (which can be changed with the rollover setting). It's affected by time_scale but not by pausing. If you need a TIME variable that is not affected by time scale, add your own global shader uniform and update it each frame.

A PI constant (3.141592). A ratio of a circle's circumference to its diameter and amount of radians in half turn.

A TAU constant (6.283185). An equivalent of PI * 2 and amount of radians in full turn.

An E constant (2.718281). Euler's number and a base of the natural logarithm.

Vertex data (VERTEX) is presented in local space (pixel coordinates, relative to the Node2D's origin). If not written to, these values will not be modified and be passed through as they came.

The user can disable the built-in model to world transform (world to screen and projection will still happen later) and do it manually with the following code:

Other built-ins, such as UV and COLOR, are also passed through to the fragment() function if not modified.

For instancing, the INSTANCE_CUSTOM variable contains the instance custom data. When using particles, this information is usually:

x: Rotation angle in radians.

y: Phase during lifetime (0.0 to 1.0).

Local space to world space transform. World space is the coordinates you normally use in the editor.

in mat4 CANVAS_MATRIX

World space to canvas space transform. In canvas space the origin is the upper-left corner of the screen and coordinates ranging from (0.0, 0.0) to viewport size.

in mat4 SCREEN_MATRIX

Canvas space to clip space. In clip space coordinates ranging from (-1.0, -1.0) to (1.0, 1.0).

Instance ID for instancing.

in vec4 INSTANCE_CUSTOM

Instance custom data.

in bool AT_LIGHT_PASS

in vec2 TEXTURE_PIXEL_SIZE

Normalized pixel size of default 2D texture. For a Sprite2D with a texture of size 64x32px, TEXTURE_PIXEL_SIZE = vec2(1/64, 1/32)

Vertex position, in local space.

The index of the current vertex in the vertex buffer.

Normalized texture coordinates. Range from 0.0 to 1.0.

Color from vertex primitive multiplied by CanvasItem's modulate multiplied by CanvasItem's self_modulate.

inout float POINT_SIZE

Point size for point drawing.

Custom value from vertex primitive.

Custom value from vertex primitive.

The built-in variable COLOR is used for a few things:

In the vertex() function, COLOR contains the color from the vertex primitive multiplied by the CanvasItem's modulate multiplied by the CanvasItem's self_modulate.

In the fragment() function, the input value COLOR is that same value multiplied by the color from the default TEXTURE (if present).

In the fragment() function, COLOR is also the final output.

Certain nodes (for example, Sprite2D) display a texture by default, for example texture. When using a custom fragment() function, you have a few options on how to sample this texture.

To read only the contents of the default texture, ignoring the vertex COLOR:

To read the contents of the default texture multiplied by vertex COLOR:

To read only the vertex COLOR in fragment(), ignoring the main texture, you must pass COLOR as a varying, then read it in fragment():

Similarly, if a normal map is used in the CanvasTexture, Godot uses it by default and assigns its value to the built-in NORMAL variable. If you are using a normal map meant for use in 3D, it will appear inverted. In order to use it in your shader, you must assign it to the NORMAL_MAP property. Godot will handle converting it for use in 2D and overwriting NORMAL.

Coordinate of pixel center. In screen space. xy specifies position in viewport. Upper-left of the viewport is the origin, (0.0, 0.0).

in vec2 SCREEN_PIXEL_SIZE

Size of individual pixels. Equal to inverse of resolution.

Visible area of the sprite region in format (x, y, width, height). Varies according to Sprite2D's region_enabled property.

Coordinate for drawing points.

in vec2 TEXTURE_PIXEL_SIZE

Normalized pixel size of default 2D texture. For a Sprite2D with a texture of size 64x32px, TEXTURE_PIXEL_SIZE = vec2(1/64, 1/32)

in bool AT_LIGHT_PASS

sampler2D SPECULAR_SHININESS_TEXTURE

Specular shininess texture of this object.

in vec4 SPECULAR_SHININESS

Specular shininess color, as sampled from the texture.

UV from the vertex() function. For Sprite2D with region enabled, this will sample the entire texture. Use REGION_RECT instead to sample only the region defined in the Sprite2D's properties.

Screen UV coordinate for current pixel.

sampler2D SCREEN_TEXTURE

Removed in Godot 4. Use a sampler2D with hint_screen_texture instead.

Normal read from NORMAL_TEXTURE. Writable.

sampler2D NORMAL_TEXTURE

Default 2D normal texture.

Configures normal maps meant for 3D for use in 2D. If used, overrides NORMAL.

out float NORMAL_MAP_DEPTH

Normal map depth for scaling.

Pixel position in screen space.

inout vec2 SHADOW_VERTEX

Same as VERTEX but can be written to alter shadows.

inout vec3 LIGHT_VERTEX

Same as VERTEX but can be written to alter lighting. Z component represents height.

COLOR from the vertex() function multiplied by the TEXTURE color. Also output color value.

Light processor functions work differently in Godot 4.x than they did in Godot 3.x. In Godot 4.x all lighting is done during the regular draw pass. In other words, Godot no longer draws the object again for each light.

Use the unshaded render mode if you do not want the light() function to run. Use the light_only render mode if you only want to see the impact of lighting on an object; this can be useful when you only want the object visible where it is covered by light.

If you define a light() function it will replace the built-in light function, even if your light function is empty.

Below is an example of a light shader that takes a CanvasItem's normal map into account:

Coordinate of pixel center. In screen space. xy specifies position in viewport. Upper-left of the viewport is the origin, (0.0, 0.0).

Input color. This is the output of the fragment() function.

UV from the vertex() function, equivalent to the UV in the fragment() function.

Current texture in use for CanvasItem.

in vec2 TEXTURE_PIXEL_SIZE

Normalized pixel size of TEXTURE. For a Sprite2D with a TEXTURE of size 64x32 pixels, TEXTURE_PIXEL_SIZE = vec2(1/64, 1/32)

Screen UV coordinate for current pixel.

Color of the Light2D. If the light is a PointLight2D, multiplied by the light's texture.

in float LIGHT_ENERGY

Energy multiplier of the Light2D.

in vec3 LIGHT_POSITION

Position of the Light2D in screen space. If using a DirectionalLight2D this is always (0.0, 0.0, 0.0).

in vec3 LIGHT_DIRECTION

Direction of the Light2D in screen space.

in bool LIGHT_IS_DIRECTIONAL

true if this pass is a DirectionalLight2D.

Pixel position, in screen space as modified in the fragment() function.

Output color for this Light2D.

in vec4 SPECULAR_SHININESS

Specular shininess, as set in the object's texture.

out vec4 SHADOW_MODULATE

Multiply shadows cast at this point by this color.

There are a few additional functions implemented to sample an automatically generated Signed Distance Field texture. These functions available for the fragment() and light() functions of CanvasItem shaders. Custom functions may also use them as long as they called from supported functions.

The signed distance field is generated from LightOccluder2D nodes present in the scene with the SDF Collision property enabled (which is the default). See the 2D lights and shadows documentation for more information.

float texture_sdf (vec2 sdf_pos)

Performs an SDF texture lookup.

vec2 texture_sdf_normal (vec2 sdf_pos)

Calculates a normal from the SDF texture.

vec2 sdf_to_screen_uv (vec2 sdf_pos)

Converts an SDF to screen UV.

vec2 screen_uv_to_sdf (vec2 uv)

Converts screen UV to an SDF.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
shader_type canvas_item;
render_mode skip_vertex_transform;

void vertex() {

    VERTEX = (MODEL_MATRIX * vec4(VERTEX, 0.0, 1.0)).xy;
}
```

Example 2 (unknown):
```unknown
void fragment() {
  COLOR = texture(TEXTURE, UV);
}
```

Example 3 (unknown):
```unknown
void fragment() {
  // Equivalent to an empty fragment() function, since COLOR is also the output variable.
  COLOR = COLOR;
}
```

Example 4 (unknown):
```unknown
varying vec4 vertex_color;
void vertex() {
  vertex_color = COLOR;
}
void fragment() {
  COLOR = vertex_color;
}
```

---

## Canvas layers — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/canvas_layers.html

**Contents:**
- Canvas layers
- Viewport and Canvas items
- CanvasLayers
- User-contributed notes

CanvasItem is the base for all 2D nodes, be it regular 2D nodes, such as Node2D, or Control. Both inherit from CanvasItem. You can arrange canvas items in trees. Each item will inherit its parent's transform: when the parent moves, its children move too.

CanvasItem nodes, and nodes inheriting from them, are direct or indirect children of a Viewport, that displays them.

The Viewport's property Viewport.canvas_transform, allows to apply a custom Transform2D transform to the CanvasItem hierarchy it contains. Nodes such as Camera2D work by changing that transform.

To achieve effects like scrolling, manipulating the canvas transform property is more efficient than moving the root canvas item and the entire scene with it.

Usually though, we don't want everything in the game or app to be subject to the canvas transform. For example:

Parallax Backgrounds: Backgrounds that move slower than the rest of the stage.

UI: Think of a user interface (UI) or head-up display (HUD) superimposed on our view of the game world. We want a life counter, score display and other elements to retain their screen positions even when our view of the game world changes.

Transitions: We may want visual effects used for transitions (fades, blends) to remain at a fixed screen location.

How to solve these problems in a single scene tree?

The answer is CanvasLayer, which is a node that adds a separate 2D rendering layer for all its children and grand-children. Viewport children will draw by default at layer "0", while a CanvasLayer will draw at any numeric layer. Layers with a greater number will be drawn above those with a smaller number. CanvasLayers also have their own transform and do not depend on the transform of other layers. This allows the UI to be fixed in screen-space while our view on the game world changes.

An example of this is creating a parallax background. This can be done with a CanvasLayer at layer "-1". The screen with the points, life counter and pause button can also be created at layer "1".

Here's a diagram of how it looks:

CanvasLayers are independent of tree order, and they only depend on their layer number, so they can be instantiated when needed.

CanvasLayers aren't necessary to control the drawing order of nodes. The standard way to ensuring that a node is correctly drawn 'in front' or 'behind' others is to manipulate the order of the nodes in the scene panel. Perhaps counterintuitively, the topmost nodes in the scene panel are drawn on behind lower ones in the viewport. 2D nodes also have the CanvasItem.z_index property for controlling their drawing order.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Collision shapes (2D) — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/physics/collision_shapes_2d.html

**Contents:**
- Collision shapes (2D)
- Primitive collision shapes
- Convex collision shapes
- Concave or trimesh collision shapes
- Performance caveats
- User-contributed notes

The types of collision shapes available in 2D in Godot.

Using an image converted to a polygon as a collision shape.

Performance considerations regarding 2D collisions.

Godot provides many kinds of collision shapes, with different performance and accuracy tradeoffs.

You can define the shape of a PhysicsBody2D by adding one or more CollisionShape2Ds or CollisionPolygon2Ds as direct child nodes. Indirect child nodes (i.e. children of child nodes) will be ignored and won't be used as collision shapes. Also, note that you must add a Shape2D resource to collision shape nodes in the Inspector dock.

When you add multiple collision shapes to a single PhysicsBody2D, you don't have to worry about them overlapping. They won't "collide" with each other.

Godot provides the following primitive collision shape types:

SeparationRayShape2D (designed for characters)

WorldBoundaryShape2D (infinite plane)

You can represent the collision of most smaller objects using one or more primitive shapes. However, for more complex objects, such as a large ship or a whole level, you may need convex or concave shapes instead. More on that below.

We recommend favoring primitive shapes for dynamic objects such as RigidBodies and CharacterBodies as their behavior is the most reliable. They often provide better performance as well.

Godot currently doesn't offer a built-in way to create 2D convex collision shapes. This section is mainly here for reference purposes.

Convex collision shapes are a compromise between primitive collision shapes and concave collision shapes. They can represent shapes of any complexity, but with an important caveat. As their name implies, an individual shape can only represent a convex shape. For instance, a pyramid is convex, but a hollow box is concave. To define a concave object with a single collision shape, you need to use a concave collision shape.

Depending on the object's complexity, you may get better performance by using multiple convex shapes instead of a concave collision shape. Godot lets you use convex decomposition to generate convex shapes that roughly match a hollow object. Note this performance advantage no longer applies after a certain amount of convex shapes. For large and complex objects such as a whole level, we recommend using concave shapes instead.

Concave collision shapes, also called trimesh collision shapes, can take any form, from a few triangles to thousands of triangles. Concave shapes are the slowest option but are also the most accurate in Godot. You can only use concave shapes within StaticBodies. They will not work with CharacterBodies or RigidBodies unless the RigidBody's mode is Static.

Even though concave shapes offer the most accurate collision, contact reporting can be less precise than primitive shapes.

When not using TileMaps for level design, concave shapes are the best approach for a level's collision.

You can configure the CollisionPolygon2D node's build mode in the inspector. If it is set to Solids (the default), collisions will include the polygon and its contained area. If it is set to Segments, collisions will only include the polygon edges.

You can generate a concave collision shape from the editor by selecting a Sprite2D and using the Sprite2D menu at the top of the 2D viewport. The Sprite2D menu dropdown exposes an option called Create CollisionPolygon2D Sibling. Once you click it, it displays a menu with 3 settings:

Simplification: Higher values will result in a less detailed shape, which improves performance at the cost of accuracy.

Shrink (Pixels): Higher values will shrink the generated collision polygon relative to the sprite's edges.

Grow (Pixels): Higher values will grow the generated collision polygon relative to the sprite's edges. Note that setting Grow and Shrink to equal values may yield different results than leaving both of them on 0.

If you have an image with many small details, it's recommended to create a simplified version and use it to generate the collision polygon. This can result in better performance and game feel, since the player won't be blocked by small, decorative details.

To use a separate image for collision polygon generation, create another Sprite2D, generate a collision polygon sibling from it then remove the Sprite2D node. This way, you can exclude small details from the generated collision.

You aren't limited to a single collision shape per PhysicsBody. Still, we recommend keeping the number of shapes as low as possible to improve performance, especially for dynamic objects like RigidBodies and CharacterBodies. On top of that, avoid translating, rotating, or scaling CollisionShapes to benefit from the physics engine's internal optimizations.

When using a single non-transformed collision shape in a StaticBody, the engine's broad phase algorithm can discard inactive PhysicsBodies. The narrow phase will then only have to take into account the active bodies' shapes. If a StaticBody has many collision shapes, the broad phase will fail. The narrow phase, which is slower, must then perform a collision check against each shape.

If you run into performance issues, you may have to make tradeoffs in terms of accuracy. Most games out there don't have a 100% accurate collision. They find creative ways to hide it or otherwise make it unnoticeable during normal gameplay.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Controlling thousands of fish with Particles — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/performance/vertex_animation/controlling_thousands_of_fish.html

**Contents:**
- Controlling thousands of fish with Particles
- User-contributed notes

The content of this page was not yet updated for Godot 4.5 and may be outdated. If you know how to improve this page or you can confirm that it's up to date, feel free to open a pull request.

The problem with MeshInstance3D is that it is expensive to update their transform array. It is great for placing many static objects around the scene. But it is still difficult to move the objects around the scene.

To make each instance move in an interesting way, we will use a GPUParticles3D node. Particles take advantage of GPU acceleration by computing and setting the per-instance information in a Shader.

First create a Particles node. Then, under "Draw Passes" set the Particle's "Draw Pass 1" to your Mesh. Then under "Process Material" create a new ShaderMaterial.

Set the shader_type to particles.

Then add the following two functions:

These functions come from the default ParticleProcessMaterial. They are used to generate a random number from each particle's RANDOM_SEED.

A unique thing about particle shaders is that some built-in variables are saved across frames. TRANSFORM, COLOR, and CUSTOM can all be accessed in the shader of the mesh, and also in the particle shader the next time it is run.

Next, setup your start() function. Particles shaders contain a start() function and a process() function.

The code in the start() function only runs when the particle system starts. The code in the process() function will always run.

We need to generate 4 random numbers: 3 to create a random position and one for the random offset of the swim cycle.

First, generate 4 seeds inside the start() function using the hash() function provided above:

Then, use those seeds to generate random numbers using rand_from_seed:

Finally, assign position to TRANSFORM[3].xyz, which is the part of the transform that holds the position information.

Remember, all this code so far goes inside the start() function.

The vertex shader for your mesh can stay the exact same as it was in the previous tutorial.

Now you can move each fish individually each frame, either by adding to the TRANSFORM directly or by writing to VELOCITY.

Let's transform the fish by setting their VELOCITY in the start() function.

This is the most basic way to set VELOCITY every particle (or fish) will have the same velocity.

Just by setting VELOCITY you can make the fish swim however you want. For example, try the code below.

This will give each fish a unique speed between 2 and 10.

You can also let each fish change its velocity over time if you set the velocity in the process() function.

If you used CUSTOM.y in the last tutorial, you can also set the speed of the swim animation based on the VELOCITY. Just use CUSTOM.y.

This code gives you the following behavior:

Using a ParticleProcessMaterial you can make the fish behavior as simple or complex as you like. In this tutorial we only set Velocity, but in your own Shaders you can also set COLOR, rotation, scale (through TRANSFORM). Please refer to the Particles Shader Reference for more information on particle shaders.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
shader_type particles
```

Example 2 (unknown):
```unknown
float rand_from_seed(in uint seed) {
  int k;
  int s = int(seed);
  if (s == 0)
    s = 305420679;
  k = s / 127773;
  s = 16807 * (s - k * 127773) - 2836 * k;
  if (s < 0)
    s += 2147483647;
  seed = uint(s);
  return float(seed % uint(65536)) / 65535.0;
}

uint hash(uint x) {
  x = ((x >> uint(16)) ^ x) * uint(73244475);
  x = ((x >> uint(16)) ^ x) * uint(73244475);
  x = (x >> uint(16)) ^ x;
  return x;
}
```

Example 3 (unknown):
```unknown
uint alt_seed1 = hash(NUMBER + uint(1) + RANDOM_SEED);
uint alt_seed2 = hash(NUMBER + uint(27) + RANDOM_SEED);
uint alt_seed3 = hash(NUMBER + uint(43) + RANDOM_SEED);
uint alt_seed4 = hash(NUMBER + uint(111) + RANDOM_SEED);
```

Example 4 (unknown):
```unknown
CUSTOM.x = rand_from_seed(alt_seed1);
vec3 position = vec3(rand_from_seed(alt_seed2) * 2.0 - 1.0,
                     rand_from_seed(alt_seed3) * 2.0 - 1.0,
                     rand_from_seed(alt_seed4) * 2.0 - 1.0);
```

---

## Creating movies — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/animation/creating_movies.html

**Contents:**
- Creating movies
- Enabling Movie Maker mode
  - Command line usage
- Choosing an output format
  - OGV (recommended)
  - AVI
  - PNG
  - Custom
- Configuration
- Quitting Movie Maker mode

Godot can record non-real-time video and audio from any 2D or 3D project. This kind of recording is also called offline rendering. There are many scenarios where this is useful:

Recording game trailers for promotional use.

Recording cutscenes that will be displayed as pre-recorded videos in the final game. This allows for using higher quality settings (at the cost of file size), regardless of the player's hardware.

Recording procedurally generated animations or motion design. User interaction remains possible during video recording, and audio can be included as well (although you won't be able to hear it while the video is recording).

Comparing the visual output of graphics settings, shaders, or rendering techniques in an animated scene.

With Godot's animation features such as the AnimationPlayer node, Tweeners, particles and shaders, it can effectively be used to create any kind of 2D and 3D animations (and still images).

If you are already used to Godot's workflow, you may find yourself more productive by using Godot for video rendering compared to Blender. That said, renderers designed for non-real-time usage such as Cycles and Eevee can result in better visuals (at the cost of longer rendering times).

Compared to real-time video recording, some advantages of non-real-time recording include:

Use any graphics settings (including extremely demanding settings) regardless of your hardware's capabilities. The output video will always have perfect frame pacing; it will never exhibit dropped frames or stuttering. Faster hardware will allow you to render a given animation in less time, but the visual output remains identical.

Render at a higher resolution than the screen resolution, without having to rely on driver-specific tools such as NVIDIA's Dynamic Super Resolution or AMD's Virtual Super Resolution.

Render at a higher framerate than the video's target framerate, then post-process to generate high-quality motion blur. This also makes effects that converge over several frames (such as temporal antialiasing, SDFGI and volumetric fog) look better.

This feature is not designed for capturing real-time footage during gameplay.

Players should use something like OBS Studio or SimpleScreenRecorder to record gameplay videos, as they do a much better job at intercepting the compositor than Godot can do using Vulkan or OpenGL natively.

That said, if your game runs at near-real-time speeds when capturing, you can still use this feature (but it will lack audible sound playback, as sound is saved directly to the video file).

To enable Movie Maker mode, click the "movie reel" button in the top-right corner of the editor before running the project:

Movie Maker mode is disabled, click the "movie reel" icon to enable

A menu will be displayed with options to enable Movie Maker mode and to go to the settings. The icon gets a background matching the accent color when Movie Maker mode is enabled:

Movie Maker mode is enabled, click the "movie reel" icon again to disable

Movie Maker status is not persisted when the editor quits, so you must re-enable Movie Maker mode again after restarting the editor if needed.

Toggling Movie Maker mode while running the project will not have any effect until the project is restarted.

Before you can record video by running the project, you still need to configure the output file path. This path can be set for all scenes in the Project Settings:

Movie Maker project settings (with Advanced toggle enabled)

Alternatively, you can set the output file path on a per-scene basis by adding a String metadata with the name movie_file to the scene's root node. This is only used when the main scene is set to the scene in question, or when running the scene directly by pressing F6 (Cmd + R on macOS).

Inspector view after creating a movie_file metadata of type String

The path specified in the project settings or metadata can be either absolute, or relative to the project root.

Once you've configured and enabled Movie Maker mode, it will be automatically used when running the project from the editor.

Movie Maker can also be enabled from the command line:

If the output path is relative, then it is relative to the project folder, not the current working directory. In the above example, the file will be written to /path/to/your_project/output.avi. This behavior is similar to the --export-release command line argument.

Since Movie Maker's output resolution is set by the viewport size, you can adjust the window size on startup to override it if the project uses the disabled or canvas_items stretch mode:

Note that the window size is clamped by your display's resolution. See Rendering at a higher resolution than the screen resolution if you need to record a video at a higher resolution than the screen resolution.

The recording FPS can also be overridden on the command line, without having to edit the Project Settings:

The --write-movie and --fixed-fps command line arguments are both available in exported projects. Movie Maker mode cannot be toggled while the project is running, but you can use the OS.execute() method to run a second instance of the exported project that will record a video file.

Output formats are provided by the MovieWriter class. Godot has 3 built-in MovieWriters, and more can be implemented by extensions:

OGV container with Theora for video and Vorbis for audio. Features lossy video and audio compression with a good balance of file size and encoding speed, with a better image quality than MJPEG. It has 4 speed levels that can be adjusted by changing Editor > Movie Writer > Encoding Speed with the fastest one being around as fast as AVI with better compression. At slower speed levels, it can compress even better while keeping the same image quality. The lossy compression quality can be adjusted by changing Editor > Movie Writer > Video Quality for video and Editor > Movie Writer > Audio Quality for audio.

The Keyframe Interval can be adjusted by changing Editor > Movie Writer > Keyframe Interval. In some cases, increasing this setting can improve compression efficiency without downsides.

The resulting file can be viewed in Godot with VideoStreamPlayer and most video players but not web browsers. OGV does not support transparency.

To use OGV, specify a path to a .ogv file to be created in the Editor > Movie Writer > Movie File project setting.

OGV can only be recorded in editor builds. On the other hand, OGV playback is possible in both editor and export template builds.

AVI container with MJPEG for video and uncompressed audio. Features lossy video compression, resulting in medium file sizes and fast encoding. The lossy compression quality can be adjusted by changing Editor > Movie Writer > Video Quality.

The resulting file can be viewed in most video players, but it must be converted to another format for viewing on the web or by Godot with the VideoStreamPlayer node. MJPEG does not support transparency. AVI output is currently limited to a file of 4 GB in size at most.

To use AVI, specify a path to a .avi file to be created in the Editor > Movie Writer > Movie File project setting.

PNG image sequence for video and WAV for audio. Features lossless video compression, at the cost of large file sizes and slow encoding. This is designed to be encoded to a video file with an external tool after recording.

Transparency is supported, but the root viewport must have its transparent_bg property set to true for transparency to be visible on the output image. This can be achieved by enabling the Rendering > Transparent Background advanced project setting. Display > Window > Size > Transparent and Display > Window > Per Pixel Transparency > Enabled can optionally be enabled to allow transparency to be previewed while recording the video, but they do not have to be enabled for the output image to contain transparency.

To use PNG, specify a .png file to be created in the Editor > Movie Writer > Movie File project setting. The generated .wav file will have the same name as the .png file (minus the extension).

If you need to encode directly to a different format or pipe a stream through third-party software, you can extend the MovieWriter class to create your own movie writers. This should typically be done using GDExtension for performance reasons.

In the Editor > Movie Writer section of the Project Settings, there are several options you can configure. Some of them are only visible after enabling the Advanced toggle in the top-right corner of the Project Settings dialog.

Mix Rate Hz: The audio mix rate to use in the recorded audio when writing a movie. This can be different from the project's mix rate, but this value must be divisible by the recorded FPS to prevent audio from desynchronizing over time.

Speaker Mode: The speaker mode to use in the recorded audio when writing a movie (stereo, 5.1 surround or 7.1 surround).

Video Quality: The image quality to use when writing a video to an OGV or AVI file, between 0.01 and 1.0 (inclusive). Higher quality values result in better-looking output at the cost of larger file sizes. Recommended quality values are between 0.75 and 0.9. Even at quality 1.0, compression remains lossy. This setting does not affect audio quality and is ignored when writing to a PNG image sequence.

Movie File: The output path for the movie. This can be absolute or relative to the project root.

Disable V-Sync: If enabled, requests V-Sync to be disabled when writing a movie. This can speed up video writing if the hardware is fast enough to render, encode and save the video at a framerate higher than the monitor's refresh rate. This setting has no effect if the operating system or graphics driver forces V-Sync with no way for applications to disable it.

FPS: The rendered frames per second in the output movie. Higher values result in smoother animation, at the cost of longer rendering times and larger output file sizes. Most video hosting platforms do not support FPS values higher than 60, but you can use a higher value and use that to generate motion blur.

Audio Quality: The audio quality to use when writing a video to an OGV file, between -0.1 and 1.0 (inclusive). Higher quality values result in better audio quality at the cost of very slightly larger file sizes. Recommended quality values are between 0.3 and 0.5. Even at quality 1.0, compression remains lossy.

Encoding Speed: The speed level to use when writing a video to an OGV file. Faster speed levels have less compression efficiency. The image quality stays barely the same.

Keyframe Interval: Also known as GOP (Group Of Pictures), the maximum number of inter-frames to use when writing to an OGV file. Higher values can improve compression efficiency without quality loss but at the cost of slower video seeks.

When using the disabled or 2d stretch modes, the output file's resolution is set by the window size. Make sure to resize the window before the splash screen has ended. For this purpose, it's recommended to adjust the Display > Window > Size > Window Width Override and Window Height Override advanced project settings.

See also Rendering at a higher resolution than the screen resolution.

To safely quit a project that is using Movie Maker mode, use the X button at the top of the window, or call get_tree().quit() in a script. You can also use the --quit-after N command line argument where N is the number of frames to render before quitting.

Pressing F8 (Cmd + . on macOS) or pressing Ctrl + C on the terminal running Godot is not recommended, as it will result in an improperly formatted AVI file with no duration information. For PNG image sequences, PNG images will not be negatively altered, but the associated WAV file will still lack duration information. OGV files might end up with slightly different duration video and audio tracks but still valid.

Some video players may still be able to play the AVI or WAV file with working video and audio. However, software that makes use of the AVI or WAV file such as video editors may not be able to open the file. Using a video converter program can help in those cases.

If you're using an AnimationPlayer to control a "main action" in the scene (such as camera movement), you can enable the Movie Quit On Finish property on the AnimationPlayer node in question. When enabled, this property will make Godot quit on its own when an animation is done playing and the engine is running in Movie Maker mode. Note that this property has no effect on looping animations. Therefore, you need to make sure that the animation is set as non-looping.

The movie feature tag can be used to override specific project settings. This is useful to enable high-quality graphics settings that wouldn't be fast enough to run in real-time speeds on your hardware. Remember that putting every setting to its maximum value can still slow down movie saving speed, especially when recording at higher resolutions. Therefore, it's still recommended to only increase graphics settings if they make a meaningful difference in the output image.

This feature tag can also be queried in a script to increase quality settings that are set in the Environment resource. For example, to further improve SDFGI detail and reduce light leaking:

The overall rendering quality can be improved significantly by rendering at high resolutions such as 4K or 8K.

For 3D rendering, Godot provides a Rendering > Scaling 3D > Scale advanced project setting, which can be set above 1.0 to obtain supersample antialiasing. The 3D rendering is then downsampled when it's drawn on the viewport. This provides an expensive but high-quality form of antialiasing, without increasing the final output resolution.

Consider using this project setting first, as it avoids slowing down movie writing speeds and increasing output file size compared to actually increasing the output resolution.

If you wish to render 2D at a higher resolution, or if you actually need the higher raw pixel output for 3D rendering, you can increase the resolution above what the screen allows.

By default, Godot uses the disabled stretch modes in projects. If using disabled or canvas_items stretch mode, the window size dictates the output video resolution.

On the other hand, if the project is configured to use the viewport stretch mode, the viewport resolution dictates the output video resolution. The viewport resolution is set using the Display > Window > Size > Viewport Width and Viewport Height project settings. This can be used to render a video at a higher resolution than the screen resolution.

To make the window smaller during recording without affecting the output video resolution, you can set the Display > Window > Size > Window Width Override and Window Height Override advanced project settings to values greater than 0.

To apply a resolution override only when recording a movie, you can override those settings with the movie feature tag.

Some common post-processing steps are listed below.

When using several post-processing steps, try to perform all of them in a single FFmpeg command. This will save encoding time and improve quality by avoiding multiple lossy encoding steps.

While some platforms such as YouTube support uploading the AVI file directly, many others will require a conversion step beforehand. HandBrake (GUI) and FFmpeg (CLI) are popular open source tools for this purpose. FFmpeg has a steeper learning curve, but it's more powerful.

The command below converts an OGV/AVI video to an MP4 (H.264) video with a Constant Rate Factor (CRF) of 15. This results in a relatively large file, but is well-suited for platforms that will re-encode your videos to reduce their size (such as most video sharing websites):

To get a smaller file at the cost of quality, increase the CRF value in the above command.

To get a file with a better size/quality ratio (at the cost of slower encoding times), add -preset veryslow before -crf 15 in the above command. On the contrary, -preset veryfast can be used to achieve faster encoding at the cost of a worse size/quality ratio.

If you chose to record a PNG image sequence with a WAV file beside it, you need to convert it to a video before you can use it elsewhere.

The filename for the PNG image sequence generated by Godot always contains 8 digits, starting at 0 with zero-padded numbers. If you specify an output path folder/example.png, Godot will write folder/example00000000.png, folder/example00000001.png, and so on in that folder. The audio will be saved at folder/example.wav.

The FPS is specified using the -r argument. It should match the FPS specified during recording. Otherwise, the video will appear to be slowed down or sped up, and audio will be out of sync with the video.

If you recorded a PNG image sequence with transparency enabled, you need to use a video format that supports storing transparency. MP4/H.264 doesn't support storing transparency, so you can use WebM/VP9 as an alternative:

You can trim parts of the video you don't want to keep after the video is recorded. For example, to discard everything before 12.1 seconds and keep only 5.2 seconds of video after that point:

Cutting videos can also be done with the GUI tool LosslessCut.

The following command resizes a video to be 1080 pixels tall (1080p), while preserving its existing aspect ratio:

The following command changes a video's framerate to 30 FPS, dropping some of the original frames if there are more in the input video:

Godot does not have built-in support for motion blur, but it can still be created in recorded videos.

If you record the video at a multiple of the original framerate, you can blend the frames together then reduce the frameate to produce a video with accumulation motion blur. This motion blur can look very good, but it can take a long time to generate since you have to render many more frames per second (on top of the time spent on post-processing).

Example with a 240 FPS source video, generating 4× motion blur and decreasing its output framerate to 60 FPS:

This also makes effects that converge over several frames (such as temporal antialiasing, SDFGI and volumetric fog) converge faster and therefore look better, since they'll be able to work with more data at a given time. See Reducing framerate if you want to get this benefit without adding motion blur.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
godot --path /path/to/your_project --write-movie output.avi
```

Example 2 (unknown):
```unknown
godot --path /path/to/your_project --write-movie output.avi --resolution 1280x720
```

Example 3 (unknown):
```unknown
godot --path /path/to/your_project --write-movie output.avi --fixed-fps 30
```

Example 4 (unknown):
```unknown
extends Node3D

func _ready():
    if OS.has_feature("movie"):
        # When recording a movie, improve SDFGI cell density
        # without decreasing its maximum distance.
        get_viewport().world_3d.environment.sdfgi_min_cell_size *= 0.25
        get_viewport().world_3d.environment.sdfgi_cascades = 8
```

---

## Customizing the mouse cursor — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/inputs/custom_mouse_cursor.html

**Contents:**
- Customizing the mouse cursor
- Using project settings
- Using a script
- Cursor list
- User-contributed notes

You might want to change the appearance of the mouse cursor in your game in order to suit the overall design. There are two ways to customize the mouse cursor:

Using project settings. This is simpler, but more limited.

Using a script. This is more customizable, but involves scripting.

You could display a "software" mouse cursor by hiding the mouse cursor and moving a Sprite2D to the cursor position in a _process() method, but this will add at least one frame of latency compared to a "hardware" mouse cursor. Therefore, it's recommended to use the approach described here whenever possible.

If you have to use the "software" approach, consider adding an extrapolation step to better display the actual mouse input.

Open the Project Settings and go to Display > Mouse Cursor. You will see the settings Custom Image, Custom Image Hotspot, and Tooltip Position Offset.

Custom Image is the desired image that you would like to set as the mouse cursor. Custom Hotspot is the point in the image that you would like to use as the cursor's detection point.

The custom image must be 256×256 pixels at most. To avoid rendering issues, sizes of 128×128 or smaller are recommended.

On the web platform, the maximum allowed cursor image size is 128×128.

Create a Node and attach the following script.

Check Input.set_custom_mouse_cursor()'s documentation for more information on usage and platform-specific caveats.

There are multiple mouse cursors you can define, documented in the Input.CursorShape enum. Which ones you want to use depends on your use case.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (gdscript):
```gdscript
extends Node


# Load the custom images for the mouse cursor.
var arrow = load("res://arrow.png")
var beam = load("res://beam.png")


func _ready():
    # Changes only the arrow shape of the cursor.
    # This is similar to changing it in the project settings.
    Input.set_custom_mouse_cursor(arrow)

    # Changes a specific shape of the cursor (here, the I-beam shape).
    Input.set_custom_mouse_cursor(beam, Input.CURSOR_IBEAM)
```

Example 2 (unknown):
```unknown
using Godot;

public partial class MyNode : Node
{
    public override void _Ready()
    {
        // Load the custom images for the mouse cursor.
        var arrow = ResourceLoader.Load("res://arrow.png");
        var beam = ResourceLoader.Load("res://beam.png");

        // Changes only the arrow shape of the cursor.
        // This is similar to changing it in the project settings.
        Input.SetCustomMouseCursor(arrow);

        // Changes a specific shape of the cursor (here, the I-beam shape).
        Input.SetCustomMouseCursor(beam, Input.CursorShape.Ibeam);
    }
}
```

---

## Custom drawing in 2D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/custom_drawing_in_2d.html

**Contents:**
- Custom drawing in 2D
- Introduction
- Drawing
- Updating
- Coordinates and line width alignment
- Antialiased drawing
- Tools
- Example 1: drawing a custom shape
  - Drawing a custom polygon shape
  - Drawing connected lines

Godot has nodes to draw sprites, polygons, particles, text, and many other common game development needs. However, if you need something specific not covered with the standard nodes you can make any 2D node (for example, Control or Node2D-based) draw on screen using custom commands.

Custom drawing in a 2D node is really useful. Here are some use cases:

Drawing shapes or logic that existing nodes can't do, such as an image with trails or a special animated polygon.

Drawing a large number of simple objects, such as a grid or a board for a 2d game. Custom drawing avoids the overhead of using a large number of nodes, possibly lowering memory usage and improving performance.

Making a custom UI control. There are plenty of controls available, but when you have unusual needs, you will likely need a custom control.

Add a script to any CanvasItem derived node, like Control or Node2D. Then override the _draw() function.

Draw commands are described in the CanvasItem class reference. There are plenty of them and we will see some of them in the examples below.

The _draw function is only called once, and then the draw commands are cached and remembered, so further calls are unnecessary.

If re-drawing is required because a variable or something else changed, call CanvasItem.queue_redraw in that same node and a new _draw() call will happen.

Here is a little more complex example, where we have a texture variable that can be modified at any time, and using a setter, it forces a redraw of the texture when modified:

To see it in action, you can set the texture to be the Godot icon on the editor by dragging and dropping the default icon.svg from the FileSystem tab to the Texture property on the Inspector tab. When changing the Texture property value while the previous script is running, the texture will also change automatically.

In some cases, we may need to redraw every frame. For this, call queue_redraw from the _process method, like this:

The drawing API uses the CanvasItem's coordinate system, not necessarily pixel coordinates. This means _draw() uses the coordinate space created after applying the CanvasItem's transform. Additionally, you can apply a custom transform on top of it by using draw_set_transform or draw_set_transform_matrix.

When using draw_line, you should consider the width of the line. When using a width that is an odd size, the position of the start and end points should be shifted by 0.5 to keep the line centered, as shown below.

The same applies to the draw_rect method with filled = false.

Godot offers method parameters in draw_line to enable antialiasing, but not all custom drawing methods offer this antialiased parameter.

For custom drawing methods that don't provide an antialiased parameter, you can enable 2D MSAA instead, which affects rendering in the entire viewport. This provides high-quality antialiasing, but a higher performance cost and only on specific elements. See 2D antialiasing for more information.

Here is a comparison of a line of minimal width (width=-1) drawn with antialiased=false, antialiased=true, and antialiased=false with 2D MSAA 2x, 4x, and 8x enabled.

Drawing your own nodes might also be desired while running them in the editor. This can be used as a preview or visualization of some feature or behavior.

To do this, you can use the tool annotation on both GDScript and C#. See the example below and Running code in the editor for more information.

We will now use the custom drawing functionality of the Godot Engine to draw something that Godot doesn't provide functions for. We will recreate the Godot logo but with code- only using drawing functions.

You will have to code a function to perform this and draw it yourself.

The following instructions use a fixed set of coordinates that could be too small for high resolution screens (larger than 1080p). If that is your case, and the drawing is too small consider increasing your window scale in the project setting Display > Window > Stretch > Scale to adjust the project to a higher resolution (a 2 or 4 scale tends to work well).

While there is a dedicated node to draw custom polygons ( Polygon2D), we will use in this case exclusively lower level drawing functions to combine them on the same node and be able to create more complex shapes later on.

First, we will define a set of points -or X and Y coordinates- that will form the base of our shape:

This format, while compact, is not the one that Godot understands to draw a polygon. In a different scenario we could have to load these coordinates from a file or calculate the positions while the application is running, so some transformation may be needed.

To transform these coordinates into the right format, we will create a new method float_array_to_Vector2Array(). Then we will override the _ready() function, which Godot will call only once -at the start of the execution- to load those coordinates into a variable:

To finally draw our first shape, we will use the method draw_polygon and pass the points (as an array of Vector2 coordinates) and its color, like this:

When running it you should see something like this:

Note the lower part of the logo looks segmented- this is because a low amount of points were used to define that part. To simulate a smooth curve, we could add more points to our array, or maybe use a mathematical function to interpolate a curve and create a smooth shape from code (see example 2).

Polygons will always connect its last defined point to its first one in order to have a closed shape.

Drawing a sequence of connected lines that don't close down to form a polygon is very similar to the previous method. We will use a connected set of lines to draw Godot's logo mouth.

First, we will define the list of coordinates that form the mouth shape, like this:

We will load these coordinates into a variable and define an additional variable with the configurable line thickness:

And finally we will use the method draw_polyline to actually draw the line, like this:

You should get the following output:

Unlike draw_polygon(), polylines can only have a single unique color for all its points (the second argument). This method has 2 additional arguments: the width of the line (which is as small as possible by default) and enabling or disabling the antialiasing (it is disabled by default).

The order of the _draw calls is important- like with the Node positions on the tree hierarchy, the different shapes will be drawn from top to bottom, resulting in the latest shapes hiding earlier ones if they overlap. In this case we want the mouth drawn over the head, so we put it afterwards.

Notice how we can define colors in different ways, either with a hexadecimal code or a predefined color name. Check the class Color for other constants and ways to define Colors.

To create the eyes, we are going to add 4 additional calls to draw the eye shapes, in different sizes, colors and positions.

To draw a circle, you position it based on its center using the draw_circle method. The first parameter is a Vector2 with the coordinates of its center, the second is its radius, and the third is its color:

When executing it, you should have something like this:

For partial, unfilled arcs (portions of a circle shape between certain arbitrary angles), you can use the method draw_arc.

To draw the final shape (the nose) we will use a line to approximate it.

draw_line can be used to draw a single segment by providing its start and end coordinates as arguments, like this:

You should now be able to see the following shape on screen:

Note that if multiple unconnected lines are going to be drawn at the same time, you may get additional performance by drawing all of them in a single call, using the draw_multiline method.

While using the Label Node is the most common way to add text to your application, the low-level _draw function includes functionality to add text to your custom Node drawing. We will use it to add the name "GODOT" under the robot head.

We will use the draw_string method to do it, like this:

Here we first load into the defaultFont variable the configured default theme font (a custom one can be set instead) and then we pass the following parameters: font, position, text, horizontal alignment, width, and font size.

You should see the following on your screen:

Additional parameters as well as other methods related to text and characters can be found on the CanvasItem class reference.

While the code so far is able to draw the logo on a running window, it will not show up on the 2D view on the editor. In certain cases you would also like to show your custom Node2D or control on the editor, to position and scale it appropriately, like most other nodes do.

To show the logo directly on the editor (without running it), you can use the @tool annotation to request the custom drawing of the node to also appear while editing, like this:

You will need to save your scene, rebuild your project (for C# only) and reload the current scene manually at the menu option Scene > Reload Saved Scene to refresh the current node in the 2D view the first time you add or remove the @tool annotation.

If we wanted to make the custom shape change at runtime, we could modify the methods called or its arguments at execution time, or apply a transform.

For example, if we want the custom shape we just designed to rotate, we could add the following variable and code to the _ready and _process methods:

The problem with the above code is that because we have created the points approximately on a rectangle starting from the upper left corner, the (0, 0) coordinate and extending to the right and down, we see that the rotation is done using the top left corner as pivot. A position transform change on the node won't help us here, as the rotation transform is applied first.

While we could rewrite all of the points' coordinates to be centered around (0, 0), including negative coordinates, that would be a lot of work.

One possible way to work around this is to use the lower level draw_set_transform method to fix this issue, translating all points in the CanvasItem's own space, and then moving it back to its original place with a regular node transform, either in the editor or in code, like this:

This is the result, rotating around a pivot now on (60, 60):

If what we wanted to animate was a property inside the _draw() call, we must remember to call queue_redraw() to force a refresh, as otherwise it would not be updated on screen.

For example, this is how we can make the robot appear to open and close its mouth, by changing the width of its mouth line follow a sinusoidal (sin) curve:

It will look somewhat like this when run:

Please note that _mouth_width is a user defined property like any other and it or any other used as a drawing argument can be animated using more standard and high-level methods such as a Tween or an AnimationPlayer Node. The only difference is that a queue_redraw() call is needed to apply those changes so they get shown on screen.

The previous example was useful to learn how to draw and modify nodes with custom shapes and animations. This could have some advantages, such as using exact coordinates and vectors for drawing, rather than bitmaps -which means they will scale well when transformed on screen. In some cases, similar results could be achieved composing higher level functionality with nodes such as sprites or AnimatedSprites loading SVG resources (which are also images defined with vectors) and the AnimationPlayer node.

In other cases that will not be possible because we will not know what the resulting graphical representation will be before running the code. Here we will see how to draw a dynamic line whose coordinates are not known beforehand, and are affected by the user's input.

Let's assume we want to draw a straight line between 2 points, the first one will be fixed on the upper left corner (0, 0) and the second will be defined by the cursor position on screen.

We could draw a dynamic line between those 2 points like this:

In this example we obtain the position of the mouse in the default viewport every frame with the method get_mouse_position. If the position has changed since the last draw request (a small optimization to avoid redrawing on every frame)- we will schedule a redraw. Our _draw() method only has one line: requesting the drawing of a green line of width 10 pixels between the top left corner and that obtained position.

The width, color, and position of the starting point can be configured with with the corresponding properties.

It should look like this when run:

The above example works, but we may want to join those 2 points with a different shape or function, other than a straight line.

Let's try now creating an arc (a portion of a circumference) between both points.

Exporting the line starting point, segments, width, color, and antialiasing will allow us to modify those properties very easily directly from the editor inspector panel:

To draw the arc, we can use the method draw_arc. There are many arcs that pass through 2 points, so we will chose for this example the semicircle that has its center in the middle point between the 2 initial points.

Calculating this arc will be more complex than in the case of the line:

The center of the semicircle will be the middle point between both points. The radius will be half the distance between both points. The start and end angles will be the angles of the vector from point1 to point2 and vice-versa. Note we had to normalize the end_angle in positive values because if end_angle is less than start_angle, the arc will be drawn counter-clockwise, which we don't want in this case (the arc would be upside-down).

The result should be something like this, with the arc going down and between the points:

Feel free to play with the parameters in the inspector to obtain different results: change the color, the width, the antialiasing, and increase the number of segments to increase the curve smoothness, at the cost of extra performance.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
extends Node2D

func _draw():
    pass  # Your draw commands here.
```

Example 2 (unknown):
```unknown
using Godot;

public partial class MyNode2D : Node2D
{
    public override void _Draw()
    {
        // Your draw commands here.
    }
}
```

Example 3 (gdscript):
```gdscript
extends Node2D

@export var texture : Texture2D:
    set(value):
        texture = value
        queue_redraw()

func _draw():
    draw_texture(texture, Vector2())
```

Example 4 (unknown):
```unknown
using Godot;

public partial class MyNode2D : Node2D
{
    private Texture2D _texture;

    [Export]
    public Texture2D Texture
    {
        get
        {
            return _texture;
        }

        set
        {
            _texture = value;
            QueueRedraw();
        }
    }

    public override void _Draw()
    {
        DrawTexture(_texture, new Vector2());
    }
}
```

---

## Cutout animation — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/animation/cutout_animation.html

**Contents:**
- Cutout animation
- What is it?
- Cutout animation in Godot
- Making of GBot
- Setting up the rig
- Adjusting the pivot
- RemoteTransform2D node
- Completing the skeleton
- Skeletons
- IK chains

The content of this page was not yet updated for Godot 4.5 and may be outdated. If you know how to improve this page or you can confirm that it's up to date, feel free to open a pull request.

Traditionally, cutout animation is a type of stop motion animation in which pieces of paper (or other thin material) are cut into special shapes and arranged in two-dimensional representations of characters and objects. Characters' bodies are usually made out of several pieces. The pieces are arranged and photographed once for each frame of the film. The animator moves and rotates the parts in small increments between each shot to create the illusion of movement when the images are played back quickly in sequence.

Simulations of cutout animation can now be created using software as seen in South Park and Jake and the Never Land Pirates.

In video games, this technique has also become popular. Examples of this are Paper Mario or Rayman Origins .

Godot provides tools for working with cutout rigs, and is ideal for the workflow:

The animation system is fully integrated with the engine: This means animations can control much more than just motion of objects. Textures, sprite sizes, pivots, opacity, color modulation, and more, can all be animated and blended.

Combine animation styles: AnimatedSprite2D allows traditional cel animation to be used alongside cutout animation. In cel animation different animation frames use entirely different drawings rather than the same pieces positioned differently. In an otherwise cutout-based animation, cel animation can be used selectively for complex parts such as hands, feet, changing facial expressions, etc.

Custom Shaped Elements: Custom shapes can be created with Polygon2D allowing UV animation, deformations, etc.

Particle Systems: A cutout animation rig can be combined with particle systems. This can be useful for magic effects, jetpacks, etc.

Custom Colliders: Set colliders and influence areas in different parts of the skeletons, great for bosses and fighting games.

Animation Tree: Allows complex combinations and blending between several animations, the same way it works in 3D.

For this tutorial, we will use as demo content the pieces of the GBot character, created by Andreas Esau.

Get your assets: cutout_animation_assets.zip.

Create an empty Node2D as root of the scene, we will work under it:

The first node of the model is the hip. Generally, both in 2D and 3D, the hip is the root of the skeleton. This makes it easier to animate:

Next will be the torso. The torso needs to be a child of the hip, so create a child sprite and load the torso texture, later accommodate it properly:

This looks good. Let's see if our hierarchy works as a skeleton by rotating the torso. We can do this be pressing E to enter rotate mode, and dragging with the left mouse button. To exit rotate mode hit ESC.

The rotation pivot is wrong and needs to be adjusted.

This small cross in the middle of the Sprite2D is the rotation pivot:

The pivot can be adjusted by changing the offset property in the Sprite2D:

The pivot can also be adjusted visually. While hovering over the desired pivot point, press V to move the pivot there for the selected Sprite2D. There is also a tool in the tool bar that has a similar function.

Continue adding body pieces, starting with the right arm. Make sure to put each sprite in its correct place in the hierarchy, so its rotations and translations are relative to its parent:

With the left arm there's a problem. In 2D, child nodes appear in front of their parents:

We want the left arm to appear behind the hip and the torso. We could move the left arm nodes behind the hip (above the hip node in the scene hierarchy), but then the left arm is no longer in its proper place in the hierarchy. This means it wouldn't be affected by the movement of the torso. We'll fix this problem with RemoteTransform2D nodes.

You can also fix depth ordering problems by adjusting the Z property of any node inheriting from Node2D.

The RemoteTransform2D node transforms nodes somewhere else in the hierarchy. This node applies its own transform (including any transformation it inherits from its parents) to the remote node it targets.

This allows us to correct the visibility order of our elements, independently of the locations of those parts in the cutout hierarchy.

Create a RemoteTransform2D node as a child of the torso. Call it remote_arm_l. Create another RemoteTransform2D node inside the first and call it remote_hand_l. Use the Remote Path property of the two new nodes to target the arm_l and hand_l sprites respectively:

Moving the RemoteTransform2D nodes now moves the sprites. So we can create animations by adjusting the RemoteTransform2D transforms:

Complete the skeleton by following the same steps for the rest of the parts. The resulting scene should look similar to this:

The resulting rig will be easy to animate. By selecting the nodes and rotating them you can animate forward kinematics (FK) efficiently.

For simple objects and rigs this is fine, but there are limitations:

Selecting sprites in the main viewport can become difficult in complex rigs. The scene tree ends up being used to select parts instead, which can be slower.

Inverse Kinematics (IK) is useful for animating extremities like hands and feet, and can't be used with our rig in its current state.

To solve these problems we'll use Godot's skeletons.

In Godot there is a helper to create "bones" between nodes. The bone-linked nodes are called skeletons.

As an example, let's turn the right arm into a skeleton. To create a skeleton, a chain of nodes must be selected from top to bottom:

Then, click on the Skeleton menu and select Make Bones.

This will add bones covering the arm, but the result may be surprising.

Why does the hand lack a bone? In Godot, a bone connects a node with its parent. And there's currently no child of the hand node. With this knowledge let's try again.

The first step is creating an endpoint node. Any kind of node will do, but Marker2D is preferred because it's visible in the editor. The endpoint node will ensure that the last bone has orientation.

Now select the whole chain, from the endpoint to the arm and create bones:

The result resembles a skeleton a lot more, and now the arm and forearm can be selected and animated.

Create endpoints for all important extremities. Generate bones for all articulable parts of the cutout, with the hip as the ultimate connection between all of them.

You may notice that an extra bone is created when connecting the hip and torso. Godot has connected the hip node to the scene root with a bone, and we don't want that. To fix this, select the root and hip node, open the Skeleton menu, click clear bones.

Your final skeleton should look something like this:

You might have noticed a second set of endpoints in the hands. This will make sense soon.

Now that the whole figure is rigged, the next step is setting up the IK chains. IK chains allow for more natural control of extremities.

IK stands for inverse kinematics. It's a convenient technique for animating the position of hands, feet and other extremities of rigs like the one we've made. Imagine you want to pose a character's foot in a specific position on the ground. Without IK chains, each motion of the foot would require rotating and positioning several other bones (the shin and the thigh at least). This would be quite complex and lead to imprecise results. IK allows us to move the foot directly while the shin and thigh self-adjust.

IK chains in Godot currently work in the editor only, not at runtime. They are intended to ease the process of setting keyframes, and are not currently useful for techniques like procedural animation.

To create an IK chain, select a chain of bones from endpoint to the base for the chain. For example, to create an IK chain for the right leg, select the following:

Then enable this chain for IK. Go to Edit > Make IK Chain.

As a result, the base of the chain will turn Yellow.

Once the IK chain is set up, grab any child or grand-child of the base of the chain (e.g. a foot), and move it. You'll see the rest of the chain adjust as you adjust its position.

The following section will be a collection of tips for creating animation for your cutout rigs. For more information on how the animation system in Godot works, see Introduction to the animation features.

Special contextual elements appear in the top toolbar when the animation editor window is open:

The key button inserts location, rotation, and scale keyframes for the selected objects or bones at the current playhead position.

The "loc", "rot", and "scl" toggle buttons to the left of the key button modify its function, allowing you to specify which of the three properties keyframes will be created for.

Here's an illustration of how this can be useful: Imagine you have a node which already has two keyframes animating its scale only. You want to add an overlapping rotation movement to the same node. The rotation movement should begin and end at different times from the scale change that's already set up. You can use the toggle buttons to have only rotation information added when you add a new keyframe. This way, you can avoid adding unwanted scale keyframes which would disrupt the existing scale animation.

Think of a rest pose as a default pose that your cutout rig should be set to when no other pose is active in your game. Create a rest pose as follows:

1. Make sure the rig parts are positioned in what looks like a "resting" arrangement.

Create a new animation, rename it "rest".

Select all nodes in your rig (box selection should work fine).

4. Make sure the "loc", "rot", and "scl" toggle buttons are all active in the toolbar.

5. Press the key button. Keys will be inserted for all selected parts storing their current arrangement. This pose can now be recalled when necessary in your game by playing the "rest" animation you've created.

When animating a cutout rig, often it's only the rotation of the nodes that needs to change. Location and scale are rarely used.

So when inserting keys, you might find it convenient to have only the "rot" toggle active most of the time:

This will avoid the creation of unwanted animation tracks for position and scale.

When editing IK chains, it's not necessary to select the whole chain to add keyframes. Selecting the endpoint of the chain and inserting a keyframe will automatically insert keyframes for all other parts of the chain too.

Sometimes it is necessary to have a node change its visual depth relative to its parent node during an animation. Think of a character facing the camera, who pulls something out from behind his back and holds it out in front of him. During this animation the whole arm and the object in his hand would need to change their visual depth relative to the body of the character.

To help with this there's a keyframable "Behind Parent" property on all Node2D-inheriting nodes. When planning your rig, think about the movements it will need to perform and give some thought to how you'll use "Behind Parent" and/or RemoteTransform2D nodes. They provide overlapping functionality.

To apply the same easing curve to multiple keyframes at once:

Select the relevant keys.

Click on the pencil icon in the bottom right of the animation panel. This will open the transition editor.

In the transition editor, click on the desired curve to apply it.

Skeletal deform can be used to augment a cutout rig, allowing single pieces to deform organically (e.g. antennae that wobble as an insect character walks).

This process is described in a separate tutorial.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Kinematic character (2D) — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/physics/kinematic_character_2d.html

**Contents:**
- Kinematic character (2D)
- Introduction
- Physics process
- Scene setup
- Moving the kinematic character
- User-contributed notes

Yes, the name sounds strange. "Kinematic Character". What is that? The reason for the name is that, when physics engines came out, they were called "Dynamics" engines (because they dealt mainly with collision responses). Many attempts were made to create a character controller using the dynamics engines, but it wasn't as easy as it seemed. Godot has one of the best implementations of dynamic character controller you can find (as it can be seen in the 2d/platformer demo), but using it requires a considerable level of skill and understanding of physics engines (or a lot of patience with trial and error).

Some physics engines, such as Havok seem to swear by dynamic character controllers as the best option, while others (PhysX) would rather promote the kinematic one.

So, what is the difference?:

A dynamic character controller uses a rigid body with an infinite inertia tensor. It's a rigid body that can't rotate. Physics engines always let objects move and collide, then solve their collisions all together. This makes dynamic character controllers able to interact with other physics objects seamlessly, as seen in the platformer demo. However, these interactions are not always predictable. Collisions can take more than one frame to be solved, so a few collisions may seem to displace a tiny bit. Those problems can be fixed, but require a certain amount of skill.

A kinematic character controller is assumed to always begin in a non-colliding state, and will always move to a non-colliding state. If it starts in a colliding state, it will try to free itself like rigid bodies do, but this is the exception, not the rule. This makes their control and motion a lot more predictable and easier to program. However, as a downside, they can't directly interact with other physics objects, unless done by hand in code.

This short tutorial focuses on the kinematic character controller. It uses the old-school way of handling collisions, which is not necessarily simpler under the hood, but well hidden and presented as an API.

To manage the logic of a kinematic body or character, it is always advised to use physics process, because it's called before physics step and its execution is in sync with physics server, also it is called the same amount of times per second, always. This makes physics and motion calculation work in a more predictable way than using regular process, which might have spikes or lose precision if the frame rate is too high or too low.

To have something to test, here's the scene (from the tilemap tutorial): kinematic_character_2d_starter.zip. We'll be creating a new scene for the character. Use the robot sprite and create a scene like this:

You'll notice that there's a warning icon next to our CollisionShape2D node; that's because we haven't defined a shape for it. Create a new CircleShape2D in the shape property of CollisionShape2D. Click on <CircleShape2D> to go to the options for it, and set the radius to 30:

Note: As mentioned before in the physics tutorial, the physics engine can't handle scale on most types of shapes (only collision polygons, planes and segments work), so always change the parameters (such as radius) of the shape instead of scaling it. The same is also true for the kinematic/rigid/static bodies themselves, as their scale affects the shape scale.

Now, create a script for the character, the one used as an example above should work as a base.

Finally, instance that character scene in the tilemap, and make the map scene the main one, so it runs when pressing play.

Go back to the character scene, and open the script, the magic begins now! Kinematic body will do nothing by default, but it has a useful function called CharacterBody2D.move_and_collide(). This function takes a Vector2 as an argument, and tries to apply that motion to the kinematic body. If a collision happens, it stops right at the moment of the collision.

So, let's move our sprite downwards until it hits the floor:

The result is that the character will move, but stop right when hitting the floor. Pretty cool, huh?

The next step will be adding gravity to the mix, this way it behaves a little more like a regular game character:

Now the character falls smoothly. Let's make it walk to the sides, left and right when touching the directional keys. Remember that the values being used (for speed at least) are pixels/second.

This adds basic support for walking when pressing left and right:

This is a good starting point for a platformer. A more complete demo can be found in the demo zip distributed with the engine, or in the https://github.com/godotengine/godot-demo-projects/tree/master/2d/kinematic_character.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
extends CharacterBody2D

func _physics_process(delta):
    pass
```

Example 2 (unknown):
```unknown
using Godot;

public partial class MyCharacterBody2D : CharacterBody2D
{
    public override void _PhysicsProcess(double delta)
    {
    }
}
```

Example 3 (unknown):
```unknown
extends CharacterBody2D

func _physics_process(delta):
    move_and_collide(Vector2(0, 1)) # Move down 1 pixel per physics frame
```

Example 4 (unknown):
```unknown
using Godot;

public partial class MyCharacterBody2D : CharacterBody2D
{
    public override void _PhysicsProcess(double delta)
    {
        // Move down 1 pixel per physics frame
        MoveAndCollide(new Vector2(0, 1));
    }
}
```

---

## Node — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/classes/class_node.html

**Contents:**
- Node
- Description
- Tutorials
- Properties
- Methods
- Signals
- Enumerations
- Constants
- Property Descriptions
- Method Descriptions

Inherited By: AnimationMixer, AudioStreamPlayer, CanvasItem, CanvasLayer, EditorFileSystem, EditorPlugin, EditorResourcePreview, HTTPRequest, InstancePlaceholder, MissingNode, MultiplayerSpawner, MultiplayerSynchronizer, NavigationAgent2D, NavigationAgent3D, Node3D, ResourcePreloader, ShaderGlobalsOverride, StatusIndicator, Timer, Viewport, WorldEnvironment

Base class for all scene objects.

Nodes are Godot's building blocks. They can be assigned as the child of another node, resulting in a tree arrangement. A given node can contain any number of nodes as children with the requirement that all siblings (direct children of a node) should have unique names.

A tree of nodes is called a scene. Scenes can be saved to the disk and then instantiated into other scenes. This allows for very high flexibility in the architecture and data model of Godot projects.

Scene tree: The SceneTree contains the active tree of nodes. When a node is added to the scene tree, it receives the NOTIFICATION_ENTER_TREE notification and its _enter_tree() callback is triggered. Child nodes are always added after their parent node, i.e. the _enter_tree() callback of a parent node will be triggered before its child's.

Once all nodes have been added in the scene tree, they receive the NOTIFICATION_READY notification and their respective _ready() callbacks are triggered. For groups of nodes, the _ready() callback is called in reverse order, starting with the children and moving up to the parent nodes.

This means that when adding a node to the scene tree, the following order will be used for the callbacks: _enter_tree() of the parent, _enter_tree() of the children, _ready() of the children and finally _ready() of the parent (recursively for the entire scene tree).

Processing: Nodes can override the "process" state, so that they receive a callback on each frame requesting them to process (do something). Normal processing (callback _process(), toggled with set_process()) happens as fast as possible and is dependent on the frame rate, so the processing time delta (in seconds) is passed as an argument. Physics processing (callback _physics_process(), toggled with set_physics_process()) happens a fixed number of times per second (60 by default) and is useful for code related to the physics engine.

Nodes can also process input events. When present, the _input() function will be called for each input that the program receives. In many cases, this can be overkill (unless used for simple projects), and the _unhandled_input() function might be preferred; it is called when the input event was not handled by anyone else (typically, GUI Control nodes), ensuring that the node only receives the events that were meant for it.

To keep track of the scene hierarchy (especially when instantiating scenes into other scenes), an "owner" can be set for the node with the owner property. This keeps track of who instantiated what. This is mostly useful when writing editors and tools, though.

Finally, when a node is freed with Object.free() or queue_free(), it will also free all its children.

Groups: Nodes can be added to as many groups as you want to be easy to manage, you could create groups like "enemies" or "collectables" for example, depending on your game. See add_to_group(), is_in_group() and remove_from_group(). You can then retrieve all nodes in these groups, iterate them and even call methods on groups via the methods on SceneTree.

Networking with nodes: After connecting to a server (or making one, see ENetMultiplayerPeer), it is possible to use the built-in RPC (remote procedure call) system to communicate over the network. By calling rpc() with a method name, it will be called locally and in all connected peers (peers = clients and the server that accepts connections). To identify which node receives the RPC call, Godot will use its NodePath (make sure node names are the same on all peers). Also, take a look at the high-level networking tutorial and corresponding demos.

Note: The script property is part of the Object class, not Node. It isn't exposed like most properties but does have a setter and getter (see Object.set_script() and Object.get_script()).

PhysicsInterpolationMode

physics_interpolation_mode

process_physics_priority

process_thread_group_order

BitField[ProcessThreadMessages]

process_thread_messages

_enter_tree() virtual

_get_accessibility_configuration_warnings() virtual const

_get_configuration_warnings() virtual const

_get_focused_accessibility_element() virtual const

_input(event: InputEvent) virtual

_physics_process(delta: float) virtual

_process(delta: float) virtual

_shortcut_input(event: InputEvent) virtual

_unhandled_input(event: InputEvent) virtual

_unhandled_key_input(event: InputEvent) virtual

add_child(node: Node, force_readable_name: bool = false, internal: InternalMode = 0)

add_sibling(sibling: Node, force_readable_name: bool = false)

add_to_group(group: StringName, persistent: bool = false)

atr(message: String, context: StringName = "") const

atr_n(message: String, plural_message: StringName, n: int, context: StringName = "") const

call_deferred_thread_group(method: StringName, ...) vararg

call_thread_safe(method: StringName, ...) vararg

can_auto_translate() const

duplicate(flags: int = 15) const

find_child(pattern: String, recursive: bool = true, owned: bool = true) const

find_children(pattern: String, type: String = "", recursive: bool = true, owned: bool = true) const

find_parent(pattern: String) const

get_accessibility_element() const

get_child(idx: int, include_internal: bool = false) const

get_child_count(include_internal: bool = false) const

get_children(include_internal: bool = false) const

get_index(include_internal: bool = false) const

get_last_exclusive_window() const

get_multiplayer_authority() const

get_node(path: NodePath) const

get_node_and_resource(path: NodePath)

get_node_or_null(path: NodePath) const

get_node_rpc_config() const

get_orphan_node_ids() static

get_path_to(node: Node, use_unique_path: bool = false) const

get_physics_process_delta_time() const

get_process_delta_time() const

get_scene_instance_load_placeholder() const

get_tree_string_pretty()

has_node(path: NodePath) const

has_node_and_resource(path: NodePath) const

is_ancestor_of(node: Node) const

is_displayed_folded() const

is_editable_instance(node: Node) const

is_greater_than(node: Node) const

is_in_group(group: StringName) const

is_inside_tree() const

is_multiplayer_authority() const

is_node_ready() const

is_part_of_edited_scene() const

is_physics_interpolated() const

is_physics_interpolated_and_enabled() const

is_physics_processing() const

is_physics_processing_internal() const

is_processing() const

is_processing_input() const

is_processing_internal() const

is_processing_shortcut_input() const

is_processing_unhandled_input() const

is_processing_unhandled_key_input() const

move_child(child_node: Node, to_index: int)

notify_deferred_thread_group(what: int)

notify_thread_safe(what: int)

print_orphan_nodes() static

propagate_call(method: StringName, args: Array = [], parent_first: bool = false)

propagate_notification(what: int)

queue_accessibility_update()

remove_child(node: Node)

remove_from_group(group: StringName)

reparent(new_parent: Node, keep_global_transform: bool = true)

replace_by(node: Node, keep_groups: bool = false)

reset_physics_interpolation()

rpc(method: StringName, ...) vararg

rpc_config(method: StringName, config: Variant)

rpc_id(peer_id: int, method: StringName, ...) vararg

set_deferred_thread_group(property: StringName, value: Variant)

set_display_folded(fold: bool)

set_editable_instance(node: Node, is_editable: bool)

set_multiplayer_authority(id: int, recursive: bool = true)

set_physics_process(enable: bool)

set_physics_process_internal(enable: bool)

set_process(enable: bool)

set_process_input(enable: bool)

set_process_internal(enable: bool)

set_process_shortcut_input(enable: bool)

set_process_unhandled_input(enable: bool)

set_process_unhandled_key_input(enable: bool)

set_scene_instance_load_placeholder(load_placeholder: bool)

set_thread_safe(property: StringName, value: Variant)

set_translation_domain_inherited()

update_configuration_warnings()

child_entered_tree(node: Node) 🔗

Emitted when the child node enters the SceneTree, usually because this node entered the tree (see tree_entered), or add_child() has been called.

This signal is emitted after the child node's own NOTIFICATION_ENTER_TREE and tree_entered.

child_exiting_tree(node: Node) 🔗

Emitted when the child node is about to exit the SceneTree, usually because this node is exiting the tree (see tree_exiting), or because the child node is being removed or freed.

When this signal is received, the child node is still accessible inside the tree. This signal is emitted after the child node's own tree_exiting and NOTIFICATION_EXIT_TREE.

child_order_changed() 🔗

Emitted when the list of children is changed. This happens when child nodes are added, moved or removed.

editor_description_changed(node: Node) 🔗

Emitted when the node's editor description field changed.

editor_state_changed() 🔗

Emitted when an attribute of the node that is relevant to the editor is changed. Only emitted in the editor.

Emitted when the node is considered ready, after _ready() is called.

Emitted when the node's name is changed, if the node is inside the tree.

replacing_by(node: Node) 🔗

Emitted when this node is being replaced by the node, see replace_by().

This signal is emitted after node has been added as a child of the original parent node, but before all original child nodes have been reparented to node.

Emitted when the node enters the tree.

This signal is emitted after the related NOTIFICATION_ENTER_TREE notification.

Emitted after the node exits the tree and is no longer active.

This signal is emitted after the related NOTIFICATION_EXIT_TREE notification.

Emitted when the node is just about to exit the tree. The node is still valid. As such, this is the right place for de-initialization (or a "destructor", if you will).

This signal is emitted after the node's _exit_tree(), and before the related NOTIFICATION_EXIT_TREE.

ProcessMode PROCESS_MODE_INHERIT = 0

Inherits process_mode from the node's parent. This is the default for any newly created node.

ProcessMode PROCESS_MODE_PAUSABLE = 1

Stops processing when SceneTree.paused is true. This is the inverse of PROCESS_MODE_WHEN_PAUSED, and the default for the root node.

ProcessMode PROCESS_MODE_WHEN_PAUSED = 2

Process only when SceneTree.paused is true. This is the inverse of PROCESS_MODE_PAUSABLE.

ProcessMode PROCESS_MODE_ALWAYS = 3

Always process. Keeps processing, ignoring SceneTree.paused. This is the inverse of PROCESS_MODE_DISABLED.

ProcessMode PROCESS_MODE_DISABLED = 4

Never process. Completely disables processing, ignoring SceneTree.paused. This is the inverse of PROCESS_MODE_ALWAYS.

enum ProcessThreadGroup: 🔗

ProcessThreadGroup PROCESS_THREAD_GROUP_INHERIT = 0

Process this node based on the thread group mode of the first parent (or grandparent) node that has a thread group mode that is not inherit. See process_thread_group for more information.

ProcessThreadGroup PROCESS_THREAD_GROUP_MAIN_THREAD = 1

Process this node (and child nodes set to inherit) on the main thread. See process_thread_group for more information.

ProcessThreadGroup PROCESS_THREAD_GROUP_SUB_THREAD = 2

Process this node (and child nodes set to inherit) on a sub-thread. See process_thread_group for more information.

flags ProcessThreadMessages: 🔗

ProcessThreadMessages FLAG_PROCESS_THREAD_MESSAGES = 1

Allows this node to process threaded messages created with call_deferred_thread_group() right before _process() is called.

ProcessThreadMessages FLAG_PROCESS_THREAD_MESSAGES_PHYSICS = 2

Allows this node to process threaded messages created with call_deferred_thread_group() right before _physics_process() is called.

ProcessThreadMessages FLAG_PROCESS_THREAD_MESSAGES_ALL = 3

Allows this node to process threaded messages created with call_deferred_thread_group() right before either _process() or _physics_process() are called.

enum PhysicsInterpolationMode: 🔗

PhysicsInterpolationMode PHYSICS_INTERPOLATION_MODE_INHERIT = 0

Inherits physics_interpolation_mode from the node's parent. This is the default for any newly created node.

PhysicsInterpolationMode PHYSICS_INTERPOLATION_MODE_ON = 1

Enables physics interpolation for this node and for children set to PHYSICS_INTERPOLATION_MODE_INHERIT. This is the default for the root node.

PhysicsInterpolationMode PHYSICS_INTERPOLATION_MODE_OFF = 2

Disables physics interpolation for this node and for children set to PHYSICS_INTERPOLATION_MODE_INHERIT.

enum DuplicateFlags: 🔗

DuplicateFlags DUPLICATE_SIGNALS = 1

Duplicate the node's signal connections that are connected with the Object.CONNECT_PERSIST flag.

DuplicateFlags DUPLICATE_GROUPS = 2

Duplicate the node's groups.

DuplicateFlags DUPLICATE_SCRIPTS = 4

Duplicate the node's script (also overriding the duplicated children's scripts, if combined with DUPLICATE_USE_INSTANTIATION).

DuplicateFlags DUPLICATE_USE_INSTANTIATION = 8

Duplicate using PackedScene.instantiate(). If the node comes from a scene saved on disk, reuses PackedScene.instantiate() as the base for the duplicated node and its children.

InternalMode INTERNAL_MODE_DISABLED = 0

The node will not be internal.

InternalMode INTERNAL_MODE_FRONT = 1

The node will be placed at the beginning of the parent's children, before any non-internal sibling.

InternalMode INTERNAL_MODE_BACK = 2

The node will be placed at the end of the parent's children, after any non-internal sibling.

enum AutoTranslateMode: 🔗

AutoTranslateMode AUTO_TRANSLATE_MODE_INHERIT = 0

Inherits auto_translate_mode from the node's parent. This is the default for any newly created node.

AutoTranslateMode AUTO_TRANSLATE_MODE_ALWAYS = 1

Always automatically translate. This is the inverse of AUTO_TRANSLATE_MODE_DISABLED, and the default for the root node.

AutoTranslateMode AUTO_TRANSLATE_MODE_DISABLED = 2

Never automatically translate. This is the inverse of AUTO_TRANSLATE_MODE_ALWAYS.

String parsing for POT generation will be skipped for this node and children that are set to AUTO_TRANSLATE_MODE_INHERIT.

NOTIFICATION_ENTER_TREE = 10 🔗

Notification received when the node enters a SceneTree. See _enter_tree().

This notification is received before the related tree_entered signal.

NOTIFICATION_EXIT_TREE = 11 🔗

Notification received when the node is about to exit a SceneTree. See _exit_tree().

This notification is received after the related tree_exiting signal.

NOTIFICATION_MOVED_IN_PARENT = 12 🔗

Deprecated: This notification is no longer sent by the engine. Use NOTIFICATION_CHILD_ORDER_CHANGED instead.

NOTIFICATION_READY = 13 🔗

Notification received when the node is ready. See _ready().

NOTIFICATION_PAUSED = 14 🔗

Notification received when the node is paused. See process_mode.

NOTIFICATION_UNPAUSED = 15 🔗

Notification received when the node is unpaused. See process_mode.

NOTIFICATION_PHYSICS_PROCESS = 16 🔗

Notification received from the tree every physics frame when is_physics_processing() returns true. See _physics_process().

NOTIFICATION_PROCESS = 17 🔗

Notification received from the tree every rendered frame when is_processing() returns true. See _process().

NOTIFICATION_PARENTED = 18 🔗

Notification received when the node is set as a child of another node (see add_child() and add_sibling()).

Note: This does not mean that the node entered the SceneTree.

NOTIFICATION_UNPARENTED = 19 🔗

Notification received when the parent node calls remove_child() on this node.

Note: This does not mean that the node exited the SceneTree.

NOTIFICATION_SCENE_INSTANTIATED = 20 🔗

Notification received only by the newly instantiated scene root node, when PackedScene.instantiate() is completed.

NOTIFICATION_DRAG_BEGIN = 21 🔗

Notification received when a drag operation begins. All nodes receive this notification, not only the dragged one.

Can be triggered either by dragging a Control that provides drag data (see Control._get_drag_data()) or using Control.force_drag().

Use Viewport.gui_get_drag_data() to get the dragged data.

NOTIFICATION_DRAG_END = 22 🔗

Notification received when a drag operation ends.

Use Viewport.gui_is_drag_successful() to check if the drag succeeded.

NOTIFICATION_PATH_RENAMED = 23 🔗

Notification received when the node's name or one of its ancestors' name is changed. This notification is not received when the node is removed from the SceneTree.

NOTIFICATION_CHILD_ORDER_CHANGED = 24 🔗

Notification received when the list of children is changed. This happens when child nodes are added, moved or removed.

NOTIFICATION_INTERNAL_PROCESS = 25 🔗

Notification received from the tree every rendered frame when is_processing_internal() returns true.

NOTIFICATION_INTERNAL_PHYSICS_PROCESS = 26 🔗

Notification received from the tree every physics frame when is_physics_processing_internal() returns true.

NOTIFICATION_POST_ENTER_TREE = 27 🔗

Notification received when the node enters the tree, just before NOTIFICATION_READY may be received. Unlike the latter, it is sent every time the node enters tree, not just once.

NOTIFICATION_DISABLED = 28 🔗

Notification received when the node is disabled. See PROCESS_MODE_DISABLED.

NOTIFICATION_ENABLED = 29 🔗

Notification received when the node is enabled again after being disabled. See PROCESS_MODE_DISABLED.

NOTIFICATION_RESET_PHYSICS_INTERPOLATION = 2001 🔗

Notification received when reset_physics_interpolation() is called on the node or its ancestors.

NOTIFICATION_EDITOR_PRE_SAVE = 9001 🔗

Notification received right before the scene with the node is saved in the editor. This notification is only sent in the Godot editor and will not occur in exported projects.

NOTIFICATION_EDITOR_POST_SAVE = 9002 🔗

Notification received right after the scene with the node is saved in the editor. This notification is only sent in the Godot editor and will not occur in exported projects.

NOTIFICATION_WM_MOUSE_ENTER = 1002 🔗

Notification received when the mouse enters the window.

Implemented for embedded windows and on desktop and web platforms.

NOTIFICATION_WM_MOUSE_EXIT = 1003 🔗

Notification received when the mouse leaves the window.

Implemented for embedded windows and on desktop and web platforms.

NOTIFICATION_WM_WINDOW_FOCUS_IN = 1004 🔗

Notification received from the OS when the node's Window ancestor is focused. This may be a change of focus between two windows of the same engine instance, or from the OS desktop or a third-party application to a window of the game (in which case NOTIFICATION_APPLICATION_FOCUS_IN is also received).

A Window node receives this notification when it is focused.

NOTIFICATION_WM_WINDOW_FOCUS_OUT = 1005 🔗

Notification received from the OS when the node's Window ancestor is defocused. This may be a change of focus between two windows of the same engine instance, or from a window of the game to the OS desktop or a third-party application (in which case NOTIFICATION_APPLICATION_FOCUS_OUT is also received).

A Window node receives this notification when it is defocused.

NOTIFICATION_WM_CLOSE_REQUEST = 1006 🔗

Notification received from the OS when a close request is sent (e.g. closing the window with a "Close" button or Alt + F4).

Implemented on desktop platforms.

NOTIFICATION_WM_GO_BACK_REQUEST = 1007 🔗

Notification received from the OS when a go back request is sent (e.g. pressing the "Back" button on Android).

Implemented only on Android.

NOTIFICATION_WM_SIZE_CHANGED = 1008 🔗

Notification received when the window is resized.

Note: Only the resized Window node receives this notification, and it's not propagated to the child nodes.

NOTIFICATION_WM_DPI_CHANGE = 1009 🔗

Notification received from the OS when the screen's dots per inch (DPI) scale is changed. Only implemented on macOS.

NOTIFICATION_VP_MOUSE_ENTER = 1010 🔗

Notification received when the mouse cursor enters the Viewport's visible area, that is not occluded behind other Controls or Windows, provided its Viewport.gui_disable_input is false and regardless if it's currently focused or not.

NOTIFICATION_VP_MOUSE_EXIT = 1011 🔗

Notification received when the mouse cursor leaves the Viewport's visible area, that is not occluded behind other Controls or Windows, provided its Viewport.gui_disable_input is false and regardless if it's currently focused or not.

NOTIFICATION_WM_POSITION_CHANGED = 1012 🔗

Notification received when the window is moved.

NOTIFICATION_OS_MEMORY_WARNING = 2009 🔗

Notification received from the OS when the application is exceeding its allocated memory.

Implemented only on iOS.

NOTIFICATION_TRANSLATION_CHANGED = 2010 🔗

Notification received when translations may have changed. Can be triggered by the user changing the locale, changing auto_translate_mode or when the node enters the scene tree. Can be used to respond to language changes, for example to change the UI strings on the fly. Useful when working with the built-in translation support, like Object.tr().

Note: This notification is received alongside NOTIFICATION_ENTER_TREE, so if you are instantiating a scene, the child nodes will not be initialized yet. You can use it to setup translations for this node, child nodes created from script, or if you want to access child nodes added in the editor, make sure the node is ready using is_node_ready().

NOTIFICATION_WM_ABOUT = 2011 🔗

Notification received from the OS when a request for "About" information is sent.

Implemented only on macOS.

NOTIFICATION_CRASH = 2012 🔗

Notification received from Godot's crash handler when the engine is about to crash.

Implemented on desktop platforms, if the crash handler is enabled.

NOTIFICATION_OS_IME_UPDATE = 2013 🔗

Notification received from the OS when an update of the Input Method Engine occurs (e.g. change of IME cursor position or composition string).

Implemented only on macOS.

NOTIFICATION_APPLICATION_RESUMED = 2014 🔗

Notification received from the OS when the application is resumed.

Specific to the Android and iOS platforms.

NOTIFICATION_APPLICATION_PAUSED = 2015 🔗

Notification received from the OS when the application is paused.

Specific to the Android and iOS platforms.

Note: On iOS, you only have approximately 5 seconds to finish a task started by this signal. If you go over this allotment, iOS will kill the app instead of pausing it.

NOTIFICATION_APPLICATION_FOCUS_IN = 2016 🔗

Notification received from the OS when the application is focused, i.e. when changing the focus from the OS desktop or a thirdparty application to any open window of the Godot instance.

Implemented on desktop and mobile platforms.

NOTIFICATION_APPLICATION_FOCUS_OUT = 2017 🔗

Notification received from the OS when the application is defocused, i.e. when changing the focus from any open window of the Godot instance to the OS desktop or a thirdparty application.

Implemented on desktop and mobile platforms.

NOTIFICATION_TEXT_SERVER_CHANGED = 2018 🔗

Notification received when the TextServer is changed.

NOTIFICATION_ACCESSIBILITY_UPDATE = 3000 🔗

Notification received when an accessibility information update is required.

NOTIFICATION_ACCESSIBILITY_INVALIDATE = 3001 🔗

Notification received when accessibility elements are invalidated. All node accessibility elements are automatically deleted after receiving this message, therefore all existing references to such elements should be discarded.

AutoTranslateMode auto_translate_mode = 0 🔗

void set_auto_translate_mode(value: AutoTranslateMode)

AutoTranslateMode get_auto_translate_mode()

Defines if any text should automatically change to its translated version depending on the current locale (for nodes such as Label, RichTextLabel, Window, etc.). Also decides if the node's strings should be parsed for POT generation.

Note: For the root node, auto translate mode can also be set via ProjectSettings.internationalization/rendering/root_node_auto_translate.

String editor_description = "" 🔗

void set_editor_description(value: String)

String get_editor_description()

An optional description to the node. It will be displayed as a tooltip when hovering over the node in the editor's Scene dock.

MultiplayerAPI multiplayer 🔗

MultiplayerAPI get_multiplayer()

The MultiplayerAPI instance associated with this node. See SceneTree.get_multiplayer().

Note: Renaming the node, or moving it in the tree, will not move the MultiplayerAPI to the new path, you will have to update this manually.

void set_name(value: StringName)

StringName get_name()

The name of the node. This name must be unique among the siblings (other child nodes from the same parent). When set to an existing sibling's name, the node is automatically renamed.

Note: When changing the name, the following characters will be replaced with an underscore: (. : @ / " %). In particular, the @ character is reserved for auto-generated names. See also String.validate_node_name().

void set_owner(value: Node)

The owner of this node. The owner must be an ancestor of this node. When packing the owner node in a PackedScene, all the nodes it owns are also saved with it. See also unique_name_in_owner.

Note: In the editor, nodes not owned by the scene root are usually not displayed in the Scene dock, and will not be saved. To prevent this, remember to set the owner after calling add_child().

PhysicsInterpolationMode physics_interpolation_mode = 0 🔗

void set_physics_interpolation_mode(value: PhysicsInterpolationMode)

PhysicsInterpolationMode get_physics_interpolation_mode()

The physics interpolation mode to use for this node. Only effective if ProjectSettings.physics/common/physics_interpolation or SceneTree.physics_interpolation is true.

By default, nodes inherit the physics interpolation mode from their parent. This property can enable or disable physics interpolation individually for each node, regardless of their parents' physics interpolation mode.

Note: Some node types like VehicleWheel3D have physics interpolation disabled by default, as they rely on their own custom solution.

Note: When teleporting a node to a distant position, it's recommended to temporarily disable interpolation with reset_physics_interpolation() after moving the node. This avoids creating a visual streak between the old and new positions.

ProcessMode process_mode = 0 🔗

void set_process_mode(value: ProcessMode)

ProcessMode get_process_mode()

The node's processing behavior. To check if the node can process in its current mode, use can_process().

int process_physics_priority = 0 🔗

void set_physics_process_priority(value: int)

int get_physics_process_priority()

Similar to process_priority but for NOTIFICATION_PHYSICS_PROCESS, _physics_process(), or NOTIFICATION_INTERNAL_PHYSICS_PROCESS.

int process_priority = 0 🔗

void set_process_priority(value: int)

int get_process_priority()

The node's execution order of the process callbacks (_process(), NOTIFICATION_PROCESS, and NOTIFICATION_INTERNAL_PROCESS). Nodes whose priority value is lower call their process callbacks first, regardless of tree order.

ProcessThreadGroup process_thread_group = 0 🔗

void set_process_thread_group(value: ProcessThreadGroup)

ProcessThreadGroup get_process_thread_group()

Set the process thread group for this node (basically, whether it receives NOTIFICATION_PROCESS, NOTIFICATION_PHYSICS_PROCESS, _process() or _physics_process() (and the internal versions) on the main thread or in a sub-thread.

By default, the thread group is PROCESS_THREAD_GROUP_INHERIT, which means that this node belongs to the same thread group as the parent node. The thread groups means that nodes in a specific thread group will process together, separate to other thread groups (depending on process_thread_group_order). If the value is set is PROCESS_THREAD_GROUP_SUB_THREAD, this thread group will occur on a sub thread (not the main thread), otherwise if set to PROCESS_THREAD_GROUP_MAIN_THREAD it will process on the main thread. If there is not a parent or grandparent node set to something other than inherit, the node will belong to the default thread group. This default group will process on the main thread and its group order is 0.

During processing in a sub-thread, accessing most functions in nodes outside the thread group is forbidden (and it will result in an error in debug mode). Use Object.call_deferred(), call_thread_safe(), call_deferred_thread_group() and the likes in order to communicate from the thread groups to the main thread (or to other thread groups).

To better understand process thread groups, the idea is that any node set to any other value than PROCESS_THREAD_GROUP_INHERIT will include any child (and grandchild) nodes set to inherit into its process thread group. This means that the processing of all the nodes in the group will happen together, at the same time as the node including them.

int process_thread_group_order 🔗

void set_process_thread_group_order(value: int)

int get_process_thread_group_order()

Change the process thread group order. Groups with a lesser order will process before groups with a greater order. This is useful when a large amount of nodes process in sub thread and, afterwards, another group wants to collect their result in the main thread, as an example.

BitField[ProcessThreadMessages] process_thread_messages 🔗

void set_process_thread_messages(value: BitField[ProcessThreadMessages])

BitField[ProcessThreadMessages] get_process_thread_messages()

Set whether the current thread group will process messages (calls to call_deferred_thread_group() on threads), and whether it wants to receive them during regular process or physics process callbacks.

String scene_file_path 🔗

void set_scene_file_path(value: String)

String get_scene_file_path()

The original scene's file path, if the node has been instantiated from a PackedScene file. Only scene root nodes contains this.

bool unique_name_in_owner = false 🔗

void set_unique_name_in_owner(value: bool)

bool is_unique_name_in_owner()

If true, the node can be accessed from any node sharing the same owner or from the owner itself, with special %Name syntax in get_node().

Note: If another node with the same owner shares the same name as this node, the other node will no longer be accessible as unique.

void _enter_tree() virtual 🔗

Called when the node enters the SceneTree (e.g. upon instantiating, scene changing, or after calling add_child() in a script). If the node has children, its _enter_tree() callback will be called first, and then that of the children.

Corresponds to the NOTIFICATION_ENTER_TREE notification in Object._notification().

void _exit_tree() virtual 🔗

Called when the node is about to leave the SceneTree (e.g. upon freeing, scene changing, or after calling remove_child() in a script). If the node has children, its _exit_tree() callback will be called last, after all its children have left the tree.

Corresponds to the NOTIFICATION_EXIT_TREE notification in Object._notification() and signal tree_exiting. To get notified when the node has already left the active tree, connect to the tree_exited.

PackedStringArray _get_accessibility_configuration_warnings() virtual const 🔗

The elements in the array returned from this method are displayed as warnings in the Scene dock if the script that overrides it is a tool script, and accessibility warnings are enabled in the editor settings.

Returning an empty array produces no warnings.

PackedStringArray _get_configuration_warnings() virtual const 🔗

The elements in the array returned from this method are displayed as warnings in the Scene dock if the script that overrides it is a tool script.

Returning an empty array produces no warnings.

Call update_configuration_warnings() when the warnings need to be updated for this node.

RID _get_focused_accessibility_element() virtual const 🔗

Called during accessibility information updates to determine the currently focused sub-element, should return a sub-element RID or the value returned by get_accessibility_element().

void _input(event: InputEvent) virtual 🔗

Called when there is an input event. The input event propagates up through the node tree until a node consumes it.

It is only called if input processing is enabled, which is done automatically if this method is overridden, and can be toggled with set_process_input().

To consume the input event and stop it propagating further to other nodes, Viewport.set_input_as_handled() can be called.

For gameplay input, _unhandled_input() and _unhandled_key_input() are usually a better fit as they allow the GUI to intercept the events first.

Note: This method is only called if the node is present in the scene tree (i.e. if it's not an orphan).

void _physics_process(delta: float) virtual 🔗

Called once on each physics tick, and allows Nodes to synchronize their logic with physics ticks. delta is the logical time between physics ticks in seconds and is equal to Engine.time_scale / Engine.physics_ticks_per_second.

It is only called if physics processing is enabled for this Node, which is done automatically if this method is overridden, and can be toggled with set_physics_process().

Processing happens in order of process_physics_priority, lower priority values are called first. Nodes with the same priority are processed in tree order, or top to bottom as seen in the editor (also known as pre-order traversal).

Corresponds to the NOTIFICATION_PHYSICS_PROCESS notification in Object._notification().

Note: This method is only called if the node is present in the scene tree (i.e. if it's not an orphan).

Note: Accumulated delta may diverge from real world seconds.

void _process(delta: float) virtual 🔗

Called on each idle frame, prior to rendering, and after physics ticks have been processed. delta is the time between frames in seconds.

It is only called if processing is enabled for this Node, which is done automatically if this method is overridden, and can be toggled with set_process().

Processing happens in order of process_priority, lower priority values are called first. Nodes with the same priority are processed in tree order, or top to bottom as seen in the editor (also known as pre-order traversal).

Corresponds to the NOTIFICATION_PROCESS notification in Object._notification().

Note: This method is only called if the node is present in the scene tree (i.e. if it's not an orphan).

Note: When the engine is struggling and the frame rate is lowered, delta will increase. When delta is increased, it's capped at a maximum of Engine.time_scale * Engine.max_physics_steps_per_frame / Engine.physics_ticks_per_second. As a result, accumulated delta may not represent real world time.

Note: When --fixed-fps is enabled or the engine is running in Movie Maker mode (see MovieWriter), process delta will always be the same for every frame, regardless of how much time the frame took to render.

Note: Frame delta may be post-processed by OS.delta_smoothing if this is enabled for the project.

void _ready() virtual 🔗

Called when the node is "ready", i.e. when both the node and its children have entered the scene tree. If the node has children, their _ready() callbacks get triggered first, and the parent node will receive the ready notification afterwards.

Corresponds to the NOTIFICATION_READY notification in Object._notification(). See also the @onready annotation for variables.

Usually used for initialization. For even earlier initialization, Object._init() may be used. See also _enter_tree().

Note: This method may be called only once for each node. After removing a node from the scene tree and adding it again, _ready() will not be called a second time. This can be bypassed by requesting another call with request_ready(), which may be called anywhere before adding the node again.

void _shortcut_input(event: InputEvent) virtual 🔗

Called when an InputEventKey, InputEventShortcut, or InputEventJoypadButton hasn't been consumed by _input() or any GUI Control item. It is called before _unhandled_key_input() and _unhandled_input(). The input event propagates up through the node tree until a node consumes it.

It is only called if shortcut processing is enabled, which is done automatically if this method is overridden, and can be toggled with set_process_shortcut_input().

To consume the input event and stop it propagating further to other nodes, Viewport.set_input_as_handled() can be called.

This method can be used to handle shortcuts. For generic GUI events, use _input() instead. Gameplay events should usually be handled with either _unhandled_input() or _unhandled_key_input().

Note: This method is only called if the node is present in the scene tree (i.e. if it's not orphan).

void _unhandled_input(event: InputEvent) virtual 🔗

Called when an InputEvent hasn't been consumed by _input() or any GUI Control item. It is called after _shortcut_input() and after _unhandled_key_input(). The input event propagates up through the node tree until a node consumes it.

It is only called if unhandled input processing is enabled, which is done automatically if this method is overridden, and can be toggled with set_process_unhandled_input().

To consume the input event and stop it propagating further to other nodes, Viewport.set_input_as_handled() can be called.

For gameplay input, this method is usually a better fit than _input(), as GUI events need a higher priority. For keyboard shortcuts, consider using _shortcut_input() instead, as it is called before this method. Finally, to handle keyboard events, consider using _unhandled_key_input() for performance reasons.

Note: This method is only called if the node is present in the scene tree (i.e. if it's not an orphan).

void _unhandled_key_input(event: InputEvent) virtual 🔗

Called when an InputEventKey hasn't been consumed by _input() or any GUI Control item. It is called after _shortcut_input() but before _unhandled_input(). The input event propagates up through the node tree until a node consumes it.

It is only called if unhandled key input processing is enabled, which is done automatically if this method is overridden, and can be toggled with set_process_unhandled_key_input().

To consume the input event and stop it propagating further to other nodes, Viewport.set_input_as_handled() can be called.

This method can be used to handle Unicode character input with Alt, Alt + Ctrl, and Alt + Shift modifiers, after shortcuts were handled.

For gameplay input, this and _unhandled_input() are usually a better fit than _input(), as GUI events should be handled first. This method also performs better than _unhandled_input(), since unrelated events such as InputEventMouseMotion are automatically filtered. For shortcuts, consider using _shortcut_input() instead.

Note: This method is only called if the node is present in the scene tree (i.e. if it's not an orphan).

void add_child(node: Node, force_readable_name: bool = false, internal: InternalMode = 0) 🔗

Adds a child node. Nodes can have any number of children, but every child must have a unique name. Child nodes are automatically deleted when the parent node is deleted, so an entire scene can be removed by deleting its topmost node.

If force_readable_name is true, improves the readability of the added node. If not named, the node is renamed to its type, and if it shares name with a sibling, a number is suffixed more appropriately. This operation is very slow. As such, it is recommended leaving this to false, which assigns a dummy name featuring @ in both situations.

If internal is different than INTERNAL_MODE_DISABLED, the child will be added as internal node. These nodes are ignored by methods like get_children(), unless their parameter include_internal is true. It also prevents these nodes being duplicated with their parent. The intended usage is to hide the internal nodes from the user, so the user won't accidentally delete or modify them. Used by some GUI nodes, e.g. ColorPicker.

Note: If node already has a parent, this method will fail. Use remove_child() first to remove node from its current parent. For example:

If you need the child node to be added below a specific node in the list of children, use add_sibling() instead of this method.

Note: If you want a child to be persisted to a PackedScene, you must set owner in addition to calling add_child(). This is typically relevant for tool scripts and editor plugins. If add_child() is called without setting owner, the newly added Node will not be visible in the scene tree, though it will be visible in the 2D/3D view.

void add_sibling(sibling: Node, force_readable_name: bool = false) 🔗

Adds a sibling node to this node's parent, and moves the added sibling right below this node.

If force_readable_name is true, improves the readability of the added sibling. If not named, the sibling is renamed to its type, and if it shares name with a sibling, a number is suffixed more appropriately. This operation is very slow. As such, it is recommended leaving this to false, which assigns a dummy name featuring @ in both situations.

Use add_child() instead of this method if you don't need the child node to be added below a specific node in the list of children.

Note: If this node is internal, the added sibling will be internal too (see add_child()'s internal parameter).

void add_to_group(group: StringName, persistent: bool = false) 🔗

Adds the node to the group. Groups can be helpful to organize a subset of nodes, for example "enemies" or "collectables". See notes in the description, and the group methods in SceneTree.

If persistent is true, the group will be stored when saved inside a PackedScene. All groups created and displayed in the Node dock are persistent.

Note: To improve performance, the order of group names is not guaranteed and may vary between project runs. Therefore, do not rely on the group order.

Note: SceneTree's group methods will not work on this node if not inside the tree (see is_inside_tree()).

String atr(message: String, context: StringName = "") const 🔗

Translates a message, using the translation catalogs configured in the Project Settings. Further context can be specified to help with the translation. Note that most Control nodes automatically translate their strings, so this method is mostly useful for formatted strings or custom drawn text.

This method works the same as Object.tr(), with the addition of respecting the auto_translate_mode state.

If Object.can_translate_messages() is false, or no translation is available, this method returns the message without changes. See Object.set_message_translation().

For detailed examples, see Internationalizing games.

String atr_n(message: String, plural_message: StringName, n: int, context: StringName = "") const 🔗

Translates a message or plural_message, using the translation catalogs configured in the Project Settings. Further context can be specified to help with the translation.

This method works the same as Object.tr_n(), with the addition of respecting the auto_translate_mode state.

If Object.can_translate_messages() is false, or no translation is available, this method returns message or plural_message, without changes. See Object.set_message_translation().

The n is the number, or amount, of the message's subject. It is used by the translation system to fetch the correct plural form for the current language.

For detailed examples, see Localization using gettext.

Note: Negative and float numbers may not properly apply to some countable subjects. It's recommended to handle these cases with atr().

Variant call_deferred_thread_group(method: StringName, ...) vararg 🔗

This function is similar to Object.call_deferred() except that the call will take place when the node thread group is processed. If the node thread group processes in sub-threads, then the call will be done on that thread, right before NOTIFICATION_PROCESS or NOTIFICATION_PHYSICS_PROCESS, the _process() or _physics_process() or their internal versions are called.

Variant call_thread_safe(method: StringName, ...) vararg 🔗

This function ensures that the calling of this function will succeed, no matter whether it's being done from a thread or not. If called from a thread that is not allowed to call the function, the call will become deferred. Otherwise, the call will go through directly.

bool can_auto_translate() const 🔗

Returns true if this node can automatically translate messages depending on the current locale. See auto_translate_mode, atr(), and atr_n().

bool can_process() const 🔗

Returns true if the node can receive processing notifications and input callbacks (NOTIFICATION_PROCESS, _input(), etc.) from the SceneTree and Viewport. The returned value depends on process_mode:

If set to PROCESS_MODE_PAUSABLE, returns true when the game is processing, i.e. SceneTree.paused is false;

If set to PROCESS_MODE_WHEN_PAUSED, returns true when the game is paused, i.e. SceneTree.paused is true;

If set to PROCESS_MODE_ALWAYS, always returns true;

If set to PROCESS_MODE_DISABLED, always returns false;

If set to PROCESS_MODE_INHERIT, use the parent node's process_mode to determine the result.

If the node is not inside the tree, returns false no matter the value of process_mode.

Tween create_tween() 🔗

Creates a new Tween and binds it to this node.

This is the equivalent of doing:

The Tween will start automatically on the next process frame or physics frame (depending on TweenProcessMode). See Tween.bind_node() for more info on Tweens bound to nodes.

Note: The method can still be used when the node is not inside SceneTree. It can fail in an unlikely case of using a custom MainLoop.

Node duplicate(flags: int = 15) const 🔗

Duplicates the node, returning a new node with all of its properties, signals, groups, and children copied from the original. The behavior can be tweaked through the flags (see DuplicateFlags). Internal nodes are not duplicated.

Note: For nodes with a Script attached, if Object._init() has been defined with required parameters, the duplicated node will not have a Script.

Node find_child(pattern: String, recursive: bool = true, owned: bool = true) const 🔗

Finds the first descendant of this node whose name matches pattern, returning null if no match is found. The matching is done against node names, not their paths, through String.match(). As such, it is case-sensitive, "*" matches zero or more characters, and "?" matches any single character.

If recursive is false, only this node's direct children are checked. Nodes are checked in tree order, so this node's first direct child is checked first, then its own direct children, etc., before moving to the second direct child, and so on. Internal children are also included in the search (see internal parameter in add_child()).

If owned is true, only descendants with a valid owner node are checked.

Note: This method can be very slow. Consider storing a reference to the found node in a variable. Alternatively, use get_node() with unique names (see unique_name_in_owner).

Note: To find all descendant nodes matching a pattern or a class type, see find_children().

Array[Node] find_children(pattern: String, type: String = "", recursive: bool = true, owned: bool = true) const 🔗

Finds all descendants of this node whose names match pattern, returning an empty Array if no match is found. The matching is done against node names, not their paths, through String.match(). As such, it is case-sensitive, "*" matches zero or more characters, and "?" matches any single character.

If type is not empty, only ancestors inheriting from type are included (see Object.is_class()).

If recursive is false, only this node's direct children are checked. Nodes are checked in tree order, so this node's first direct child is checked first, then its own direct children, etc., before moving to the second direct child, and so on. Internal children are also included in the search (see internal parameter in add_child()).

If owned is true, only descendants with a valid owner node are checked.

Note: This method can be very slow. Consider storing references to the found nodes in a variable.

Note: To find a single descendant node matching a pattern, see find_child().

Node find_parent(pattern: String) const 🔗

Finds the first ancestor of this node whose name matches pattern, returning null if no match is found. The matching is done through String.match(). As such, it is case-sensitive, "*" matches zero or more characters, and "?" matches any single character. See also find_child() and find_children().

Note: As this method walks upwards in the scene tree, it can be slow in large, deeply nested nodes. Consider storing a reference to the found node in a variable. Alternatively, use get_node() with unique names (see unique_name_in_owner).

RID get_accessibility_element() const 🔗

Returns main accessibility element RID.

Note: This method should be called only during accessibility information updates (NOTIFICATION_ACCESSIBILITY_UPDATE).

Node get_child(idx: int, include_internal: bool = false) const 🔗

Fetches a child node by its index. Each child node has an index relative to its siblings (see get_index()). The first child is at index 0. Negative values can also be used to start from the end of the list. This method can be used in combination with get_child_count() to iterate over this node's children. If no child exists at the given index, this method returns null and an error is generated.

If include_internal is false, internal children are ignored (see add_child()'s internal parameter).

Note: To fetch a node by NodePath, use get_node().

int get_child_count(include_internal: bool = false) const 🔗

Returns the number of children of this node.

If include_internal is false, internal children are not counted (see add_child()'s internal parameter).

Array[Node] get_children(include_internal: bool = false) const 🔗

Returns all children of this node inside an Array.

If include_internal is false, excludes internal children from the returned array (see add_child()'s internal parameter).

Array[StringName] get_groups() const 🔗

Returns an Array of group names that the node has been added to.

Note: To improve performance, the order of group names is not guaranteed and may vary between project runs. Therefore, do not rely on the group order.

Note: This method may also return some group names starting with an underscore (_). These are internally used by the engine. To avoid conflicts, do not use custom groups starting with underscores. To exclude internal groups, see the following code snippet:

int get_index(include_internal: bool = false) const 🔗

Returns this node's order among its siblings. The first node's index is 0. See also get_child().

If include_internal is false, returns the index ignoring internal children. The first, non-internal child will have an index of 0 (see add_child()'s internal parameter).

Window get_last_exclusive_window() const 🔗

Returns the Window that contains this node, or the last exclusive child in a chain of windows starting with the one that contains this node.

int get_multiplayer_authority() const 🔗

Returns the peer ID of the multiplayer authority for this node. See set_multiplayer_authority().

Node get_node(path: NodePath) const 🔗

Fetches a node. The NodePath can either be a relative path (from this node), or an absolute path (from the SceneTree.root) to a node. If path does not point to a valid node, generates an error and returns null. Attempts to access methods on the return value will result in an "Attempt to call <method> on a null instance." error.

Note: Fetching by absolute path only works when the node is inside the scene tree (see is_inside_tree()).

Example: Assume this method is called from the Character node, inside the following tree:

The following calls will return a valid node:

Array get_node_and_resource(path: NodePath) 🔗

Fetches a node and its most nested resource as specified by the NodePath's subname. Returns an Array of size 3 where:

Element 0 is the Node, or null if not found;

Element 1 is the subname's last nested Resource, or null if not found;

Element 2 is the remaining NodePath, referring to an existing, non-Resource property (see Object.get_indexed()).

Example: Assume that the child's Sprite2D.texture has been assigned an AtlasTexture:

Node get_node_or_null(path: NodePath) const 🔗

Fetches a node by NodePath. Similar to get_node(), but does not generate an error if path does not point to a valid node.

Variant get_node_rpc_config() const 🔗

Returns a Dictionary mapping method names to their RPC configuration defined for this node using rpc_config().

Note: This method only returns the RPC configuration assigned via rpc_config(). See Script.get_rpc_config() to retrieve the RPCs defined by the Script.

Array[int] get_orphan_node_ids() static 🔗

Returns object IDs of all orphan nodes (nodes outside the SceneTree). Used for debugging.

Note: get_orphan_node_ids() only works in debug builds. When called in a project exported in release mode, get_orphan_node_ids() will return an empty array.

Node get_parent() const 🔗

Returns this node's parent node, or null if the node doesn't have a parent.

NodePath get_path() const 🔗

Returns the node's absolute path, relative to the SceneTree.root. If the node is not inside the scene tree, this method fails and returns an empty NodePath.

NodePath get_path_to(node: Node, use_unique_path: bool = false) const 🔗

Returns the relative NodePath from this node to the specified node. Both nodes must be in the same SceneTree or scene hierarchy, otherwise this method fails and returns an empty NodePath.

If use_unique_path is true, returns the shortest path accounting for this node's unique name (see unique_name_in_owner).

Note: If you get a relative path which starts from a unique node, the path may be longer than a normal relative path, due to the addition of the unique node's name.

float get_physics_process_delta_time() const 🔗

Returns the time elapsed (in seconds) since the last physics callback. This value is identical to _physics_process()'s delta parameter, and is often consistent at run-time, unless Engine.physics_ticks_per_second is changed. See also NOTIFICATION_PHYSICS_PROCESS.

Note: The returned value will be larger than expected if running at a framerate lower than Engine.physics_ticks_per_second / Engine.max_physics_steps_per_frame FPS. This is done to avoid "spiral of death" scenarios where performance would plummet due to an ever-increasing number of physics steps per frame. This behavior affects both _process() and _physics_process(). As a result, avoid using delta for time measurements in real-world seconds. Use the Time singleton's methods for this purpose instead, such as Time.get_ticks_usec().

float get_process_delta_time() const 🔗

Returns the time elapsed (in seconds) since the last process callback. This value is identical to _process()'s delta parameter, and may vary from frame to frame. See also NOTIFICATION_PROCESS.

Note: The returned value will be larger than expected if running at a framerate lower than Engine.physics_ticks_per_second / Engine.max_physics_steps_per_frame FPS. This is done to avoid "spiral of death" scenarios where performance would plummet due to an ever-increasing number of physics steps per frame. This behavior affects both _process() and _physics_process(). As a result, avoid using delta for time measurements in real-world seconds. Use the Time singleton's methods for this purpose instead, such as Time.get_ticks_usec().

bool get_scene_instance_load_placeholder() const 🔗

Returns true if this node is an instance load placeholder. See InstancePlaceholder and set_scene_instance_load_placeholder().

SceneTree get_tree() const 🔗

Returns the SceneTree that contains this node. If this node is not inside the tree, generates an error and returns null. See also is_inside_tree().

String get_tree_string() 🔗

Returns the tree as a String. Used mainly for debugging purposes. This version displays the path relative to the current node, and is good for copy/pasting into the get_node() function. It also can be used in game UI/UX.

May print, for example:

String get_tree_string_pretty() 🔗

Similar to get_tree_string(), this returns the tree as a String. This version displays a more graphical representation similar to what is displayed in the Scene Dock. It is useful for inspecting larger trees.

May print, for example:

Viewport get_viewport() const 🔗

Returns the node's closest Viewport ancestor, if the node is inside the tree. Otherwise, returns null.

Window get_window() const 🔗

Returns the Window that contains this node. If the node is in the main window, this is equivalent to getting the root node (get_tree().get_root()).

bool has_node(path: NodePath) const 🔗

Returns true if the path points to a valid node. See also get_node().

bool has_node_and_resource(path: NodePath) const 🔗

Returns true if path points to a valid node and its subnames point to a valid Resource, e.g. Area2D/CollisionShape2D:shape. Properties that are not Resource types (such as nodes or other Variant types) are not considered. See also get_node_and_resource().

bool is_ancestor_of(node: Node) const 🔗

Returns true if the given node is a direct or indirect child of this node.

bool is_displayed_folded() const 🔗

Returns true if the node is folded (collapsed) in the Scene dock. This method is intended to be used in editor plugins and tools. See also set_display_folded().

bool is_editable_instance(node: Node) const 🔗

Returns true if node has editable children enabled relative to this node. This method is intended to be used in editor plugins and tools. See also set_editable_instance().

bool is_greater_than(node: Node) const 🔗

Returns true if the given node occurs later in the scene hierarchy than this node. A node occurring later is usually processed last.

bool is_in_group(group: StringName) const 🔗

Returns true if this node has been added to the given group. See add_to_group() and remove_from_group(). See also notes in the description, and the SceneTree's group methods.

bool is_inside_tree() const 🔗

Returns true if this node is currently inside a SceneTree. See also get_tree().

bool is_multiplayer_authority() const 🔗

Returns true if the local system is the multiplayer authority of this node.

bool is_node_ready() const 🔗

Returns true if the node is ready, i.e. it's inside scene tree and all its children are initialized.

request_ready() resets it back to false.

bool is_part_of_edited_scene() const 🔗

Returns true if the node is part of the scene currently opened in the editor.

bool is_physics_interpolated() const 🔗

Returns true if physics interpolation is enabled for this node (see physics_interpolation_mode).

Note: Interpolation will only be active if both the flag is set and physics interpolation is enabled within the SceneTree. This can be tested using is_physics_interpolated_and_enabled().

bool is_physics_interpolated_and_enabled() const 🔗

Returns true if physics interpolation is enabled (see physics_interpolation_mode) and enabled in the SceneTree.

This is a convenience version of is_physics_interpolated() that also checks whether physics interpolation is enabled globally.

See SceneTree.physics_interpolation and ProjectSettings.physics/common/physics_interpolation.

bool is_physics_processing() const 🔗

Returns true if physics processing is enabled (see set_physics_process()).

bool is_physics_processing_internal() const 🔗

Returns true if internal physics processing is enabled (see set_physics_process_internal()).

bool is_processing() const 🔗

Returns true if processing is enabled (see set_process()).

bool is_processing_input() const 🔗

Returns true if the node is processing input (see set_process_input()).

bool is_processing_internal() const 🔗

Returns true if internal processing is enabled (see set_process_internal()).

bool is_processing_shortcut_input() const 🔗

Returns true if the node is processing shortcuts (see set_process_shortcut_input()).

bool is_processing_unhandled_input() const 🔗

Returns true if the node is processing unhandled input (see set_process_unhandled_input()).

bool is_processing_unhandled_key_input() const 🔗

Returns true if the node is processing unhandled key input (see set_process_unhandled_key_input()).

void move_child(child_node: Node, to_index: int) 🔗

Moves child_node to the given index. A node's index is the order among its siblings. If to_index is negative, the index is counted from the end of the list. See also get_child() and get_index().

Note: The processing order of several engine callbacks (_ready(), _process(), etc.) and notifications sent through propagate_notification() is affected by tree order. CanvasItem nodes are also rendered in tree order. See also process_priority.

void notify_deferred_thread_group(what: int) 🔗

Similar to call_deferred_thread_group(), but for notifications.

void notify_thread_safe(what: int) 🔗

Similar to call_thread_safe(), but for notifications.

void print_orphan_nodes() static 🔗

Prints all orphan nodes (nodes outside the SceneTree). Useful for debugging.

Note: This method only works in debug builds. Does nothing in a project exported in release mode.

Prints the node and its children to the console, recursively. The node does not have to be inside the tree. This method outputs NodePaths relative to this node, and is good for copy/pasting into get_node(). See also print_tree_pretty().

May print, for example:

void print_tree_pretty() 🔗

Prints the node and its children to the console, recursively. The node does not have to be inside the tree. Similar to print_tree(), but the graphical representation looks like what is displayed in the editor's Scene dock. It is useful for inspecting larger trees.

May print, for example:

void propagate_call(method: StringName, args: Array = [], parent_first: bool = false) 🔗

Calls the given method name, passing args as arguments, on this node and all of its children, recursively.

If parent_first is true, the method is called on this node first, then on all of its children. If false, the children's methods are called first.

void propagate_notification(what: int) 🔗

Calls Object.notification() with what on this node and all of its children, recursively.

void queue_accessibility_update() 🔗

Queues an accessibility information update for this node.

Queues this node to be deleted at the end of the current frame. When deleted, all of its children are deleted as well, and all references to the node and its children become invalid.

Unlike with Object.free(), the node is not deleted instantly, and it can still be accessed before deletion. It is also safe to call queue_free() multiple times. Use Object.is_queued_for_deletion() to check if the node will be deleted at the end of the frame.

Note: The node will only be freed after all other deferred calls are finished. Using this method is not always the same as calling Object.free() through Object.call_deferred().

void remove_child(node: Node) 🔗

Removes a child node. The node, along with its children, are not deleted. To delete a node, see queue_free().

Note: When this node is inside the tree, this method sets the owner of the removed node (or its descendants) to null, if their owner is no longer an ancestor (see is_ancestor_of()).

void remove_from_group(group: StringName) 🔗

Removes the node from the given group. Does nothing if the node is not in the group. See also notes in the description, and the SceneTree's group methods.

void reparent(new_parent: Node, keep_global_transform: bool = true) 🔗

Changes the parent of this Node to the new_parent. The node needs to already have a parent. The node's owner is preserved if its owner is still reachable from the new location (i.e., the node is still a descendant of the new parent after the operation).

If keep_global_transform is true, the node's global transform will be preserved if supported. Node2D, Node3D and Control support this argument (but Control keeps only position).

void replace_by(node: Node, keep_groups: bool = false) 🔗

Replaces this node by the given node. All children of this node are moved to node.

If keep_groups is true, the node is added to the same groups that the replaced node is in (see add_to_group()).

Warning: The replaced node is removed from the tree, but it is not deleted. To prevent memory leaks, store a reference to the node in a variable, or use Object.free().

void request_ready() 🔗

Requests _ready() to be called again the next time the node enters the tree. Does not immediately call _ready().

Note: This method only affects the current node. If the node's children also need to request ready, this method needs to be called for each one of them. When the node and its children enter the tree again, the order of _ready() callbacks will be the same as normal.

void reset_physics_interpolation() 🔗

When physics interpolation is active, moving a node to a radically different transform (such as placement within a level) can result in a visible glitch as the object is rendered moving from the old to new position over the physics tick.

That glitch can be prevented by calling this method, which temporarily disables interpolation until the physics tick is complete.

The notification NOTIFICATION_RESET_PHYSICS_INTERPOLATION will be received by the node and all children recursively.

Note: This function should be called after moving the node, rather than before.

Error rpc(method: StringName, ...) vararg 🔗

Sends a remote procedure call request for the given method to peers on the network (and locally), sending additional arguments to the method called by the RPC. The call request will only be received by nodes with the same NodePath, including the exact same name. Behavior depends on the RPC configuration for the given method (see rpc_config() and @GDScript.@rpc). By default, methods are not exposed to RPCs.

May return @GlobalScope.OK if the call is successful, @GlobalScope.ERR_INVALID_PARAMETER if the arguments passed in the method do not match, @GlobalScope.ERR_UNCONFIGURED if the node's multiplayer cannot be fetched (such as when the node is not inside the tree), @GlobalScope.ERR_CONNECTION_ERROR if multiplayer's connection is not available.

Note: You can only safely use RPCs on clients after you received the MultiplayerAPI.connected_to_server signal from the MultiplayerAPI. You also need to keep track of the connection state, either by the MultiplayerAPI signals like MultiplayerAPI.server_disconnected or by checking (get_multiplayer().peer.get_connection_status() == CONNECTION_CONNECTED).

void rpc_config(method: StringName, config: Variant) 🔗

Changes the RPC configuration for the given method. config should either be null to disable the feature (as by default), or a Dictionary containing the following entries:

rpc_mode: see RPCMode;

transfer_mode: see TransferMode;

call_local: if true, the method will also be called locally;

channel: an int representing the channel to send the RPC on.

Note: In GDScript, this method corresponds to the @GDScript.@rpc annotation, with various parameters passed (@rpc(any), @rpc(authority)...). See also the high-level multiplayer tutorial.

Error rpc_id(peer_id: int, method: StringName, ...) vararg 🔗

Sends a rpc() to a specific peer identified by peer_id (see MultiplayerPeer.set_target_peer()).

May return @GlobalScope.OK if the call is successful, @GlobalScope.ERR_INVALID_PARAMETER if the arguments passed in the method do not match, @GlobalScope.ERR_UNCONFIGURED if the node's multiplayer cannot be fetched (such as when the node is not inside the tree), @GlobalScope.ERR_CONNECTION_ERROR if multiplayer's connection is not available.

void set_deferred_thread_group(property: StringName, value: Variant) 🔗

Similar to call_deferred_thread_group(), but for setting properties.

void set_display_folded(fold: bool) 🔗

If set to true, the node appears folded in the Scene dock. As a result, all of its children are hidden. This method is intended to be used in editor plugins and tools, but it also works in release builds. See also is_displayed_folded().

void set_editable_instance(node: Node, is_editable: bool) 🔗

Set to true to allow all nodes owned by node to be available, and editable, in the Scene dock, even if their owner is not the scene root. This method is intended to be used in editor plugins and tools, but it also works in release builds. See also is_editable_instance().

void set_multiplayer_authority(id: int, recursive: bool = true) 🔗

Sets the node's multiplayer authority to the peer with the given peer id. The multiplayer authority is the peer that has authority over the node on the network. Defaults to peer ID 1 (the server). Useful in conjunction with rpc_config() and the MultiplayerAPI.

If recursive is true, the given peer is recursively set as the authority for all children of this node.

Warning: This does not automatically replicate the new authority to other peers. It is the developer's responsibility to do so. You may replicate the new authority's information using MultiplayerSpawner.spawn_function, an RPC, or a MultiplayerSynchronizer. Furthermore, the parent's authority does not propagate to newly added children.

void set_physics_process(enable: bool) 🔗

If set to true, enables physics (fixed framerate) processing. When a node is being processed, it will receive a NOTIFICATION_PHYSICS_PROCESS at a fixed (usually 60 FPS, see Engine.physics_ticks_per_second to change) interval (and the _physics_process() callback will be called if it exists).

Note: If _physics_process() is overridden, this will be automatically enabled before _ready() is called.

void set_physics_process_internal(enable: bool) 🔗

If set to true, enables internal physics for this node. Internal physics processing happens in isolation from the normal _physics_process() calls and is used by some nodes internally to guarantee proper functioning even if the node is paused or physics processing is disabled for scripting (set_physics_process()).

Warning: Built-in nodes rely on internal processing for their internal logic. Disabling it is unsafe and may lead to unexpected behavior. Use this method if you know what you are doing.

void set_process(enable: bool) 🔗

If set to true, enables processing. When a node is being processed, it will receive a NOTIFICATION_PROCESS on every drawn frame (and the _process() callback will be called if it exists).

Note: If _process() is overridden, this will be automatically enabled before _ready() is called.

Note: This method only affects the _process() callback, i.e. it has no effect on other callbacks like _physics_process(). If you want to disable all processing for the node, set process_mode to PROCESS_MODE_DISABLED.

void set_process_input(enable: bool) 🔗

If set to true, enables input processing.

Note: If _input() is overridden, this will be automatically enabled before _ready() is called. Input processing is also already enabled for GUI controls, such as Button and TextEdit.

void set_process_internal(enable: bool) 🔗

If set to true, enables internal processing for this node. Internal processing happens in isolation from the normal _process() calls and is used by some nodes internally to guarantee proper functioning even if the node is paused or processing is disabled for scripting (set_process()).

Warning: Built-in nodes rely on internal processing for their internal logic. Disabling it is unsafe and may lead to unexpected behavior. Use this method if you know what you are doing.

void set_process_shortcut_input(enable: bool) 🔗

If set to true, enables shortcut processing for this node.

Note: If _shortcut_input() is overridden, this will be automatically enabled before _ready() is called.

void set_process_unhandled_input(enable: bool) 🔗

If set to true, enables unhandled input processing. It enables the node to receive all input that was not previously handled (usually by a Control).

Note: If _unhandled_input() is overridden, this will be automatically enabled before _ready() is called. Unhandled input processing is also already enabled for GUI controls, such as Button and TextEdit.

void set_process_unhandled_key_input(enable: bool) 🔗

If set to true, enables unhandled key input processing.

Note: If _unhandled_key_input() is overridden, this will be automatically enabled before _ready() is called.

void set_scene_instance_load_placeholder(load_placeholder: bool) 🔗

If set to true, the node becomes an InstancePlaceholder when packed and instantiated from a PackedScene. See also get_scene_instance_load_placeholder().

void set_thread_safe(property: StringName, value: Variant) 🔗

Similar to call_thread_safe(), but for setting properties.

void set_translation_domain_inherited() 🔗

Makes this node inherit the translation domain from its parent node. If this node has no parent, the main translation domain will be used.

This is the default behavior for all nodes. Calling Object.set_translation_domain() disables this behavior.

void update_configuration_warnings() 🔗

Refreshes the warnings displayed for this node in the Scene dock. Use _get_configuration_warnings() to customize the warning messages to display.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
func _notification(what):
    if what == NOTIFICATION_TRANSLATION_CHANGED:
        if not is_node_ready():
            await ready # Wait until ready signal.
        $Label.text = atr("%d Bananas") % banana_counter
```

Example 2 (gdscript):
```gdscript
@export var energy = 0:
    set(value):
        energy = value
        update_configuration_warnings()

func _get_configuration_warnings():
    if energy < 0:
        return ["Energy must be 0 or greater."]
    else:
        return []
```

Example 3 (unknown):
```unknown
var child_node = get_child(0)
if child_node.get_parent():
    child_node.get_parent().remove_child(child_node)
add_child(child_node)
```

Example 4 (unknown):
```unknown
Node childNode = GetChild(0);
if (childNode.GetParent() != null)
{
    childNode.GetParent().RemoveChild(childNode);
}
AddChild(childNode);
```

---

## ParticleProcessMaterial 2D Usage — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/particle_process_material_2d.html

**Contents:**
- ParticleProcessMaterial 2D Usage
- Process material properties
  - Lifetime Randomness
- Particle Flags
- Spawn
  - Angle
  - Velocity
    - Direction
    - Spread
    - Flatness

Min, max, and curve properties

The properties in this material control how particles behave and change over their lifetime. A lot of them have Min, Max, and Curve values that allow you to fine-tune their behavior. The relationship between these values is this: When a particle is spawned, the property is set with a random value between Min and Max. If Min and Max are the same, the value will always be the same for every particle. If the Curve is also set, the value of the property will be multiplied by the value of the curve at the current point in a particle's lifetime. Use the curve to change a property over the particle lifetime. Very complex behavior can be expressed this way.

This page covers how to use ParticleProcessMaterial for 2D scenes specifically. For information on how to use it in a 3D scene see Process material properties.

The Lifetime Randomness property controls how much randomness to apply to each particle's lifetime. A value of 0 means there is no randomness at all and all particles live for the same amount of time, set by the Lifetime property. A value of 1 means that a particle's lifetime is completely random within the range of [0.0, Lifetime].

Determines the initial angle of the particle (in degrees). This parameter is mostly useful randomized.

This is the base direction at which particles emit. The default is Vector3(1, 0, 0) which makes particles emit to the right. However, with the default gravity settings, particles will go straight down.

For this property to be noticeable, you need an initial velocity greater than 0. Here, we set the initial velocity to 40. You'll notice that particles emit toward the right, then go down because of gravity.

This parameter is the angle in degrees which will be randomly added in either direction to the base Direction. A spread of 180 will emit in all directions (+/- 180). For spread to do anything the "Initial Velocity" parameter must be greater than 0.

This property is only useful for 3D particles.

Initial velocity is the speed at which particles will be emitted (in pixels/sec). Speed might later be modified by gravity or other accelerations (as described further below).

Angular velocity is the speed at which particles rotate around their center (in degrees/sec).

Orbit velocity is used to make particles turn around their center.

The gravity applied to every particle.

The linear acceleration applied to each particle.

If this acceleration is positive, particles are accelerated away from the center. If negative, they are absorbed towards it.

This acceleration will use the tangent vector to the center. Combining with radial acceleration can do nice effects.

Damping applies friction to the particles, forcing them to stop. It is especially useful for sparks or explosions, which usually begin with a high linear velocity and then stop as they fade.

Determines the initial scale of the particles.

Used to change the color of the particles being emitted.

The Variation value sets the initial hue variation applied to each particle. The Variation Random value controls the hue variation randomness ratio.

Particle flipbook animation is only effective if the CanvasItemMaterial used on the GPUParticles2D or CPUParticles2D node has been configured accordingly.

To set up the particle flipbook for linear playback, set the Speed Min and Speed Max values to 1:

Setting up particle animation for playback during the particle's lifetime

By default, looping is disabled. If the particle is done playing before its lifetime ends, the particle will keep using the flipbook's last frame (which may be fully transparent depending on how the flipbook texture is designed). If looping is enabled, the animation will loop back to the first frame and resume playing.

Depending on how many images your sprite sheet contains and for how long your particle is alive, the animation might not look smooth. The relationship between particle lifetime, animation speed, and number of images in the sprite sheet is this:

At an animation speed of 1.0, the animation will reach the last image in the sequence just as the particle's lifetime ends.

If you wish the particle flipbook to be used as a source of random particle textures for every particle, keep the speed values at 0 and set Offset Max to 1 instead:

Setting up particle animation for random offset on emission

Note that the GPUParticles2D node's Fixed FPS also affects animation playback. For smooth animation playback, it's recommended to set it to 0 so that the particle is simulated on every rendered frame. If this is not an option for your use case, set Fixed FPS to be equal to the effective framerate used by the flipbook animation (see above for the formula).

ParticleProcessMaterials allow you to set an Emission Mask, which dictates the area and direction in which particles are emitted. These can be generated from textures in your project.

Ensure that a ParticleProcessMaterial is set, and the GPUParticles2D node is selected. A "Particles" menu should appear in the Toolbar:

Open it and select "Load Emission Mask":

Then select which texture you want to use as your mask:

A dialog box with several settings will appear.

Three types of emission masks can be generated from a texture:

Solid Pixels: Particles will spawn from any area of the texture, excluding transparent areas.

Border Pixels: Particles will spawn from the outer edges of the texture.

Directed Border Pixels: Similar to Border Pixels, but adds extra information to the mask to give particles the ability to emit away from the borders. Note that an Initial Velocity will need to be set in order to utilize this.

Capture from Pixel will cause the particles to inherit the color of the mask at their spawn points.

Once you click "OK", the mask will be generated and set to the ParticleProcessMaterial, under Spawn and then Position

All of the values within this section have been automatically generated by the "Load Emission Mask" menu, so they should generally be left alone.

An image should not be added to Point Texture or Color Texture directly. The "Load Emission Mask" menu should always be used instead.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Particle shaders — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/shaders/shader_reference/particle_shader.html

**Contents:**
- Particle shaders
- Render modes
- Built-ins
- Global built-ins
- Start and Process built-ins
- Start built-ins
- Process built-ins
- Process functions
- User-contributed notes

Particle shaders are a special type of shader that runs before the object is drawn. They are used for calculating material properties such as color, position, and rotation. They are drawn with any regular material for CanvasItem or Spatial, depending on whether they are 2D or 3D.

Particle shaders are unique because they are not used to draw the object itself; they are used to calculate particle properties, which are then used by a CanvasItem or Spatial shader. They contain two processor functions: start() and process().

Unlike other shader types, particle shaders keep the data that was output the previous frame. Therefore, particle shaders can be used for complex effects that take place over multiple frames.

Particle shaders are only available with GPU-based particle nodes (GPUParticles2D and GPUParticles3D).

CPU-based particle nodes (CPUParticles2D and CPUParticles3D) are rendered on the GPU (which means they can use custom CanvasItem or Spatial shaders), but their motion is simulated on the CPU.

Do not clear previous data on restart.

Disable attractor force.

Ignore VELOCITY value.

Scale the particle's size for collisions.

Values marked as in are read-only. Values marked as out can optionally be written to and will not necessarily contain sensible values. Values marked as inout provide a sensible default value, and can optionally be written to. Samplers cannot be written to so they are not marked.

Global built-ins are available everywhere, including custom functions.

Global time since the engine has started, in seconds. It repeats after every 3,600 seconds (which can be changed with the rollover setting). It's affected by time_scale but not by pausing. If you need a TIME variable that is not affected by time scale, add your own global shader uniform and update it each frame.

A PI constant (3.141592). A ratio of a circle's circumference to its diameter and amount of radians in half turn.

A TAU constant (6.283185). An equivalent of PI * 2 and amount of radians in full turn.

An E constant (2.718281). Euler's number and a base of the natural logarithm.

These properties can be accessed from both the start() and process() functions.

Unique number since emission start.

Particle index (from total particles).

in mat4 EMISSION_TRANSFORM

Emitter transform (used for non-local systems).

Random seed used as base for random.

true when the particle is active, can be set false.

Particle color, can be written to and accessed in mesh's vertex function.

Particle velocity, can be modified.

Custom particle data. Accessible from shader of mesh as INSTANCE_CUSTOM.

Particle mass, intended to be used with attractors. Equals 1.0 by default.

Vector that enables the integration of supplementary user-defined data into the particle process shader. USERDATAX are six built-ins identified by number, X can be numbers between 1 and 6, for example USERDATA3.

in uint FLAG_EMIT_POSITION

A flag for using on the last argument of emit_subparticle() function to assign a position to a new particle's transform.

in uint FLAG_EMIT_ROT_SCALE

A flag for using on the last argument of emit_subparticle() function to assign the rotation and scale to a new particle's transform.

in uint FLAG_EMIT_VELOCITY

A flag for using on the last argument of emit_subparticle() function to assign a velocity to a new particle.

in uint FLAG_EMIT_COLOR

A flag for using on the last argument of emit_subparticle() function to assign a color to a new particle.

in uint FLAG_EMIT_CUSTOM

A flag for using on the last argument of emit_subparticle() function to assign a custom data vector to a new particle.

in vec3 EMITTER_VELOCITY

Velocity of the Particles2D (3D) node.

in float INTERPOLATE_TO_END

Value of interp_to_end (3D) property of Particles node.

Value of amount_ratio (3D) property of Particles node.

In order to use the COLOR variable in a StandardMaterial3D, set vertex_color_use_as_albedo to true. In a ShaderMaterial, access it with the COLOR variable.

in bool RESTART_POSITION

true if particle is restarted, or emitted without a custom position (i.e. this particle was created by emit_subparticle() without the FLAG_EMIT_POSITION flag).

in bool RESTART_ROT_SCALE

true if particle is restarted, or emitted without a custom rotation or scale (i.e. this particle was created by emit_subparticle() without the FLAG_EMIT_ROT_SCALE flag).

in bool RESTART_VELOCITY

true if particle is restarted, or emitted without a custom velocity (i.e. this particle was created by emit_subparticle() without the FLAG_EMIT_VELOCITY flag).

in bool RESTART_COLOR

true if particle is restarted, or emitted without a custom color (i.e. this particle was created by emit_subparticle() without the FLAG_EMIT_COLOR flag).

in bool RESTART_CUSTOM

true if particle is restarted, or emitted without a custom property (i.e. this particle was created by emit_subparticle() without the FLAG_EMIT_CUSTOM flag).

true if the current process frame is first for the particle.

true when the particle has collided with a particle collider.

in vec3 COLLISION_NORMAL

A normal of the last collision. If there is no collision detected it is equal to (0.0, 0.0, 0.0).

in float COLLISION_DEPTH

A length of normal of the last collision. If there is no collision detected it is equal to 0.0.

in vec3 ATTRACTOR_FORCE

A combined force of the attractors at the moment on that particle.

emit_subparticle() is currently the only custom function supported by particles shaders. It allows users to add a new particle with specified parameters from a sub-emitter. The newly created particle will only use the properties that match the flags parameter. For example, the following code will emit a particle with a specified position, velocity, and color, but unspecified rotation, scale, and custom value:

bool emit_subparticle (mat4 xform, vec3 velocity, vec4 color, vec4 custom, uint flags)

Emits a particle from a sub-emitter.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
mat4 custom_transform = mat4(1.0);
custom_transform[3].xyz = vec3(10.5, 0.0, 4.0);
emit_subparticle(custom_transform, vec3(1.0, 0.5, 1.0), vec4(1.0, 0.0, 0.0, 1.0), vec4(1.0), FLAG_EMIT_POSITION | FLAG_EMIT_VELOCITY | FLAG_EMIT_COLOR);
```

---

## Playing videos — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/animation/playing_videos.html

**Contents:**
- Playing videos
- Supported playback formats
- Setting up VideoStreamPlayer
  - Handling resizing and different aspect ratios
  - Displaying a video on a 3D surface
  - Looping a video
- Video decoding conditions and recommended resolutions
- Playback limitations
- Recommended Theora encoding settings
  - Balancing quality and file size

Godot supports video playback with the VideoStreamPlayer node.

The only supported format in core is Ogg Theora (not to be confused with Ogg Vorbis audio) with optional Ogg Vorbis audio tracks. It's possible for extensions to bring support for additional formats.

H.264 and H.265 cannot be supported in core Godot, as they are both encumbered by software patents. AV1 is royalty-free, but it remains slow to decode on the CPU and hardware decoding support isn't readily available on all GPUs in use yet.

WebM was supported in core in Godot 3.x, but support for it was removed in 4.0 as it was too buggy and difficult to maintain.

You may find videos with a .ogg or .ogx extensions, which are generic extensions for data within an Ogg container.

Renaming these file extensions to .ogv may allow the videos to be imported in Godot. However, not all files with .ogg or .ogx extensions are videos - some of them may only contain audio.

Create a VideoStreamPlayer node using the Create New Node dialog.

Select the VideoStreamPlayer node in the scene tree dock, go to the inspector and load a .ogv file in the Stream property.

If you don't have your video in Ogg Theora format yet, jump to Recommended Theora encoding settings.

If you want the video to play as soon as the scene is loaded, check Autoplay in the inspector. If not, leave Autoplay disabled and call play() on the VideoStreamPlayer node in a script to start playback when desired.

By default in Godot 4.0, the VideoStreamPlayer will automatically be resized to match the video's resolution. You can make it follow usual Control sizing by enabling Expand on the VideoStreamPlayer node.

To adjust how the VideoStreamPlayer node resizes depending on window size, adjust the anchors using the Layout menu at the top of the 2D editor viewport. However, this setup may not be powerful enough to handle all use cases, such as playing fullscreen videos without distorting the video (but with empty space on the edges instead). For more control, you can use an AspectRatioContainer node, which is designed to handle this kind of use case:

Add an AspectRatioContainer node. Make sure it is not a child of any other container node. Select the AspectRatioContainer node, then set its Layout at the top of the 2D editor to Full Rect. Set Ratio in the AspectRatioContainer node to match your video's aspect ratio. You can use math formulas in the inspector to help yourself. Remember to make one of the operands a float. Otherwise, the division's result will always be an integer.

This will evaluate to (approximately) 1.777778

Once you've configured the AspectRatioContainer, reparent your VideoStreamPlayer node to be a child of the AspectRatioContainer node. Make sure Expand is enabled on the VideoStreamPlayer. Your video should now scale automatically to fit the whole screen while avoiding distortion.

See Multiple resolutions for more tips on supporting multiple aspect ratios in your project.

Using a VideoStreamPlayer node as a child of a SubViewport node, it's possible to display any 2D node on a 3D surface. For example, this can be used to display animated billboards when frame-by-frame animation would require too much memory.

This can be done with the following steps:

Create a SubViewport node. Set its size to match your video's size in pixels.

Create a VideoStreamPlayer node as a child of the SubViewport node and specify a video path in it. Make sure Expand is disabled, and enable Autoplay if needed.

Create a MeshInstance3D node with a PlaneMesh or QuadMesh resource in its Mesh property. Resize the mesh to match the video's aspect ratio (otherwise, it will appear distorted).

Create a new StandardMaterial3D resource in the Material Override property in the GeometryInstance3D section.

Enable Local To Scene in the StandardMaterial3D's Resource section (at the bottom). This is required before you can use a ViewportTexture in its Albedo Texture property.

In the StandardMaterial3D, set the Albedo > Texture property to New ViewportTexture. Edit the new resource by clicking it, then specify the path to the SubViewport node in the Viewport Path property.

Enable Albedo Texture Force sRGB in the StandardMaterial3D to prevent colors from being washed out.

If the billboard is supposed to emit its own light, set Shading Mode to Unshaded to improve rendering performance.

See Using Viewports and the GUI in 3D demo for more information on setting this up.

For looping a video, the Loop property can be enabled. This will seamlessly restart the video when it reaches its end.

Note that setting the project setting Video Delay Compensation to a non-zero value might cause your loop to not be seamless, because the synchronization of audio and video takes place at the start of each loop causing occasional missed frames. Set Video Delay Compensation in your project settings to 0 to avoid frame drop issues.

Video decoding is performed on the CPU, as GPUs don't have hardware acceleration for decoding Theora videos. Modern desktop CPUs can decode Ogg Theora videos at 1440p @ 60 FPS or more, but low-end mobile CPUs will likely struggle with high-resolution videos.

To ensure your videos decode smoothly on varied hardware:

When developing games for desktop platforms, it's recommended to encode in 1080p at most (preferably at 30 FPS). Most people are still using 1080p or lower resolution displays, so encoding higher-resolution videos may not be worth the increased file size and CPU requirements.

When developing games for mobile or web platforms, it's recommended to encode in 720p at most (preferably at 30 FPS or even lower). The visual difference between 720p and 1080p videos on a mobile device is usually not that noticeable.

There are some limitations with the current implementation of video playback in Godot:

Streaming a video from a URL is not supported.

Only mono and stereo audio output is supported. Videos with 4, 5.1 and 7.1 audio channels are supported but down-mixed to stereo.

A word of advice is to avoid relying on built-in Ogg Theora exporters (most of the time). There are 2 reasons you may want to favor using an external program to encode your video:

Some programs such as Blender can render to Ogg Theora. However, the default quality presets are usually very low by today's standards. You may be able to increase the quality options in the software you're using, but you may find the output quality to remain less than ideal (given the increased file size). This usually means that the software only supports encoding to constant bit rate (CBR), instead of variable bit rate (VBR). VBR encoding should be preferred in most scenarios as it provides a better quality to file size ratio.

Some other programs can't render to Ogg Theora at all.

In this case, you can render the video to an intermediate high-quality format (such as a high-bitrate H.264 video) then re-encode it to Ogg Theora. Ideally, you should use a lossless or uncompressed format as an intermediate format to maximize the quality of the output Ogg Theora video, but this can require a lot of disk space.

FFmpeg (CLI) is a popular open source tool for this purpose. FFmpeg has a steep learning curve, but it's a powerful tool.

Here are example FFmpeg commands to convert an MP4 video to Ogg Theora. Since FFmpeg supports a lot of input formats, you should be able to use the commands below with almost any input video format (AVI, MOV, WebM, …).

Make sure your copy of FFmpeg is compiled with libtheora and libvorbis support. You can check this by running ffmpeg without any arguments, then looking at the configuration: line in the command output.

Current official FFmpeg releases have some bugs in their Ogg/Theora multiplexer. It's highly recommended to use one of the latest static daily builds, or build from their master branch to get the latest fixes.

The video quality level (-q:v) must be between 1 and 10. Quality 6 is a good compromise between quality and file size. If encoding at a high resolution (such as 1440p or 4K), you will probably want to decrease -q:v to 5 to keep file sizes reasonable. Since pixel density is higher on a 1440p or 4K video, lower quality presets at higher resolutions will look as good or better compared to low-resolution videos.

The audio quality level (-q:a) must be between -1 and 10. Quality 6 provides a good compromise between quality and file size. In contrast to video quality, increasing audio quality doesn't increase the output file size nearly as much. Therefore, if you want the cleanest audio possible, you can increase this to 9 to get perceptually lossless audio. This is especially valuable if your input file already uses lossy audio compression. Higher quality audio does increase the CPU usage of the decoder, so it might lead to audio dropouts in case of high system load. See this page for a table listing Ogg Vorbis audio quality presets and their respective variable bitrates.

The GOP (Group of Pictures) size (-g:v) is the max interval between keyframes. Increasing this value can improve compression with almost no impact on quality. The default size (12) is too low for most types of content, it's therefore recommended using higher GOP values before reducing video quality. Compression benefits will fade away as the GOP size increases though. Values between 64 and 512 usually give the best compression.

Higher GOP sizes will increase max seek times with a sudden increase when going beyond powers of two starting at 64. Max seek times with GOP size 65 can be almost twice as long as with GOP size 64, depending on decoding speed.

The following command converts the video while keeping its original resolution. The video and audio's bitrate will be variable to maximize quality while saving space in parts of the video/audio that don't require a high bitrate (such as static scenes).

The following command resizes a video to be 720 pixels tall (720p), while preserving its existing aspect ratio. This helps decrease the file size significantly if the source is recorded at a higher resolution than 720p:

Chroma key, commonly known as the "green screen" or "blue screen" effect, allows you to remove a specific color from an image or video and replace it with another background. This effect is widely used in video production to composite different elements together seamlessly.

We will achieve the chroma key effect by writing a custom shader in GDScript and using a VideoStreamPlayer node to display the video content.

Ensure that the scene contains a VideoStreamPlayer node to play the video and a Control node to hold the UI elements for controlling the chroma key effect.

To implement the chroma key effect, follow these steps:

Select the VideoStreamPlayer node in the scene and go to its properties. Under CanvasItem > Material, create a new shader named "ChromaKeyShader.gdshader."

In the "ChromaKeyShader.gdshader" file, write the custom shader code as shown below:

The shader uses the distance calculation to identify pixels close to the chroma key color and discards them, effectively removing the selected color. Pixels that are slightly further away from the chroma key color are faded based on the fade_factor, blending them smoothly with the surrounding colors. This process creates the desired chroma key effect, making it appear as if the background has been replaced with another image or video.

The code above represents a simple demonstration of the Chroma Key shader, and users can customize it according to their specific requirements.

To allow users to manipulate the chroma key effect in real-time, we created sliders in the Control node. The Control node's script contains the following functions:

also make sure that the range of the sliders are appropriate, our settings are :

Connect the appropriate signal from the UI elements to the Control node's script. you created in the Control node's script to control the chroma key effect. These signal handlers will update the shader's uniform variables in response to user input.

Save and run the scene to see the chroma key effect in action! With the provided UI controls, you can now adjust the chroma key color, pickup range, and fade amount in real-time, achieving the desired chroma key functionality for your video content.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
ffmpeg -i input.mp4 -q:v 6 -q:a 6 -g:v 64 output.ogv
```

Example 2 (unknown):
```unknown
ffmpeg -i input.mp4 -vf "scale=-1:720" -q:v 6 -q:a 6 -g:v 64 output.ogv
```

Example 3 (unknown):
```unknown
shader_type canvas_item;

// Uniform variables for chroma key effect
uniform vec3 chroma_key_color : source_color = vec3(0.0, 1.0, 0.0);
uniform float pickup_range : hint_range(0.0, 1.0) = 0.1;
uniform float fade_amount : hint_range(0.0, 1.0) = 0.1;

void fragment() {
    // Get the color from the texture at the given UV coordinates
    vec4 color = texture(TEXTURE, UV);

    // Calculate the distance between the current color and the chroma key color
    float distance = length(color.rgb - chroma_key_color);

    // If the distance is within the pickup range, discard the pixel
    // the lesser the distance more likely the colors are
    if (distance <= pickup_range) {
        discard;
    }

    // Calculate the fade factor based on the pickup range and fade amount
    float fade_factor = smoothstep(pickup_range, pickup_range + fade_amount, distance);

    // Set the output color with the original RGB values and the calculated fade factor
    COLOR = vec4(color.rgb, fade_factor);
}
```

Example 4 (unknown):
```unknown
extends Control

 func _on_color_picker_button_color_changed(color):
     # Update the "chroma_key_color" shader parameter of the VideoStreamPlayer's material.
     $VideoStreamPlayer.material.set("shader_parameter/chroma_key_color", color)

 func _on_h_slider_value_changed(value):
     # Update the "pickup_range" shader parameter of the VideoStreamPlayer's material.
     $VideoStreamPlayer.material.set("shader_parameter/pickup_range", value)

 func _on_h_slider_2_value_changed(value):
     # Update the "fade_amount" shader parameter of the VideoStreamPlayer's material.
     $VideoStreamPlayer.material.set("shader_parameter/fade_amount", value)

func _on_video_stream_player_finished():
     # Restart the video playback when it's finished.
     $VideoStreamPlayer.play()
```

---

## Using AnimationTree — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/animation/animation_tree.html

**Contents:**
- Using AnimationTree
- Introduction
- AnimationTree and AnimationPlayer
- Creating a tree
- Blend tree
  - Blend2 / Blend3
  - OneShot
  - TimeSeek
  - TimeScale
  - Transition

With AnimationPlayer, Godot has one of the most flexible animation systems that you can find in any game engine. It is pretty much unique in its ability to animate almost any property in any node or resource, and its dedicated transform, bezier, function calling, audio, and sub-animation tracks.

However, the support for blending those animations via AnimationPlayer is limited, as you can only set a fixed cross-fade transition time.

AnimationTree is a new node introduced in Godot 3.1 to deal with advanced transitions. It replaces the ancient AnimationTreePlayer, while adding a huge amount of features and flexibility.

Before starting, know that an AnimationTree node does not contain its own animations. Instead, it uses animations contained in an AnimationPlayer node. You create, edit, or import your animations in an AnimationPlayer and then use an AnimationTree to control the playback.

AnimationPlayer and AnimationTree can be used in both 2D and 3D scenes. When importing 3D scenes and their animations, you can use name suffixes to simplify the process and import with the correct properties. At the end, the imported Godot scene will contain the animations in an AnimationPlayer node. Since you rarely use imported scenes directly in Godot (they are either instantiated or inherited from), you can place the AnimationTree node in your new scene which contains the imported one. Afterwards, point the AnimationTree node to the AnimationPlayer that was created in the imported scene.

This is how it's done in the Third Person Shooter demo, for reference:

A new scene was created for the player with a CharacterBody3D as root. Inside this scene, the original .dae (Collada) file was instantiated and an AnimationTree node was created.

To use an AnimationTree, you have to set a root node. An animation root node is a class that contains and evaluates sub-nodes and outputs an animation. There are 3 types of sub-nodes:

Animation nodes, which reference an animation from the linked AnimationPlayer.

Animation Root nodes, which are used to blend sub-nodes and can be nested.

Animation Blend nodes, which are used in an AnimationNodeBlendTree, a 2D graph of nodes. Blend nodes take multiple input ports and give one output port.

A few types of root nodes are available:

AnimationNodeAnimation: Selects an animation from the list and plays it. This is the simplest root node, and generally not used as a root.

AnimationNodeBlendTree: Contains multiple nodes as children in a graph. Many blend nodes are available, such as mix, blend2, blend3, one shot, etc.

AnimationNodeBlendSpace1D: Allows linear blending between two animation nodes. Control the blend position in a 1D blend space to mix between animations.

AnimationNodeBlendSpace2D: Allows linear blending between three animation nodes. Control the blend position in a 2D blend space to mix between animations.

AnimationNodeStateMachine: Contains multiple nodes as children in a graph. Each node is used as a state, with multiple functions used to alternate between states.

When you make an AnimationNodeBlendTree, you get an empty 2d graph in the bottom panel, under the AnimationTree tab. It contains only an Output node by default.

In order for animations to play, a node has to be connected to the output. You can add nodes from the Add Node.. menu or by right clicking an empty space:

The simplest connection to make is to connect an Animation node to the output directly, which will just play back the animation.

Following is a description of the other available nodes:

These nodes will blend between two or three inputs by a user-specified blend value:

Blending can use filters to control individually which tracks get blended and which do not. This can be useful for layering animations on top of each other.

For more complex blending, it is recommended to use blend spaces instead.

This node will execute an animation once and return when it finishes. You can customize blend times for fading in and out, as well as filters.

This node allows you to seek to a time in the animation connected to its in input. Use this node to play an Animation starting from a certain playback position. Note that the seek request value is measured in seconds, so if you would like to play an animation from the beginning, set the value to 0.0, or if you would like to play an animation from 3 seconds in, set the value to 3.0.

This node allows you to scale the speed of the animation connected to its in input. The speed of the animation will be multiplied by the number in the scale parameter. Setting the scale to 0 will pause the animation. Setting the scale to a negative number will play the animation backwards.

This node is a simplified version of a StateMachine. You connect animations to the inputs, and the current state index determines which animation to play. You may specify a crossfade transition time. In the Inspector, you may change the number of input ports, rearrange inputs, or delete inputs.

When you make an AnimationNodeStateMachine, you get an empty 2d graph in the bottom panel, under the AnimationTree tab. It contains a Start and End state by default.

To add states, right click or use the create new nodes button, whose icon is a plus in a box. You can add animations, blendspaces, blendtrees, or even another StateMachine. To edit one of these more complex sub-nodes, click on the pencil icon on the right of the state. To return to the original StateMachine, click Root on the top left of the panel.

Before the StateMachine can do anything useful, the states must be connected with transitions. To add a transition, click the connect nodes button, which is a line with a right-facing arrow, and drag between two states. You can create 2 transitions between states, one going in each direction.

There are 3 types of transitions:

Immediate: Will switch to the next state immediately.

Sync: Will switch to the next state immediately, but will seek the new state to the playback position of the old state.

At End: Will wait for the current state playback to end, then switch to the beginning of the next state animation.

Transitions also have a few properties. Click a transition and it will be displayed in the inspector:

Xfade Time is the time to cross-fade between this state and the next.

Xfade Curve is a cross-fade following a curve rather than a linear blend.

Reset determines whether the state you are switching into plays from the beginning (true) or not (false).

Priority is used together with the travel() function from code (more on this later). Lower priority transitions are preferred when travelling through the tree.

Switch Mode is the transition type (see above). It can be changed after creation here.

Advance Mode determines the advance mode. If Disabled, the transition will not be used. If Enabled, the transition will only be used during travel(). If Auto, the transition will be used if the advance condition and expression are true, or if there are no advance conditions/expressions.

The last 2 properties in a StateMachine transition are Advance Condition and Advance Expression. When the Advance Mode is set to Auto, these determine if the transition will advance or not.

Advance Condition is a true/false check. You may put a custom variable name in the text field, and when the StateMachine reaches this transition, it will check if your variable is true. If so, the transition continues. Note that the advance condition only checks if a variable is true, and it cannot check for falseness.

This gives the Advance Condition a very limited capability. If you wanted to make a transition back and forth based on one property, you would need to make 2 variables that have opposite values, and check if either of them are true. This is why, in Godot 4, the Advance Expression was added.

The Advance Expression works similar to the Advance Condition, but instead of checking if one variable is true, it evaluates any expression. An expression is anything you could put in an if statement. These are all examples of expressions that would work in the Advance Expression:

is_walking && !is_idle

Here is an example of an improperly-set-up StateMachine transition using Advance Condition:

This is not working because there is a ! variable in the Advance Condition, which cannot be checked.

Here is the same example, set up properly, using two opposite variables:

Here is the same example, but using Advance Expression rather than Advance Condition, which eliminates the need for two variables:

In order to use Advance Expressions, the Advance Expression Base Node has to be set from the Inspector of the AnimationTree node. By default, it is set to the AnimationTree node itself, but it needs to point to whatever node contains the script with your animation variables.

One of the nice features in Godot's StateMachine implementation is the ability to travel. You can instruct the graph to go from the current state to another one, while visiting all the intermediate ones. This is done via the A* algorithm. If there is no path of transitions starting at the current state and finishing at the destination state, the graph teleports to the destination state.

To use the travel ability, you should first retrieve the AnimationNodeStateMachinePlayback object from the AnimationTree node (it is exported as a property), and then call one of its many functions:

The StateMachine must be running before you can travel. Make sure to either call start() or connect a node to Start.

BlendSpace2D is a node to do advanced blending in two dimensions. Points representing animations are added to a 2D space and then a position between them is controlled to determine the blending:

You may place these points anywhere on the graph by right clicking or using the add point button, whose icon is a pen and point. Wherever you place the points, the triangle between them will be generated automatically using Delaunay. You may also control and label the ranges in X and Y.

Finally, you may also change the blend mode. By default, blending happens by interpolating points inside the closest triangle. When dealing with 2D animations (frame by frame), you may want to switch to Discrete mode. Alternatively, if you want to keep the current play position when switching between discrete animations, there is a Carry mode. This mode can be changed in the Blend menu:

BlendSpace1D works just like BlendSpace2D, but in one dimension (a line). Triangles are not used.

In Godot 4.0+, in order for the blending results to be deterministic (reproducible and always consistent), the blended property values must have a specific initial value. For example, in the case of two animations to be blended, if one animation has a property track and the other does not, the blended animation is calculated as if the latter animation had a property track with the initial value.

When using Position/Rotation/Scale 3D tracks for Skeleton3D bones, the initial value is Bone Rest. For other properties, the initial value is 0 and if the track is present in the RESET animation, the value of its first keyframe is used instead.

For example, the following AnimationPlayer has two animations, but one of them lacks a Property track for Position.

This means that the animation lacking that will treat those Positions as Vector2(0, 0).

This problem can be solved by adding a Property track for Position as an initial value to the RESET animation.

Be aware that the RESET animation exists to define the default pose when loading an object originally. It is assumed to have only one frame and is not expected to be played back using the timeline.

Also keep in mind that the Rotation 3D tracks and the Property tracks for 2D rotation with Interpolation Type set to Linear Angle or Cubic Angle will prevent rotations greater than 180 degrees from the initial value as blended animation.

This can be useful for Skeleton3Ds to prevent the bones penetrating the body when blending animations. Therefore, Skeleton3D's Bone Rest values should be as close to the midpoint of the movable range as possible. This means that for humanoid models, it is preferable to import them in a T-pose.

You can see that the shortest rotation path from Bone Rests is prioritized rather than the shortest rotation path between animations.

If you need to rotate Skeleton3D itself more than 180 degrees by blend animations for movement, you can use Root Motion.

When working with 3D animations, a popular technique is for animators to use the root skeleton bone to give motion to the rest of the skeleton. This allows animating characters in a way where steps actually match the floor below. It also allows precise interaction with objects during cinematics.

When playing back the animation in Godot, it is possible to select this bone as the root motion track. Doing so will cancel the bone transformation visually (the animation will stay in place).

Afterwards, the actual motion can be retrieved via the AnimationTree API as a transform:

This can be fed to functions such as CharacterBody3D.move_and_slide to control the character movement.

There is also a tool node, RootMotionView, you can place a scene that will act as a custom floor for your character and animations (this node is disabled by default during the game).

After building the tree and previewing it, the only question remaining is "How is all this controlled from code?".

Keep in mind that the animation nodes are just resources, so they are shared between all instances using them. Setting values in the nodes directly will affect all instances of the scene that uses this AnimationTree. This is generally undesirable, but does have some cool use cases, e.g. you can copy and paste parts of your animation tree, or reuse nodes with a complex layout (such as a StateMachine or blend space) in different animation trees.

The actual animation data is contained in the AnimationTree node and is accessed via properties. Check the "Parameters" section of the AnimationTree node to see all the parameters that can be modified in real-time:

This is handy because it makes it possible to animate them from an AnimationPlayer, or even the AnimationTree itself, allowing very complex animation logic.

To modify these values from code, you must obtain the property path. You can find them by hovering your mouse over any of the parameters:

Then you can set or read them:

Advance Expressions from a StateMachine will not be found under the parameters. This is because they are held in another script rather than the AnimationTree itself. Advance Conditions will be found under parameters.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
# Play child animation connected to "shot" port.
animation_tree.set("parameters/OneShot/request", AnimationNodeOneShot.ONE_SHOT_REQUEST_FIRE)
# Alternative syntax (same result).
animation_tree["parameters/OneShot/request"] = AnimationNodeOneShot.ONE_SHOT_REQUEST_FIRE

# Abort child animation connected to "shot" port.
animation_tree.set("parameters/OneShot/request", AnimationNodeOneShot.ONE_SHOT_REQUEST_ABORT)
# Alternative syntax (same result).
animation_tree["parameters/OneShot/request"] = AnimationNodeOneShot.ONE_SHOT_REQUEST_ABORT

# Get current state (read-only).
animation_tree.get("parameters/OneShot/active"))
# Alternative syntax (same result).
animation_tree["parameters/OneShot/active"]
```

Example 2 (unknown):
```unknown
// Play child animation connected to "shot" port.
animationTree.Set("parameters/OneShot/request", (int)AnimationNodeOneShot.OneShotRequest.Fire);

// Abort child animation connected to "shot" port.
animationTree.Set("parameters/OneShot/request", (int)AnimationNodeOneShot.OneShotRequest.Abort);

// Get current state (read-only).
animationTree.Get("parameters/OneShot/active");
```

Example 3 (unknown):
```unknown
# Play child animation from the start.
animation_tree.set("parameters/TimeSeek/seek_request", 0.0)
# Alternative syntax (same result).
animation_tree["parameters/TimeSeek/seek_request"] = 0.0

# Play child animation from 12 second timestamp.
animation_tree.set("parameters/TimeSeek/seek_request", 12.0)
# Alternative syntax (same result).
animation_tree["parameters/TimeSeek/seek_request"] = 12.0
```

Example 4 (unknown):
```unknown
// Play child animation from the start.
animationTree.Set("parameters/TimeSeek/seek_request", 0.0);

// Play child animation from 12 second timestamp.
animationTree.Set("parameters/TimeSeek/seek_request", 12.0);
```

---

## Using Area2D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/physics/using_area_2d.html

**Contents:**
- Using Area2D
- Introduction
- What is an area?
- Area properties
- Overlap detection
- Area influence
  - Point gravity
  - Examples
- User-contributed notes

Godot offers a number of collision objects to provide both collision detection and response. Trying to decide which one to use for your project can be confusing. You can avoid problems and simplify development if you understand how each of them works and what their pros and cons are. In this tutorial, we'll look at the Area2D node and show some examples of how it can be used.

This document assumes you're familiar with Godot's various physics bodies. Please read Physics introduction first.

An Area2D defines a region of 2D space. In this space you can detect other CollisionObject2D nodes overlapping, entering, and exiting. Areas also allow for overriding local physics properties. We'll explore each of these functions below.

Areas have many properties you can use to customize their behavior.

The Gravity, Linear Damp, and Angular Damp sections are used to configure the area's physics override behavior. We'll look at how to use those in the Area influence section below.

Monitoring and Monitorable are used to enable and disable the area.

The Audio Bus section allows you to override audio in the area, for example to apply an audio effect when the player moves through.

Note that Area2D extends CollisionObject2D, so it also provides properties inherited from that class. The Collision section of CollisionObject2D is where you configure the area's collision layer(s) and mask(s).

Perhaps the most common use of Area2D nodes is for contact and overlap detection. When you need to know that two objects have touched, but don't need physical collision, you can use an area to notify you of the contact.

For example, let's say we're making a coin for the player to pick up. The coin is not a solid object - the player can't stand on it or push it - we just want it to disappear when the player touches it.

Here's the node setup for the coin:

To detect the overlap, we'll connect the appropriate signal on the Area2D. Which signal to use depends on the player's node type. If the player is another area, use area_entered. However, let's assume our player is a CharacterBody2D (and therefore a CollisionObject2D type), so we'll connect the body_entered signal.

If you're not familiar with using signals, see Using signals for an introduction.

Now our player can collect the coins!

Some other usage examples:

Areas are great for bullets and other projectiles that hit and deal damage, but don't need any other physics such as bouncing.

Use a large circular area around an enemy to define its "detect" radius. When the player is outside the area, the enemy can't "see" it.

"Security cameras" - In a large level with multiple cameras, attach areas to each camera and activate them when the player enters.

See the Your first 2D game for an example of using Area2D in a game.

The second major use for area nodes is to alter physics. By default, the area won't do this, but you can enable this with the Space Override property. When areas overlap, they are processed in Priority order (higher priority areas are processed first). There are four options for override:

Combine - The area adds its values to what has been calculated so far.

Replace - The area replaces physics properties, and lower priority areas are ignored.

Combine-Replace - The area adds its gravity/damping values to whatever has been calculated so far (in priority order), ignoring any lower priority areas.

Replace-Combine - The area replaces any gravity/damping calculated so far, but keeps calculating the rest of the areas.

Using these properties, you can create very complex behavior with multiple overlapping areas.

The physics properties that can be overridden are:

Gravity - Gravity's strength inside the area.

Gravity Direction - This vector does not need to be normalized.

Linear Damp - How quickly objects stop moving - linear velocity lost per second.

Angular Damp - How quickly objects stop spinning - angular velocity lost per second.

The Gravity Point property allows you to create an "attractor". Gravity in the area will be calculated towards a point, given by the Point Center property. Values are relative to the Area2D, so for example using (0, 0) will attract objects to the center of the area.

The example project attached below has three areas demonstrating physics override.

You can download this project here: area_2d_starter.zip

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
extends Area2D

func _on_coin_body_entered(body):
    queue_free()
```

Example 2 (unknown):
```unknown
using Godot;

public partial class Coin : Area2D
{
    private void OnCoinBodyEntered(PhysicsBody2D body)
    {
        QueueFree();
    }
}
```

---

## Using CharacterBody2D/3D — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/physics/using_character_body_2d.html

**Contents:**
- Using CharacterBody2D/3D
- Introduction
- What is a character body?
- Movement and collision
  - move_and_collide
  - move_and_slide
- Detecting collisions
- Which movement method to use?
- Examples
  - Movement and walls

Godot offers several collision objects to provide both collision detection and response. Trying to decide which one to use for your project can be confusing. You can avoid problems and simplify development if you understand how each of them works and what their pros and cons are. In this tutorial, we'll look at the CharacterBody2D node and show some examples of how to use it.

While this document uses CharacterBody2D in its examples, the same concepts apply in 3D as well.

CharacterBody2D is for implementing bodies that are controlled via code. Character bodies detect collisions with other bodies when moving, but are not affected by engine physics properties, like gravity or friction. While this means that you have to write some code to create their behavior, it also means you have more precise control over how they move and react.

This document assumes you're familiar with Godot's various physics bodies. Please read Physics introduction first, for an overview of the physics options.

A CharacterBody2D can be affected by gravity and other forces, but you must calculate the movement in code. The physics engine will not move a CharacterBody2D.

When moving a CharacterBody2D, you should not set its position property directly. Instead, you use the move_and_collide() or move_and_slide() methods. These methods move the body along a given vector and detect collisions.

You should handle physics body movement in the _physics_process() callback.

The two movement methods serve different purposes, and later in this tutorial, you'll see examples of how they work.

This method takes one required parameter: a Vector2 indicating the body's relative movement. Typically, this is your velocity vector multiplied by the frame timestep (delta). If the engine detects a collision anywhere along this vector, the body will immediately stop moving. If this happens, the method will return a KinematicCollision2D object.

KinematicCollision2D is an object containing data about the collision and the colliding object. Using this data, you can calculate your collision response.

move_and_collide is most useful when you just want to move the body and detect collision, but don't need any automatic collision response. For example, if you need a bullet that ricochets off a wall, you can directly change the angle of the velocity when you detect a collision. See below for an example.

The move_and_slide() method is intended to simplify the collision response in the common case where you want one body to slide along the other. It is especially useful in platformers or top-down games, for example.

When calling move_and_slide(), the function uses a number of node properties to calculate its slide behavior. These properties can be found in the Inspector, or set in code.

velocity - default value: Vector2( 0, 0 )

This property represents the body's velocity vector in pixels per second. move_and_slide() will modify this value automatically when colliding.

motion_mode - default value: MOTION_MODE_GROUNDED

This property is typically used to distinguish between side-scrolling and top-down movement. When using the default value, you can use the is_on_floor(), is_on_wall(), and is_on_ceiling() methods to detect what type of surface the body is in contact with, and the body will interact with slopes. When using MOTION_MODE_FLOATING, all collisions will be considered "walls".

up_direction - default value: Vector2( 0, -1 )

This property allows you to define what surfaces the engine should consider being the floor. Its value lets you use the is_on_floor(), is_on_wall(), and is_on_ceiling() methods to detect what type of surface the body is in contact with. The default value means that the top side of horizontal surfaces will be considered "ground".

floor_stop_on_slope - default value: true

This parameter prevents a body from sliding down slopes when standing still.

wall_min_slide_angle - default value: 0.261799 (in radians, equivalent to 15 degrees)

This is the minimum angle where the body is allowed to slide when it hits a slope.

floor_max_angle - default value: 0.785398 (in radians, equivalent to 45 degrees)

This parameter is the maximum angle before a surface is no longer considered a "floor."

There are many other properties that can be used to modify the body's behavior under specific circumstances. See the CharacterBody2D docs for full details.

When using move_and_collide() the function returns a KinematicCollision2D directly, and you can use this in your code.

When using move_and_slide() it's possible to have multiple collisions occur, as the slide response is calculated. To process these collisions, use get_slide_collision_count() and get_slide_collision():

get_slide_collision_count() only counts times the body has collided and changed direction.

See KinematicCollision2D for details on what collision data is returned.

A common question from new Godot users is: "How do you decide which movement function to use?" Often, the response is to use move_and_slide() because it seems simpler, but this is not necessarily the case. One way to think of it is that move_and_slide() is a special case, and move_and_collide() is more general. For example, the following two code snippets result in the same collision response:

Anything you do with move_and_slide() can also be done with move_and_collide(), but it might take a little more code. However, as we'll see in the examples below, there are cases where move_and_slide() doesn't provide the response you want.

In the example above, move_and_slide() automatically alters the velocity variable. This is because when the character collides with the environment, the function recalculates the speed internally to reflect the slowdown.

For example, if your character fell on the floor, you don't want it to accumulate vertical speed due to the effect of gravity. Instead, you want its vertical speed to reset to zero.

move_and_slide() may also recalculate the kinematic body's velocity several times in a loop as, to produce a smooth motion, it moves the character and collides up to five times by default. At the end of the process, the character's new velocity is available for use on the next frame.

To see these examples in action, download the sample project: character_body_2d_starter.zip

If you've downloaded the sample project, this example is in "basic_movement.tscn".

For this example, add a CharacterBody2D with two children: a Sprite2D and a CollisionShape2D. Use the Godot "icon.svg" as the Sprite2D's texture (drag it from the Filesystem dock to the Texture property of the Sprite2D). In the CollisionShape2D's Shape property, select "New RectangleShape2D" and size the rectangle to fit over the sprite image.

See 2D movement overview for examples of implementing 2D movement schemes.

Attach a script to the CharacterBody2D and add the following code:

Run this scene and you'll see that move_and_collide() works as expected, moving the body along the velocity vector. Now let's see what happens when you add some obstacles. Add a StaticBody2D with a rectangular collision shape. For visibility, you can use a Sprite2D, a Polygon2D, or turn on "Visible Collision Shapes" from the "Debug" menu.

Run the scene again and try moving into the obstacle. You'll see that the CharacterBody2D can't penetrate the obstacle. However, try moving into the obstacle at an angle and you'll find that the obstacle acts like glue - it feels like the body gets stuck.

This happens because there is no collision response. move_and_collide() stops the body's movement when a collision occurs. We need to code whatever response we want from the collision.

Try changing the function to move_and_slide() and running again.

move_and_slide() provides a default collision response of sliding the body along the collision object. This is useful for a great many game types, and may be all you need to get the behavior you want.

What if you don't want a sliding collision response? For this example ("bounce_and_collide.tscn" in the sample project), we have a character shooting bullets and we want the bullets to bounce off the walls.

This example uses three scenes. The main scene contains the Player and Walls. The Bullet and Wall are separate scenes so that they can be instanced.

The Player is controlled by the w and s keys for forward and back. Aiming uses the mouse pointer. Here is the code for the Player, using move_and_slide():

And the code for the Bullet:

The action happens in _physics_process(). After using move_and_collide(), if a collision occurs, a KinematicCollision2D object is returned (otherwise, the return is null).

If there is a returned collision, we use the normal of the collision to reflect the bullet's velocity with the Vector2.bounce() method.

If the colliding object (collider) has a hit method, we also call it. In the example project, we've added a flashing color effect to the Wall to demonstrate this.

Let's try one more popular example: the 2D platformer. move_and_slide() is ideal for quickly getting a functional character controller up and running. If you've downloaded the sample project, you can find this in "platformer.tscn".

For this example, we'll assume you have a level made of one or more StaticBody2D objects. They can be any shape and size. In the sample project, we're using Polygon2D to create the platform shapes.

Here's the code for the player body:

In this code we're using move_and_slide() as described above - to move the body along its velocity vector, sliding along any collision surfaces such as the ground or a platform. We're also using is_on_floor() to check if a jump should be allowed. Without this, you'd be able to "jump" in midair; great if you're making Flappy Bird, but not for a platformer game.

There is a lot more that goes into a complete platformer character: acceleration, double-jumps, coyote-time, and many more. The code above is just a starting point. You can use it as a base to expand into whatever movement behavior you need for your own projects.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
# Using move_and_collide.
var collision = move_and_collide(velocity * delta)
if collision:
    print("I collided with ", collision.get_collider().name)

# Using move_and_slide.
move_and_slide()
for i in get_slide_collision_count():
    var collision = get_slide_collision(i)
    print("I collided with ", collision.get_collider().name)
```

Example 2 (unknown):
```unknown
// Using MoveAndCollide.
var collision = MoveAndCollide(Velocity * (float)delta);
if (collision != null)
{
    GD.Print("I collided with ", ((Node)collision.GetCollider()).Name);
}

// Using MoveAndSlide.
MoveAndSlide();
for (int i = 0; i < GetSlideCollisionCount(); i++)
{
    var collision = GetSlideCollision(i);
    GD.Print("I collided with ", ((Node)collision.GetCollider()).Name);
}
```

Example 3 (unknown):
```unknown
# using move_and_collide
var collision = move_and_collide(velocity * delta)
if collision:
    velocity = velocity.slide(collision.get_normal())

# using move_and_slide
move_and_slide()
```

Example 4 (unknown):
```unknown
// using MoveAndCollide
var collision = MoveAndCollide(Velocity * (float)delta);
if (collision != null)
{
    Velocity = Velocity.Slide(collision.GetNormal());
}

// using MoveAndSlide
MoveAndSlide();
```

---

## Using TileMaps — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/using_tilemaps.html

**Contents:**
- Using TileMaps
- Introduction
- Specifying the TileSet in the TileMapLayer
- Multiple TileMapLayers and settings
  - Rendering
  - Physics
  - Navigation
  - Reordering layers
- Opening the TileMap editor
- Selecting tiles to use for painting

This page assumes you have created or downloaded a TileSet already. If not, please read Using TileSets first as you will need a TileSet to create a TileMap.

A tilemap is a grid of tiles used to create a game's layout. There are several benefits to using TileMapLayer nodes to design your levels. First, they make it possible to draw the layout by "painting" the tiles onto a grid, which is much faster than placing individual Sprite2D nodes one by one. Second, they allow for much larger levels because they are optimized for drawing large numbers of tiles. Finally, you can add collision, occlusion, and navigation shapes to tiles, adding greater functionality to the TileMap.

If you've followed the previous page on Using TileSets, you should have a TileSet resource that is built into the TileMapLayer node. This is good for prototyping, but in a real world project, you will generally have multiple levels reusing the same tileset.

The recommended way to reuse the same TileSet in several TileMapLayer nodes is to save the TileSet to an external resource. To do so, click the dropdown next to the TileSet resource and choose Save:

Saving the built-in TileSet resource to an external resource file

When working with tilemaps it's generally advised that you use multiple TileMapLayer nodes when appropriate. Using multiple layers can be advantageous, for example, this allows you to distinguish foreground tiles from background tiles for better organization. You can place one tile per layer at a given location, which allows you to overlap several tiles together if you have more than one layer.

Each TileMapLayer node has several properties you can adjust:

Enabled: If true, the layer is visible in the editor and when running the project.

TileSet The tileset used by the TileMapLayer node.

Y Sort Origin: The vertical offset to use for Y-sorting on each tile (in pixels). Only effective if Y Sort Enabled under CanvasItem settings is true.

X Draw Order Reversed Reverses the order tiles are drawn on the X axis. Requires that Y Sort Enabled under CanvasItem settings is true.

Rendering Quadrant Size A quadrant is a group of tiles drawn together on a single CanvasItem for optimization purposes. This setting defines the length of a square's side in the map's coordinate system. The quadrant size does not apply to a Y sorted TileMapLayer since tiles are grouped by Y position in that case.

Collision Enabled Enables or disables collision.

Use Kinematic Bodies When true TileMapLayer collision shapes will be instantiated as kinematic bodies.

Collision Visibility Mode Whether or not the TileMapLayer's collision shapes are visible. If set to default, then it depends on the show collision debug settings.

Navigation Enabled Whether or not navigation regions are enabled.

Navigation Visible Whether or not the TileMapLayer's navigation meshes are visible. If set to default then it depends on the show navigation debug settings.

TileMap built-in navigation has many practical limitations that result in inferior pathfinding performance and pathfollowing quality.

After designing the TileMap consider baking it to a more optimized navigation mesh (and disabling the TileMap NavigationLayer) using a NavigationRegion2D or the NavigationServer2D. See Using navigation meshes for additional information.

2D navigation meshes can not be "layered" or stacked on top of each other like visuals or physic shapes. Attempting to stack navigation meshes on the same navigation map will result in merge and logical errors that break the pathfinding.

You can reorder layers by drag-and-dropping their node in the Scene tab. You can also switch between which TileMapLayer node you're working on by using the buttons in the top right corner of the TileMap editor.

You can create, rename or reorder layers in the future without affecting existing tiles. Be careful though, as removing a layer will also remove all tiles that were placed on the layer.

Select the TileMapLayer node, then open the TileMap panel at the bottom of the editor:

Opening the TileMap panel at the bottom of the editor. The TileMapLayer node must be selected first.

First, if you've created additional layers above, make sure you've selected the layer you wish to paint on:

Selecting a layer to paint on in the TileMap editor

In the 2D editor, the layers you aren't currently editing from the same TileMapLayer node will appear grayed out while in the TileMap editor. You can disable this behavior by clicking the icon next to the layer selection menu (Highlight Selected TileMap Layer tooltip).

You can skip the above step if you haven't created additional layers, as the first layer is automatically selected when entering the TileMap editor.

Before you can place tiles in the 2D editor, you must select one or more tiles in the TileMap panel located at the bottom of the editor. To do so, click a tile in the TileMap panel, or hold down the mouse button to select multiple tiles:

Selecting a tile in the TileMap editor by clicking it

Like in the 2D and TileSet editors, you can pan across the TileMap panel using the middle or right mouse buttons, and zoom using the mouse wheel or buttons in the top-left corner.

You can also hold down Shift to append to the current selection. When selecting more than one tile, multiple tiles will be placed every time you perform a painting operation. This can be used to paint structures composed of multiple tiles in a single click (such as large platforms or trees).

The final selection does not have to be contiguous: if there is empty space between selected tiles, it will be left empty in the pattern that will be painted in the 2D editor.

Selecting multiple tiles in the TileMap editor by holding down the left mouse button

If you've created alternative tiles in your TileSet, you can select them for painting on the right of the base tiles:

Selecting an alternative tile in the TileMap editor

Lastly, if you've created a scenes collection in the TileSet, you can place scene tiles in the TileMap:

Placing a scene tile containing particles using the TileMap editor

Using the toolbar at the top of the TileMap editor, you can choose between several painting modes and tools. These modes affect operation when clicking in the 2D editor, not the TileMap panel itself.

From left to right, the painting modes and tools you can choose are:

Select tiles by clicking a single tile, or by holding down the left mouse button to select multiple with a rectangle in the 2D editor. Note that empty space cannot be selected: if you create a rectangle selection, only non-empty tiles will be selected.

To append to the current selection, hold Shift then select a tile. To remove from the current selection, hold Ctrl then select a tile.

The selection can then be used in any other painting mode to quickly create copies of an already-placed pattern.

You can remove the selected tiles from the TileMap by pressing Del.

You can toggle this mode temporarily while in Paint mode by holding Ctrl then performing a selection.

You can copy and paste tiles that were already placed by performing a selection, pressing Ctrl + C then pressing Ctrl + V. The selection will be pasted after left-clicking. You can press Ctrl + V another time to perform more copies this way. Right-click or press Escape to cancel pasting.

The standard Paint mode allows you to place tiles by clicking or holding down the left mouse button.

If you right-click, the currently selected tile will be erased from the tilemap. In other words, it will be replaced by empty space.

If you have selected multiple tiles in the TileMap or using the Selection tool, they will be placed every time you click or drag the mouse while holding down the left mouse button.

While in Paint mode, you can draw a line by holding Shift before holding down the left mouse button, then dragging the mouse to the line's end point. This is identical to using the Line tool described below.

You can also draw a rectangle by holding Ctrl and Shift before holding down the left mouse button, then dragging the mouse to the rectangle's end point. This is identical to using the Rectangle tool described below.

Lastly, you can pick existing tiles in the 2D editor by holding Ctrl then clicking on a tile (or holding and dragging the mouse). This will switch the currently painted tile(s) to the tile(s) you've just clicked. This is identical to using the Picker tool described below.

After selecting Line Paint mode, you can draw in a line that is always 1 tile thick (no matter its orientation).

If you right-click while in Line Paint mode, you will erase in a line.

If you have selected multiple tiles in the TileMap or using the Selection tool, you can place them in a repeating pattern across the line.

You can toggle this mode temporarily while in Paint or Eraser mode by holding Shift then drawing.

Using the line tool after selecting two tiles to draw platforms diagonally

After selecting Rectangle Paint mode, you can draw in an axis-aligned rectangle.

If you right-click while in Rectangle Paint mode, you will erase in an axis-aligned rectangle.

If you have selected multiple tiles in the TileMap or using the Selection tool, you can place them in a repeating pattern within the rectangle.

You can toggle this mode temporarily while in Paint or Eraser mode by holding Ctrl and Shift then drawing.

After selecting Bucket Fill mode, you can choose whether painting should be limited to contiguous areas only by toggling the Contiguous checkbox that appears on the right of the toolbar.

If you enable Contiguous (the default), only matching tiles that touch the current selection will be replaced. This contiguous check is performed horizontally and vertically, but not diagonally.

If you disable Contiguous, all tiles with the same ID in the entire TileMap will be replaced by the currently selected tile. If selecting an empty tile with Contiguous unchecked, all tiles in the rectangle that encompasses the TileMap's effective area will be replaced instead.

If you right-click while in Bucket Fill mode, you will replace matching tiles with empty tiles.

If you have selected multiple tiles in the TileMap or using the Selection tool, you can place them in a repeating pattern within the filled area.

Using the Bucket Fill tool

After selecting Picker mode, you can pick existing tiles in the 2D editor by holding Ctrl then clicking on a tile. This will switch the currently painted tile to the tile you've just clicked. You can also pick multiple tiles at once by holding down the left mouse button and forming a rectangle selection. Only non-empty tiles can be picked.

You can toggle this mode temporarily while in Paint mode by holding Ctrl then clicking or dragging the mouse.

This mode is combined with any other painting mode (Paint, Line, Rectangle, Bucket Fill). When eraser mode is enabled, tiles will be replaced by empty tiles instead of drawing new lines when left-clicking.

You can toggle this mode temporarily while in any other mode by right-clicking instead of left-clicking.

While painting, you can optionally enable randomization. When enabled, a random tile will be chosen between all the currently selected tiles when painting. This is supported with the Paint, Line, Rectangle and Bucket Fill tools. For effective paint randomization, you must select multiple tiles in the TileMap editor or use scattering (both approaches can be combined).

If Scattering is set to a value greater than 0, there is a chance that no tile will be placed when painting. This can be used to add occasional, non-repeating detail to large areas (such as adding grass or crumbs on a large top-down TileMap).

Example when using Paint mode:

Selecting from several times to randomly choose, then painting by holding down the left mouse button

Example when using Bucket Fill mode:

Using Bucket Fill tool with a single tile, but with randomization and scattering enabled

Eraser mode does not take randomization and scattering into account. All tiles within the selection are always removed.

While you can copy and paste tiles while in Select mode, you may wish to save premade patterns of tiles to place together in a go. This can be done on a per-TileMap basis by choosing the Patterns tab of the TileMap editor.

To create a new pattern, switch to Select mode, perform a selection and press Ctrl + C. Click on empty space within the Patterns tab (a blue focus rectangle should appear around the empty space), then press Ctrl + V:

Creating a new pattern from a selection in the TileMap editor

To use an existing pattern, click its image in the Patterns tab, switch to any painting mode, then left-click somewhere in the 2D editor:

Placing an existing pattern using the TileMap editor

Like multi-tile selections, patterns will be repeated if used with the Line, Rectangle or Bucket Fill painting modes.

Despite being edited in the TileMap editor, patterns are stored in the TileSet resource. This allows reusing patterns in different TileMapLayer nodes after loading a TileSet resource saved to an external file.

To use terrains, the TileMapLayer node must feature at least one terrain set and a terrain within this terrain set. See Creating terrain sets (autotiling) if you haven't created a terrain set for the TileSet yet.

There are 3 kinds of painting modes available for terrain connections:

Connect, where tiles are connected to surrounding tiles on the same TileMapLayer.

Path, where tiles are connected to tiles painted in the same stroke (until the mouse button is released).

Tile-specific overrides to resolve conflicts or handle situations not covered by the terrain system.

The Connect mode is easier to use, but Path is more flexible as it allows for more artist control during painting. For instance, Path can allow roads to be directly adjacent to each other without being connected to each other, while Connect will force both roads to be connected.

Selecting Connect mode in the TileMap editor's Terrains tab

Selecting Path mode in the TileMap editor's Terrains tab

Lastly, you can select specific tiles from the terrain to resolve conflicts in certain situations:

Painting with specific tiles in the TileMap editor's Terrains tab

Any tile that has at least one of its bits set to a value set to the corresponding terrain ID will appear in the list of tiles to choose from.

If you remove tiles in the TileSet that are referenced in a TileMap, the TileMap will display a placeholder to indicate that an invalid tile ID is placed:

Missing tiles in the TileMap editor due to the TileSet reference being broken

These placeholders are not visible in the running project, but the tile data is still persisted to disk. This allows you to safely close and reopen such scenes. Once you re-add a tile with the matching ID, the tiles will appear with the new tile's appearance.

Missing tile placeholders may not be visible until you select the TileMapLayer node and open the TileMap editor.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Using TileSets — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/using_tilesets.html

**Contents:**
- Using TileSets
- Introduction
- Creating a new TileSet
  - Using a tilesheet
  - Using a collection of scenes
- Merging several atlases into a single atlas
- Adding collision, navigation and occlusion to the TileSet
- Assigning custom metadata to the TileSet's tiles
- Creating terrain sets (autotiling)
- Assigning properties to multiple tiles at once

A tilemap is a grid of tiles used to create a game's layout. There are several benefits to using TileMapLayer nodes to design your levels. First, they let you draw a layout by "painting" tiles onto a grid, which is much faster than placing individual Sprite2D nodes one by one. Second, they allow for larger levels because they are optimized for drawing large numbers of tiles. Finally, they allow you to add greater functionality to your tiles with collision, occlusion, and navigation shapes.

To use TileMapLayer nodes, you will need to create a TileSet first. A TileSet is a collection of tiles that can be placed in a TileMapLayer node. After creating a TileSet, you will be able to place them using the TileMap editor.

To follow this guide, you will need an image containing your tiles where every tile has the same size (large objects can be split into several tiles). This image is called a tilesheet. Tiles do not have to be square: they can be rectangular, hexagonal, or isometric (pseudo-3D perspective).

This demonstration will use the following tiles taken from Kenney's "Abstract Platformer" pack. We'll use this particular tilesheet from the set:

Tilesheet with 64×64 tiles. Credit: Kenney

Create a new TileMapLayer node, then select it and create a new TileSet resource in the inspector:

Creating a new TileSet resource within the TileMapLayer node

After creating the TileSet resource, click the value to unfold it in the inspector. The default tile shape is Square, but you can also choose Isometric, Half-Offset Square or Hexagon (depending on the shape of your tile images). If using a tile shape other than Square, you may also need to adjust the Tile Layout and Tile Offset Axis properties. Lastly, enabling the Rendering > UV Clipping property may be useful if you wish tiles to be clipped by their tile coordinates. This ensures tiles cannot draw outside their allocated area on the tilesheet.

Set the tile size to 64×64 in the inspector to match the example tilesheet:

Setting the tile size to 64×64 to match the example tilesheet

If relying on automatic tiles creation (like we're about to do here), you must set the tile size before creating the atlas. The atlas will determine which tiles from the tilesheet can be added to a TileMapLayer node (as not every part of the image may be a valid tile).

Open the TileSet panel at the bottom of the editor, then click and drag the tilesheet image onto the panel. You will be asked whether to create tiles automatically. Answer Yes:

Automatically creating tiles based on tilesheet image content

This will automatically create tiles according to the tile size you specified earlier in the TileSet resource. This greatly speeds up initial tile setup.

When using automatic tile generation based on image contents, parts of the tilesheet that are fully transparent will not have tiles generated.

If there are tiles from the tilesheet you do not wish to be present in atlas, choose the Eraser tool at the top of the tileset preview, then click the tiles you wish to remove:

Using the Eraser tool to remove unwanted tiles from the TileSet atlas

You can also right-click a tile and choose Delete, as an alternative to the Eraser tool.

Like in the 2D and TileMap editors, you can pan across the TileSet panel using the middle or right mouse buttons, and zoom using the mouse wheel or buttons in the top-left corner.

If you wish to source tiles from several tilesheet images for a single TileSet, create additional atlases and assign textures to each of them before continuing. It is also possible to use one image per tile this way (although using tilesheets is recommended for better usability).

You can adjust properties for the atlas in the middle column:

Adjusting TileSet atlas properties in the dedicated inspector (part of the TileSet panel)

The following properties can be adjusted on the atlas:

ID: The identifier (unique within this TileSet), used for sorting.

Name: The human-readable name for the atlas. Use a descriptive name here for organizational purposes (such as "terrain", "decoration", etc).

Margins: The margins on the image's edges that should not be selectable as tiles (in pixels). Increasing this can be useful if you download a tilesheet image that has margins on the edges (e.g. for attribution).

Separation: The separation between each tile on the atlas in pixels. Increasing this can be useful if the tilesheet image you're using contains guides (such as outlines between every tile).

Texture Region Size: The size of each tile on the atlas in pixels. In most cases, this should match the tile size defined in the TileMapLayer property (although this is not strictly necessary).

Use Texture Padding: If checked, adds a 1-pixel transparent edge around each tile to prevent texture bleeding when filtering is enabled. It's recommended to leave this enabled unless you're running into rendering issues due to texture padding.

Note that changing texture margin, separation and region size may cause tiles to be lost (as some of them would be located outside the atlas image's coordinates). To regenerate tiles automatically from the tilesheet, use the three vertical dots menu button at the top of the TileSet editor and choose Create Tiles in Non-Transparent Texture Regions:

Recreating tiles automatically after changing atlas properties

Since Godot 4.0, you can place actual scenes as tiles. This allows you to use any collection of nodes as a tile. For example, you could use scene tiles to place gameplay elements, such as shops the player may be able to interact with. You could also use scene tiles to place AudioStreamPlayer2Ds (for ambient sounds), particle effects, and more.

Scene tiles come with a greater performance overhead compared to atlases, as every scene is instanced individually for every placed tile.

It's recommended to only use scene tiles when necessary. To draw sprites in a tile without any kind of advanced manipulation, use atlases instead.

For this example, we'll create a scene containing a CPUParticles2D root node. Save this scene to a scene file (separate from the scene containing the TileMapLayer), then switch to the scene containing the TileMapLayer node. Open the TileSet editor, and create a new Scenes Collection in the left column:

Creating a scenes collection in the TileSet editor

After creating a scenes collection, you can enter a descriptive name for the scenes collection in the middle column if you wish. Select this scenes collection then create a new scene slot:

Creating a scene tile after selecting the scenes collection in the TileSet editor

Select this scene slot in the right column, then use Quick Load (or Load) to load the scene file containing the particles:

Creating a scene slot, then loading a scene file into it in the TileSet editor

You now have a scene tile in your TileSet. Once you switch to the TileMap editor, you'll be able to select it from the scenes collection and paint it like any other tile.

Using multiple atlases within a single TileSet resource can sometimes be useful, but it can also be cumbersome in certain situations (especially if you're using one image per tile). Godot allows you to merge several atlases into a single atlas for easier organization.

To do so, you must have more than one atlas created in the TileSet resource. Use the "three vertical dots" menu button located at the bottom of the list of atlases, then choose Open Atlas Merging Tool:

Opening the atlas merging tool after creating multiple atlases

This will open a dialog, in which you can select several atlases by holding Shift or Ctrl then clicking on multiple elements:

Using the atlas merging tool dialog

Choose Merge to merge the selected atlases into a single atlas image (which translates to a single atlas within the TileSet). The unmerged atlases will be removed within the TileSet, but the original tilesheet images will be kept on the filesystem. If you don't want the unmerged atlases to be removed from the TileSet resource, choose Merge (Keep Original Atlases) instead.

TileSet features a system of tile proxies. Tile proxies are a mapping table that allows notifying the TileMap using a given TileSet that a given set of tile identifiers should be replaced by another one.

Tile proxies are automatically set up when merging different atlases, but they can also be set manually thanks to the Manage Tile Proxies dialog you can access using the "three vertical dots" menu mentioned above.

Manually creating tile proxies may be useful when you changed an atlas ID or want to replace all tiles from an atlas by the ones from another atlas. Note that when editing a TileMap, you can replace all cells by their corresponding mapped value.

We've now successfully created a basic TileSet. We could start using it in the TileMapLayer node now, but it currently lacks any form of collision detection. This means the player and other objects could walk straight through the floor or walls.

If you use 2D navigation, you'll also need to define navigation polygons for tiles to generate a navigation mesh that agents can use for pathfinding.

Lastly, if you use 2D lights and shadows or GPUParticles2D, you may also want your TileSet to be able to cast shadows and collide with particles. This requires defining occluder polygons for "solid" tiles on the TileSet.

To be able to define collision, navigation and occlusion shapes for each tile, you will need to create a physics, navigation or occlusion layer for the TileSet resource first. To do so, select the TileMapLayer node, click the TileSet property value in the inspector to edit it then unfold Physics Layers and choose Add Element:

Creating a physics layer in the TileSet resource inspector (within the TileMapLayer node)

If you also need navigation support, now is a good time to create a navigation layer:

Creating a navigation layer in the TileSet resource inspector (within the TileMapLayer node)

If you need support for light polygon occluders, now is a good time to create an occlusion layer:

Creating an occlusion layer in the TileSet resource inspector (within the TileMapLayer node)

Future steps in this tutorial are tailored to creating collision polygons, but the procedure for navigation and occlusion is very similar. Their respective polygon editors behave in the same way, so these steps are not repeated for brevity.

The only caveat is that the tile's occlusion polygon property is part of a Rendering subsection in the atlas inspector. Make sure to unfold this section so you can edit the polygon.

After creating a physics layer, you have access to the Physics Layer section in the TileSet atlas inspector:

Opening the collision editor while in Select mode

You can quickly create a rectangle collision shape by pressing F while the TileSet editor is focused. If the keyboard shortcut doesn't work, try clicking in the empty area around the polygon editor to focus it:

Using default rectangle collision shape by pressing F

In this tile collision editor, you have access to all the 2D polygon editing tools:

Use the toolbar above the polygon to toggle between creating a new polygon, editing an existing polygon and removing points on the polygon. The "three vertical dots" menu button offers additional options, such as rotating and flipping the polygon.

Create new points by clicking and dragging a line between two points.

Remove a point by right-clicking it (or using the Remove tool described above and left-clicking).

Pan in the editor by middle-clicking or right-clicking. (Right-click panning can only be used in areas where there is no point nearby.)

You can use the default rectangle shape to quickly create a triangle-shaped collision shape by removing one of the points:

Creating a triangle collision shape by right-clicking one of the corners to remove it

You can also use the rectangle as a base for more complex shapes by adding more points:

Drawing a custom collision for a complex tile shape

If you have a large tileset, specifying the collision for each tile individually could take a lot of time. This is especially true as TileMaps tend to have many tiles with common collision patterns (such as solid blocks or 45-degree slopes). To apply a similar collision shape to several tiles quickly, use functionality to assign properties to multiple tiles at once.

You can assign custom data on a per-tile basis using custom data layers. This can be useful to store information specific to your game, such as the damage that a tile should deal when the player touches it, or whether a tile can be destroyed using a weapon.

The data is associated with the tile in the TileSet: all instances of the placed tile will use the same custom data. If you need to create a variant of a tile that has different custom data, this can be done by creating an alternative tile and changing the custom data for the alternative tile only.

Creating a custom data layer in the TileSet resource inspector (within the TileMapLayer node)

Example of configured custom data layers with game-specific properties

You can reorder custom data without breaking existing metadata: the TileSet editor will update automatically after reordering custom data properties.

With the custom data layers example shown above, we're assigning a tile to have the damage_per_second metadata set to 25 and the destructible metadata to false:

Editing custom data in the TileSet editor while in Select mode

Tile property painting can also be used for custom data:

Assigning custom data in the TileSet editor using tile property painting

This functionality was implemented in a different form as autotiling in Godot 3.x. Terrains are essentially a more powerful replacement of autotiles. Unlike autotiles, terrains can support transitions from one terrain to another, as a tile may define several terrains at once.

Unlike before, where autotiles were a specific kind of tiles, terrains are only a set of properties assigned to atlas tiles. These properties are then used by a dedicated TileMap painting mode that selects tiles featuring terrain data in a smart way. This means any terrain tile can be either painted as terrain or as a single tile, like any other.

A "polished" tileset generally features variations that you should use on corners or edges of platforms, floors, etc. While these can be placed manually, this quickly becomes tedious. Handling this situation with procedurally generated levels can also be difficult and require a lot of code.

Godot offers terrains to perform this kind of tile connection automatically. This allows you to have the "correct" tile variants automatically used.

Terrains are grouped into terrain sets. Each terrain set is assigned a mode from Match Corners and Sides, Match Corners and Match sides. They define how terrains are matched to each other in a terrain set.

The above modes correspond to the previous bitmask modes autotiles used in Godot 3.x: 2×2, 3×3 or 3×3 minimal. This is also similar to what the Tiled editor features.

Select the TileMapLayer node, go to the inspector and create a new terrain set within the TileSet resource:

Creating a terrain set in the TileSet resource inspector (within the TileMapLayer node)

After creating a terrain set, you must create one or more terrains within the terrain set:

Creating a terrain within the terrain set

In the TileSet editor, switch to Select mode and click a tile. In the middle column, unfold the Terrains section then assign a terrain set ID and a terrain ID for the tile. -1 means "no terrain set" or "no terrain", which means you must set Terrain Set to 0 or greater before you can set Terrain to 0 or greater.

Terrain set IDs and terrain IDs are independent from each other. They also start from 0, not 1.

Configuring terrain on a single tile in the TileSet editor's Select mode

After doing so, you can now configure the Terrain Peering Bits section which becomes visible in the middle column. The peering bits determine which tile will be placed depending on neighboring tiles. -1 is a special value which refers to empty space.

For example, if a tile has all its bits set to 0 or greater, it will only appear if all 8 neighboring tiles are using a tile with the same terrain ID. If a tile has its bits set to 0 or greater, but the top-left, top and top-right bits are set to -1, it will only appear if there is empty space on top of it (including diagonally).

Configuring terrain peering bits on a single tile in the TileSet editor's Select mode

An example configuration for a full tilesheet may look as follows:

Example full tilesheet for a sidescrolling game

Example full tilesheet for a sidescrolling game with terrain peering bits visible

There are two ways to assign properties to multiple tiles at once. Depending on your use cases, one method may be faster than the other:

If you wish to configure various properties on several tiles at once, choose the Select mode at the top of the TileSet editor:

After doing this, you can select multiple tiles on the right column by holding Shift then clicking on tiles. You can also perform rectangle selection by holding down the left mouse button then dragging the mouse. Lastly, you can deselect tiles that were already selected (without affecting the rest of the selection) by holding Shift then clicking on a selected tile.

You can then assign properties using the inspector in the middle column of the TileSet editor. Only properties that you change here will be applied to all selected tiles. Like in the editor's inspector, properties that differ on selected tiles will remain different until you edit them.

With numerical and color properties, you will also see a preview of the property's value on all tiles in the atlas after editing a property:

Selecting multiple tiles using the Select mode, then applying properties

If you wish to apply a single property to several tiles at once, you can use the property painting mode for this purpose.

Configure a property to be painted in the middle column, then click on tiles (or hold down the left mouse button) in the right column to "paint" properties onto tiles.

Painting tile properties using the TileSet editor

Tile property painting is especially useful with properties that are time-consuming to set manually, such as collision shapes:

Painting a collision polygon, then left-clicking tiles to apply it

Sometimes, you want to use a single tile image (found only once within the atlas), but configured in different ways. For example, you may want to use the same tile image, but rotated, flipped, or modulated with a different color. This can be done using alternative tiles.

Since Godot 4.2, you don't have to create alternative tiles to rotate or flip tiles anymore. You can rotate any tile while placing it in the TileMap editor by using the rotation/flip buttons in the TileMap editor toolbar.

To create an alternative tile, right-click a base tile in the atlas displayed by the TileSet editor, then choose Create an Alternative Tile:

Creating an alternative tile by right-clicking a base tile in the TileSet editor

If currently in Select mode, the alternative tile will already be selected for editing. If not currently in Select mode, you can still create alternative tiles, but you will need to switch to Select mode and select the alternative tile to edit it.

If you don't see the alternative tile, pan over to the right of the atlas image, as alternative tiles always appear on the right of base tiles of a given atlas in the TileSet editor:

Configuring an alternative tile after clicking it in the TileSet editor

After selecting an alternative tile, you can change any properties using the middle column like you would on a base tile. However, the list of exposed properties is different compared to base tiles:

Alternative ID: The unique numerical identifier for this alternative tile. Changing it will break existing TileMaps, so be careful! This ID also controls the sorting in the list of alternative tiles displayed in the editor.

Rendering > Flip H: If true, the tile is horizontally flipped.

Rendering > Flip V: If true, the tile is vertically flipped.

Rendering > Transpose: If true, the tile is rotated 90 degrees counter-clockwise and then flipped vertically. In practice, this means that to rotate a tile by 90 degrees clockwise without flipping it, you should enable Flip H and Transpose. To rotate a tile by 180 degrees clockwise, enable Flip H and Flip V. To rotate a tile by 270 degrees clockwise, enable Flip V and Transpose.

Rendering > Texture Origin: The origin to use for drawing the tile. This can be used to visually offset the tile compared to the base tile.

Rendering > Modulate: The color multiplier to use when rendering the tile.

Rendering > Material: The material to use for this tile. This can be used to apply a different blend mode or custom shaders to a single tile.

Z Index: The sorting order for this tile. Higher values will make the tile render in front of others on the same layer.

Y Sort Origin: The vertical offset to use for tile sorting based on its Y coordinate (in pixels). This allows using layers as if they were on different height for top-down games. Adjusting this can help alleviate issues with sorting certain tiles. Only effective if Y Sort Enabled is true on the TileMapLayer node under CanvasItem > Ordering

You can create an additional alternative tile variant by clicking the large "+" icon next to the alternative tile. This is equivalent to selecting the base tile and right-clicking it to choose Create an Alternative Tile again.

When creating an alternative tile, none of the properties from the base tile are inherited. You must set properties again on the alternative tile if you wish those to be identical on the base tile and the alternative tile.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

---

## Viewport and canvas transforms — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/2d/2d_transforms.html

**Contents:**
- Viewport and canvas transforms
- Introduction
- Canvas transform
- Global canvas transform
- Stretch transform
- Window transform
- Transform order
- Transform functions
- Feeding custom input events
- User-contributed notes

This is an overview of the 2D transforms going on for nodes from the moment they draw their content locally to the time they are drawn onto the screen. This overview discusses very low-level details of the engine.

The goal of this tutorial is to teach a way for feeding input events to the Input with a position in the correct coordinate system.

A more extensive description of all coordinate systems and 2d transforms is available in 2D coordinate systems and 2D transforms.

As mentioned in the previous tutorial, Canvas layers, every CanvasItem node (remember that Node2D and Control based nodes use CanvasItem as their common root) will reside in a Canvas Layer. Every canvas layer has a transform (translation, rotation, scale, etc.) that can be accessed as a Transform2D.

Also covered in the previous tutorial, nodes are drawn by default in Layer 0, in the built-in canvas. To put nodes in a different layer, a CanvasLayer node can be used.

Viewports also have a Global Canvas transform (also a Transform2D). This is the master transform and affects all individual Canvas Layer transforms. Generally, this is primarily used in Godot's CanvasItem Editor.

Finally, viewports have a Stretch Transform, which is used when resizing or stretching the screen. This transform is used internally (as described in Multiple resolutions), but can also be manually set on each viewport.

Input events are multiplied by this transform, but lack the ones above. To convert InputEvent coordinates to local CanvasItem coordinates, the CanvasItem.make_input_local() function was added for convenience.

The root viewport is a Window. In order to scale and position the Window's content as described in Multiple resolutions, each Window contains a window transform. It is for example responsible for the black bars at the Window's sides so that the Viewport is displayed with a fixed aspect ratio.

To convert a CanvasItem local coordinate to an actual screen coordinate, the following chain of transforms must be applied:

The above graphic shows some available transform functions. All transforms are directed from right to left, this means multiplying a transform with a coordinate results in a coordinate system further to the left, multiplying the affine inverse of a transform results in a coordinate system further to the right:

Finally, then, to convert a CanvasItem local coordinates to screen coordinates, just multiply in the following order:

Keep in mind, however, that it is generally not desired to work with screen coordinates. The recommended approach is to simply work in Canvas coordinates (CanvasItem.get_global_transform()), to allow automatic screen resolution resizing to work properly.

It is often desired to feed custom input events to the game. With the above knowledge, to correctly do this in the focused window, it must be done the following way:

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
# Called from a CanvasItem.
canvas_pos = get_global_transform() * local_pos
local_pos = get_global_transform().affine_inverse() * canvas_pos
```

Example 2 (unknown):
```unknown
// Called from a CanvasItem.
canvasPos = GetGlobalTransform() * localPos;
localPos = GetGlobalTransform().AffineInverse() * canvasPos;
```

Example 3 (unknown):
```unknown
var screen_coord = get_viewport().get_screen_transform() * get_global_transform_with_canvas() * local_pos
```

Example 4 (unknown):
```unknown
var screenCoord = GetViewport().GetScreenTransform() * GetGlobalTransformWithCanvas() * localPos;
```

---

## Your first 2D shader — Godot Engine (stable) documentation in English

**URL:** https://docs.godotengine.org/en/stable/tutorials/shaders/your_first_shader/your_first_2d_shader.html

**Contents:**
- Your first 2D shader
- Introduction
- Setup
- Your first CanvasItem shader
- Your first fragment function
  - Using TEXTURE built-in
  - Uniform input
  - Interacting with shaders from code
- Your first vertex function
- Conclusion

Shaders are special programs that execute on the GPU and are used for rendering graphics. All modern rendering is done with shaders. For a more detailed description of what shaders are please see What are shaders.

This tutorial will focus on the practical aspects of writing shader programs by walking you through the process of writing a shader with both vertex and fragment functions. This tutorial targets absolute beginners to shaders.

If you have experience writing shaders and are just looking for an overview of how shaders work in Godot, see the Shading Reference.

CanvasItem shaders are used to draw all 2D objects in Godot, while Spatial shaders are used to draw all 3D objects.

In order to use a shader it must be attached inside a Material which must be attached to an object. Materials are a type of Resource. To draw multiple objects with the same material, the material must be attached to each object.

All objects derived from a CanvasItem have a material property. This includes all GUI elements, Sprite2Ds, TileMapLayers, MeshInstance2Ds etc. They also have an option to inherit their parent's material. This can be useful if you have a large number of nodes that you want to use the same material.

To begin, create a Sprite2D node. You can use any CanvasItem, so long as it is drawing to the canvas, so for this tutorial we will use a Sprite2D, as it is the easiest CanvasItem to start drawing with.

In the Inspector, click beside "Texture" where it says "[empty]" and select "Load", then select "icon.svg". For new projects, this is the Godot icon. You should now see the icon in the viewport.

Next, look down in the Inspector, under the CanvasItem section, click beside "Material" and select "New ShaderMaterial". This creates a new Material resource. Click on the sphere that appears. Godot currently doesn't know whether you are writing a CanvasItem Shader or a Spatial Shader and it previews the output of spatial shaders. So what you are seeing is the output of the default Spatial Shader.

Materials that inherit from the Material resource, such as StandardMaterial3D and ParticleProcessMaterial, can be converted to a ShaderMaterial and their existing properties will be converted to an accompanying text shader. To do so, right-click on the material in the FileSystem dock and choose Convert to ShaderMaterial. You can also do so by right-clicking on any property holding a reference to the material in the inspector.

Click beside "Shader" and select "New Shader". Finally, click on the shader you just created and the shader editor will open. You are now ready to begin writing your first shader.

In Godot, all shaders start with a line specifying what type of shader they are. It uses the following format:

Because we are writing a CanvasItem shader, we specify canvas_item in the first line. All our code will go beneath this declaration.

This line tells the engine which built-in variables and functionality to supply you with.

In Godot you can override three functions to control how the shader operates; vertex, fragment, and light. This tutorial will walk you through writing a shader with both vertex and fragment functions. Light functions are significantly more complex than vertex and fragment functions and so will not be covered here.

The fragment function runs for every pixel in a Sprite2D and determines what color that pixel should be.

They are restricted to the pixels covered by the Sprite2D, that means you cannot use one to, for example, create an outline around a Sprite2D.

The most basic fragment function does nothing except assign a single color to every pixel.

We do so by writing a vec4 to the built-in variable COLOR. vec4 is shorthand for constructing a vector with 4 numbers. For more information about vectors see the Vector math tutorial. COLOR is both an input variable to the fragment function and the final output from it.

Congratulations! You're done. You have successfully written your first shader in Godot.

Now let's make things more complex.

There are many inputs to the fragment function that you can use for calculating COLOR. UV is one of them. UV coordinates are specified in your Sprite2D (without you knowing it!) and they tell the shader where to read from textures for each part of the mesh.

In the fragment function you can only read from UV, but you can use it in other functions or to assign values to COLOR directly.

UV varies between 0-1 from left-right and from top-bottom.

The default fragment function reads from the set Sprite2D texture and displays it.

When you want to adjust a color in a Sprite2D you can adjust the color from the texture manually like in the code below.

Certain nodes, like Sprite2Ds, have a dedicated texture variable that can be accessed in the shader using TEXTURE. If you want to use the Sprite2D texture to combine with other colors, you can use the UV with the texture function to access this variable. Use them to redraw the Sprite2D with the texture.

Uniform input is used to pass data into a shader that will be the same across the entire shader.

You can use uniforms by defining them at the top of your shader like so:

For more information about usage see the Shading Language doc.

Add a uniform to change the amount of blue in our Sprite2D.

Now you can change the amount of blue in the Sprite2D from the editor. Look back at the Inspector under where you created your shader. You should see a section called "Shader Param". Unfold that section and you will see the uniform you just declared. If you change the value in the editor, it will overwrite the default value you provided in the shader.

You can change uniforms from code using the function set_shader_parameter() which is called on the node's material resource. With a Sprite2D node, the following code can be used to set the blue uniform.

Note that the name of the uniform is a string. The string must match exactly with how it is written in the shader, including spelling and case.

Now that we have a fragment function, let's write a vertex function.

Use the vertex function to calculate where on the screen each vertex should end up.

The most important variable in the vertex function is VERTEX. Initially, it specifies the vertex coordinates in your model, but you also write to it to determine where to actually draw those vertices. VERTEX is a vec2 that is initially presented in local-space (i.e. not relative to the camera, viewport, or parent nodes).

You can offset the vertices by directly adding to VERTEX.

Combined with the TIME built-in variable, this can be used for basic animation.

At their core, shaders do what you have seen so far, they compute VERTEX and COLOR. It is up to you to dream up more complex mathematical strategies for assigning values to those variables.

For inspiration, take a look at some of the more advanced shader tutorials, and look at other sites like Shadertoy and The Book of Shaders.

Please read the User-contributed notes policy before submitting a comment.

© Copyright 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0).

**Examples:**

Example 1 (unknown):
```unknown
shader_type canvas_item;
```

Example 2 (unknown):
```unknown
void fragment(){
  COLOR = vec4(0.4, 0.6, 0.9, 1.0);
}
```

Example 3 (unknown):
```unknown
void fragment() {
  COLOR = vec4(UV, 0.5, 1.0);
}
```

Example 4 (unknown):
```unknown
void fragment(){
  // This shader will result in a blue-tinted icon
  COLOR.b = 1.0;
}
```

---
